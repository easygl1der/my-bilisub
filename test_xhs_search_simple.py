#!/usr/bin/env python3
"""
å°çº¢ä¹¦æœç´¢æµ‹è¯• - ç®€åŒ–ç‰ˆç”¨äºè°ƒè¯•
"""

import asyncio
import sys
import re
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from playwright.async_api import async_playwright

PROJECT_DIR = Path(__file__).parent


def read_xhs_cookie_string() -> str:
    """ä» config/cookies.txt è¯»å–å°çº¢ä¹¦Cookieï¼ˆè¿”å›å­—ç¬¦ä¸²æ ¼å¼ï¼‰"""
    cookie_file = PROJECT_DIR / "config" / "cookies.txt"
    if not cookie_file.exists():
        return ""

    with open(cookie_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŸ¥æ‰¾ xiaohongshu_full= æ ¼å¼
    match = re.search(r'xiaohongshu_full=([^\n]+)', content)
    if match:
        return match.group(1)

    # æŸ¥æ‰¾ [xiaohongshu] éƒ¨åˆ†
    xhs_section = re.search(r'\[xiaohongshu\](.*?)\[', content, re.DOTALL)
    if xhs_section:
        section = xhs_section.group(1)
        cookies = []
        for line in section.split('\n'):
            line = line.strip()
            if '=' in line and not line.startswith('#'):
                key, value = line.split('=', 1)
                cookies.append(f"{key.strip()}={value.strip()}")
        return '; '.join(cookies)

    return ""


async def search_xhs(keyword: str, headless: bool = False):
    """å°çº¢ä¹¦æœç´¢æµ‹è¯•"""

    print(f"\n{'='*70}")
    print(f"  å°çº¢ä¹¦æœç´¢æµ‹è¯•")
    print(f"{'='*70}")
    print(f"\næœç´¢å…³é”®è¯: {keyword}")
    print(f"æ— å¤´æ¨¡å¼: {headless}\n")

    # è¯»å–Cookie
    cookie = read_xhs_cookie_string()
    if cookie:
        print(f"âœ… Cookieå·²è¯»å– ({len(cookie)} å­—ç¬¦)")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°Cookie")

    # å¯åŠ¨æµè§ˆå™¨
    playwright = await async_playwright().start()
    browser = await playwright.chromium.launch(headless=headless)
    context = await browser.new_context(
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    )

    # è®¾ç½®Cookie
    if cookie:
        try:
            cookies = []
            for item in cookie.split(';'):
                item = item.strip()
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies.append({
                        'name': key,
                        'value': value,
                        'domain': '.xiaohongshu.com',
                        'path': '/'
                    })
            await context.add_cookies(cookies)
            print(f"âœ… Cookieå·²è®¾ç½® ({len(cookies)} ä¸ª)\n")
        except Exception as e:
            print(f"âš ï¸  Cookieè®¾ç½®å¤±è´¥: {e}\n")

    page = await context.new_page()
    print("âœ… æµè§ˆå™¨å·²å¯åŠ¨\n")

    # è®¿é—®å°çº¢ä¹¦ä¸»é¡µ
    print("ğŸ“„ è®¿é—®å°çº¢ä¹¦ä¸»é¡µ...")
    try:
        await page.goto('https://www.xiaohongshu.com/', wait_until='domcontentloaded', timeout=60000)
        await asyncio.sleep(3)

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        page_content = await page.content()
        if 'ç™»å½•' in page_content and 'æ³¨å†Œ' in page_content:
            print("âš ï¸  æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
            print("ğŸ’¡ è¯·æ‰‹åŠ¨ç™»å½•æˆ–æ›´æ–°Cookie\n")
            if not headless:
                print("â³ ç­‰å¾…30ç§’ä¾›æ‰‹åŠ¨ç™»å½•...")
                await asyncio.sleep(30)
        else:
            print("âœ… å·²ç™»å½•\n")
    except Exception as e:
        print(f"âš ï¸  ä¸»é¡µåŠ è½½é—®é¢˜: {e}\n")

    # è®¿é—®æœç´¢é¡µé¢
    search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}&type=51"
    print(f"ğŸ” è®¿é—®æœç´¢é¡µé¢: {search_url}")
    try:
        await page.goto(search_url, wait_until='domcontentloaded', timeout=60000)
        await asyncio.sleep(5)
        print("âœ… æœç´¢é¡µé¢åŠ è½½å®Œæˆ\n")
    except Exception as e:
        print(f"âš ï¸  æœç´¢é¡µé¢åŠ è½½é—®é¢˜: {e}\n")

    # è·å–é¡µé¢æ ‡é¢˜
    title = await page.title()
    print(f"ğŸ“‹ é¡µé¢æ ‡é¢˜: {title}\n")

    # è·å–é¡µé¢URL
    url = page.url
    print(f"ğŸ”— å½“å‰URL: {url}\n")

    # æ£€æŸ¥é¡µé¢å†…å®¹
    print("ğŸ“Š æ£€æŸ¥é¡µé¢å†…å®¹...")
    page_content = await page.content()
    print(f"   é¡µé¢å†…å®¹é•¿åº¦: {len(page_content)} å­—ç¬¦")

    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æç¤º
    if 'å‡ºé”™' in page_content or 'é”™è¯¯' in page_content or 'è®¿é—®å—é™' in page_content:
        print("   âš ï¸  æ£€æµ‹åˆ°é”™è¯¯æç¤º")
    else:
        print("   âœ… æ— æ˜æ˜¾é”™è¯¯æç¤º")

    # æŸ¥æ‰¾ç¬”è®°é“¾æ¥
    print("\nğŸ” æŸ¥æ‰¾ç¬”è®°é“¾æ¥...")
    links = await page.evaluate('''
        () => {
            const result = [];

            // æŸ¥æ‰¾æ‰€æœ‰å¸¦ xsec_token çš„é“¾æ¥
            const allLinks = document.querySelectorAll('a[href*="xsec_token"]');

            console.log('æ‰¾åˆ°çš„æ‰€æœ‰å¸¦xsec_tokençš„é“¾æ¥æ•°é‡:', allLinks.length);

            allLinks.forEach(a => {
                result.push({
                    href: a.href,
                    text: a.textContent?.substring(0, 50) || ''
                });
            });

            return result;
        }
    ''')

    print(f"   æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥\n")

    if links:
        print("ğŸ“‹ å‰5ä¸ªé“¾æ¥:")
        for i, link in enumerate(links[:5], 1):
            print(f"   {i}. {link['href']}")
            print(f"      æ–‡æœ¬: {link['text'][:50]}...")

    # æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
    print("\nğŸ“œ æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹...")
    for i in range(3):
        try:
            await asyncio.sleep(2)
            await page.evaluate('window.scrollBy(0, window.innerHeight)')
            print(f"   æ»šåŠ¨ {i+1}/3")
        except Exception as e:
            print(f"   æ»šåŠ¨å¤±è´¥: {e}")
            break

    await asyncio.sleep(3)

    # å†æ¬¡æŸ¥æ‰¾é“¾æ¥
    print("\nğŸ” æ»šåŠ¨åå†æ¬¡æŸ¥æ‰¾ç¬”è®°é“¾æ¥...")
    links_after_scroll = await page.evaluate('''
        () => {
            const result = [];
            const allLinks = document.querySelectorAll('a[href*="xsec_token"]');

            allLinks.forEach(a => {
                result.push({
                    href: a.href,
                    text: a.textContent?.substring(0, 50) || ''
                });
            });

            return result;
        }
    ''')

    print(f"   æ‰¾åˆ° {len(links_after_scroll)} ä¸ªé“¾æ¥\n")

    if links_after_scroll:
        print("ğŸ“‹ å‰5ä¸ªé“¾æ¥:")
        for i, link in enumerate(links_after_scroll[:5], 1):
            print(f"   {i}. {link['href']}")
            print(f"      æ–‡æœ¬: {link['text'][:50]}...")

    # ä¿å­˜é¡µé¢HTMLç”¨äºè°ƒè¯•
    output_dir = PROJECT_DIR / "output" / "xhs_search_test"
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    html_file = output_dir / f"debug_{keyword}_{timestamp}.html"

    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(page_content)

    print(f"\nğŸ“ é¡µé¢HTMLå·²ä¿å­˜: {html_file}")

    # ä¿æŒæµè§ˆå™¨æ‰“å¼€ï¼ˆå¦‚æœä¸æ˜¯æ— å¤´æ¨¡å¼ï¼‰
    if not headless:
        print("\nâ³ æµè§ˆå™¨å°†ä¿æŒæ‰“å¼€60ç§’ï¼Œè¯·æŸ¥çœ‹é¡µé¢å†…å®¹...")
        await asyncio.sleep(60)

    # å…³é—­æµè§ˆå™¨
    await browser.close()
    await playwright.stop()
    print("\nâœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='å°çº¢ä¹¦æœç´¢æµ‹è¯•')
    parser.add_argument('--keyword', type=str, default='æ—…è¡Œ', help='æœç´¢å…³é”®è¯')
    parser.add_argument('--headless', action='store_true', help='ä½¿ç”¨æ— å¤´æ¨¡å¼')

    args = parser.parse_args()

    asyncio.run(search_xhs(args.keyword, args.headless))
