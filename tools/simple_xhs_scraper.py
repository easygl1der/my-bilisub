#!/usr/bin/env python3
"""
å°çº¢ä¹¦ç®€å•çˆ¬è™« - ç›´æ¥ä»HTMLæå–é“¾æ¥

åªåšä¸€ä»¶äº‹ï¼šç”¨Cookieè®¿é—®å°çº¢ä¹¦ï¼Œæå–é¡µé¢ä¸­å¸¦æœ‰xsec_tokençš„ç¬”è®°é“¾æ¥
"""

import sys
import json
from pathlib import Path
from playwright.async_api import async_playwright

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

PROJECT_DIR = Path(__file__).parent.parent


def read_xhs_cookie():
    """ä» config/cookies.txt è¯»å–å°çº¢ä¹¦Cookie"""
    cookie_file = PROJECT_DIR / "config" / "cookies.txt"
    if not cookie_file.exists():
        return {}

    with open(cookie_file, 'r', encoding='utf-8') as f:
        content = f.read()

    import re
    cookies_dict = {}

    # æŸ¥æ‰¾ [xiaohongshu] éƒ¨åˆ†
    xhs_section = re.search(r'\[xiaohongshu\](.*?)\[', content, re.DOTALL)
    if xhs_section:
        section = xhs_section.group(1)
        for line in section.split('\n'):
            line = line.strip()
            if '=' in line and not line.startswith('#'):
                key, value = line.split('=', 1)
                cookies_dict[key.strip()] = value.strip()

    return cookies_dict


async def extract_xhs_links_from_html():
    """ä»å°çº¢ä¹¦HTMLé¡µé¢æå–é“¾æ¥"""

    cookies_dict = read_xhs_cookie()
    if not cookies_dict:
        print("âŒ æœªæ‰¾åˆ°Cookieï¼Œè¯·åœ¨ config/cookies.txt ä¸­é…ç½®")
        return

    print("âœ… Cookieå·²è¯»å–")
    print(f"   a1: {cookies_dict.get('a1', '')[:20]}...")
    print()

    async with async_playwright() as p:
        print("ğŸŒ å¯åŠ¨æµè§ˆå™¨...")
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )

        # æ·»åŠ Cookie
        cookies_list = []
        for key, value in cookies_dict.items():
            if not key or not value:
                continue
            cookies_list.append({
                'name': key,
                'value': value,
                'domain': '.xiaohongshu.com',
                'path': '/',
            })

        try:
            await context.add_cookies(cookies_list)
            print(f"âœ… å·²æ·»åŠ  {len(cookies_list)} ä¸ª Cookie")
        except Exception as e:
            print(f"âš ï¸  æ·»åŠ Cookieæ—¶å‡ºé”™: {e}")

        page = await context.new_page()
        print("âœ… æµè§ˆå™¨å·²å¯åŠ¨")

        # è®¿é—®å°çº¢ä¹¦é¦–é¡µ
        print()
        print("ğŸ“„ è®¿é—®å°çº¢ä¹¦é¦–é¡µ...")
        try:
            await page.goto('https://www.xiaohongshu.com/', wait_until='networkidle', timeout=60000)
            await page.wait_for_timeout(5000)  # ç­‰å¾…5ç§’è®©å†…å®¹åŠ è½½
            print("âœ… é¡µé¢åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"âŒ é¡µé¢åŠ è½½å¤±è´¥: {e}")
            await browser.close()
            return

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        page_content = await page.content()
        if 'ç™»å½•' in page_content and 'æ³¨å†Œ' in page_content:
            print("âš ï¸  æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
            print("ğŸ’¡ è¯·æ›´æ–° Cookie")
            await browser.close()
            return

        # æå–æ‰€æœ‰ç¬”è®°é“¾æ¥
        print()
        print("=" * 70)
        print("  å¼€å§‹æå–é“¾æ¥")
        print("=" * 70)

        # æ–¹æ³•1: æå–æ‰€æœ‰å¸¦ xsec_token çš„é“¾æ¥
        links = await page.evaluate('''
            () => {
                const result = [];

                // æå–æ‰€æœ‰å¸¦ xsec_token çš„ explore é“¾æ¥
                const allLinks = document.querySelectorAll('a[href*="xsec_token"]');
                const seen = new Set();

                allLinks.forEach(a => {
                    const href = a.href;

                    // åªä¿ç•™ /explore/ å¼€å¤´çš„é“¾æ¥
                    if (href.includes('/explore/')) {
                        // æå–ç¬”è®°ID
                        const idMatch = href.match(/\\/explore\\/([a-f0-9]{32})/);
                        if (!idMatch) return;

                        const noteId = idMatch[1];

                        // æå– xsec_token
                        let xsecToken = '';
                        try {
                            const urlParams = new URLSearchParams(href.split('?')[1]);
                            xsecToken = urlParams.get('xsec_token') || '';
                        } catch (e) {}

                        // å»é‡
                        if (seen.has(noteId)) return;
                        seen.add(noteId);

                        result.push({
                            note_id: noteId,
                            full_url: href,
                            xsec_token: xsecToken
                        });
                    }
                });

                return result;
            }
        ''')

        print(f"\nâœ… æ‰¾åˆ° {len(links)} ä¸ªç¬”è®°é“¾æ¥\n")

        # è¾“å‡ºå®Œæ•´é“¾æ¥
        for i, link in enumerate(links, 1):
            print(link['full_url'])

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = PROJECT_DIR / "output" / "xhs_links.txt"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            for link in links:
                f.write(link['full_url'] + '\n')

        print("\n" + "=" * 70)
        print(f"ğŸ“ å·²ä¿å­˜åˆ°: {output_file}")
        print("=" * 70)

        await browser.close()


if __name__ == "__main__":
    import asyncio
    asyncio.run(extract_xhs_links_from_html())
