#!/usr/bin/env python3
"""
ç”¨æˆ·è§†é¢‘å†…å®¹åˆ†æå·¥å…· v2

åŠŸèƒ½ï¼š
1. è·å–ç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘é“¾æ¥ï¼ˆæ”¯æŒ Bç«™ å’Œ YouTubeï¼‰
2. æ‰¹é‡æå–è§†é¢‘å­—å¹•ï¼ˆSRT æ ¼å¼ï¼‰
3. ä½¿ç”¨ Gemini API åˆ†ææ¯ä¸ªè§†é¢‘çš„å†…å®¹
4. ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
    # Bç«™ç”¨æˆ· - è·å–æ‰€æœ‰è§†é¢‘
    python user_content_analyzer.py --user "https://space.bilibili.com/28554995" --all

    # åªä¸‹è½½å­—å¹•ï¼Œä¸åˆ†æ
    python user_content_analyzer.py --user "URL" --no-analysis
"""

import os
import sys
import asyncio
import json
import time
import requests
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import re

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ============================================================================
# é…ç½®åŒº
# ============================================================================

# Gemini API é…ç½®
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
DEFAULT_MODEL = "flash-lite"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path("user_analysis_output")

# å¹¶å‘è®¾ç½®
MAX_CONCURRENT_DOWNLOADS = 3
MAX_CONCURRENT_ANALYSIS = 5

# ============================================================================
# Bç«™ API éƒ¨åˆ†
# ============================================================================

try:
    from bilibili_api import video, Credential, user
    BILIBILI_API_AVAILABLE = True
except ImportError:
    BILIBILI_API_AVAILABLE = False

BILIBILI_COOKIE_FILE = Path(__file__).parent / "config" / "cookies_bilibili_api.txt"


# å…¨å±€ credentialï¼ˆåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
_bilibili_credential = None


def extract_user_id_from_url(user_url: str) -> Optional[str]:
    """ä» URL ä¸­æå–ç”¨æˆ· ID"""
    # åŒ¹é… space.bilibili.com/æ•°å­—
    match = re.search(r'space\.bilibili\.com\/(\d+)', user_url)
    if match:
        return match.group(1)
    return None


def get_bilibili_user_info_public(user_id: str) -> Optional[Dict]:
    """ä»ç”¨æˆ·é¡µé¢ HTML ä¸­æå–ç”¨æˆ·ä¿¡æ¯"""
    try:
        url = f"https://space.bilibili.com/{user_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        }
        response = requests.get(url, headers=headers, timeout=15)

        if response.status_code == 200:
            html = response.text

            # æ–¹æ³•1: å°è¯•ä» HTML ä¸­æå–ç”¨æˆ·å (å¤šç§å¯èƒ½çš„æ¨¡å¼)
            patterns = [
                r'"name":"([^"]+)"',  # JSON æ ¼å¼
                r'<title[^>]*>([^<]+?)çš„ä¸ªäººç©ºé—´',  # title æ ‡ç­¾
                r'<meta property="og:title" content="([^"]+)"',  # og:title
                r'class="[^"]*user-name[^"]*"[^>]*>([^<]+)',  # ç”¨æˆ·å class
                r'data-user-name="([^"]+)"',  # data å±æ€§
            ]

            for pattern in patterns:
                match = re.search(pattern, html)
                if match:
                    name = match.group(1).strip()
                    # è½¬ä¹‰ Unicode å­—ç¬¦
                    name = name.encode('utf-8').decode('unicode_escape')
                    # å»æ‰å¯èƒ½çš„åæ–œæ 
                    name = name.replace('\\', '')
                    if name and name != 'null':
                        return {
                            'name': name[:50],
                            'url': url,
                            'description': '',
                            'uid': user_id,
                        }

    except Exception as e:
        print(f"  ä»é¡µé¢è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")

    return None


def get_credential():
    """è·å– Bç«™ è®¤è¯å‡­æ®ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _bilibili_credential
    if _bilibili_credential is None:
        _bilibili_credential = load_bilibili_cookies()
    return _bilibili_credential


async def get_bilibili_user_info_api(user_url: str) -> Optional[Dict]:
    """ä½¿ç”¨ bilibili-api è·å–ç”¨æˆ·ä¿¡æ¯"""
    if not BILIBILI_API_AVAILABLE:
        return None

    user_id = extract_user_id_from_url(user_url)
    if not user_id:
        return None

    try:
        credential = get_credential()
        if not credential:
            return None

        from bilibili_api import user as bili_user
        u = bili_user.User(int(user_id), credential=credential)
        info = await u.get_user_info()

        return {
            'name': info.get('name', 'Unknown'),
            'url': user_url,
            'description': info.get('sign', '')[:500],
            'uid': user_id,
            'face': info.get('face', ''),
            'level': info.get('level', 0),
        }
    except Exception as e:
        print(f"  API è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
        return None


def load_bilibili_cookies():
    """åŠ è½½ Bç«™ Cookie"""
    cookies = {}
    if BILIBILI_COOKIE_FILE.exists():
        with open(BILIBILI_COOKIE_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "\t" in line:
                    parts = line.split("\t")
                    if len(parts) >= 7:
                        name = parts[5].strip()
                        value = parts[6].strip()
                        cookies[name] = value

    sessdata = cookies.get("SESSDATA", "")
    bili_jct = cookies.get("bili_jct", "")
    buvid3 = cookies.get("buvid3", "")

    if not sessdata:
        print("è­¦å‘Š: æœªæ‰¾åˆ° SESSDATA")

    return Credential(
        sessdata=sessdata,
        bili_jct=bili_jct,
        buvid3=buvid3
    ) if sessdata else None


def get_bilibili_user_videos_ytdlp(user_url: str, fetch_full_info: bool = False) -> Tuple[List[Dict], Dict]:
    """ä½¿ç”¨ yt-dlp è·å– Bç«™ç”¨æˆ·è§†é¢‘å’Œè¯¦ç»†ä¿¡æ¯

    Args:
        user_url: Bç«™ç”¨æˆ·é¡µé¢ URL
        fetch_full_info: æ˜¯å¦è·å–æ¯ä¸ªè§†é¢‘çš„å®Œæ•´ä¿¡æ¯ï¼ˆè¾ƒæ…¢ï¼‰
    """
    if not YT_DLP_AVAILABLE:
        raise ImportError("éœ€è¦å®‰è£… yt-dlp")

    # é¦–å…ˆè·å–ç”¨æˆ·ID
    user_id = extract_user_id_from_url(user_url)
    if not user_id:
        return [], {}

    user_info = {'name': f'User_{user_id}', 'url': user_url}

    # ç¬¬ä¸€æ­¥ï¼šè·å–è§†é¢‘åˆ—è¡¨ (ä½¿ç”¨ extract_flat)
    ydl_opts_flat = {
        'quiet': True,
        'extract_flat': True,
        'cookiefile': str(BILIBILI_COOKIE_FILE) if BILIBILI_COOKIE_FILE.exists() else None,
        'playlistend': 1000,
    }

    video_ids = []
    try:
        with yt_dlp.YoutubeDL(ydl_opts_flat) as ydl:
            info = ydl.extract_info(user_url, download=False)

            # å°è¯•è·å–ç”¨æˆ·å
            uploader = info.get('uploader') or info.get('channel') or info.get('title')
            if uploader and uploader != 'Unknown':
                user_info['name'] = uploader

            if 'entries' in info:
                for entry in info['entries']:
                    if entry:
                        video_ids.append(entry.get('id') or entry.get('bvid'))
            else:
                video_ids.append(info.get('id') or info.get('bvid'))
    except Exception as e:
        print(f"  è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
        return [], user_info

    print(f"  æ‰¾åˆ° {len(video_ids)} ä¸ªè§†é¢‘ ID")

    # ç¬¬äºŒæ­¥ï¼šè·å–æ¯ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if fetch_full_info:
        print(f"  æ­£åœ¨è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯...")
        videos = []
        ydl_opts_full = {
            'quiet': True,
            'cookiefile': str(BILIBILI_COOKIE_FILE) if BILIBILI_COOKIE_FILE.exists() else None,
        }

        for i, bvid in enumerate(video_ids):
            if not bvid:
                continue
            video_url = f"https://www.bilibili.com/video/{bvid}"
            try:
                with yt_dlp.YoutubeDL(ydl_opts_full) as ydl:
                    vinfo = ydl.extract_info(video_url, download=False)
                    videos.append({
                        'bvid': bvid,
                        'title': (vinfo.get('title') or 'Unknown').strip()[:100],
                        'url': video_url,
                        'duration': vinfo.get('duration') or 0,
                        'view_count': vinfo.get('view_count') or 0,
                        'upload_date': vinfo.get('upload_date', ''),
                        'duration_string': vinfo.get('duration_string', '') or format_duration(vinfo.get('duration', 0)),
                    })
                if (i + 1) % 10 == 0:
                    print(f"    è¿›åº¦: {i + 1}/{len(video_ids)}")
            except Exception as e:
                # å¦‚æœå•ä¸ªè§†é¢‘è·å–å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                videos.append({
                    'bvid': bvid,
                    'title': f"Video_{bvid}",
                    'url': video_url,
                    'duration': 0,
                    'view_count': 0,
                })
    else:
        # ä¸è·å–è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
        videos = []
        for bvid in video_ids:
            if bvid:
                videos.append({
                    'bvid': bvid,
                    'title': f"Video_{bvid}",
                    'url': f"https://www.bilibili.com/video/{bvid}",
                    'duration': 0,
                    'view_count': 0,
                })

    return videos, user_info


async def get_bilibili_subtitle(bvid: str, credential, output_dir: Path) -> Optional[Path]:
    """è·å– Bç«™è§†é¢‘å­—å¹•"""
    try:
        from bilibili_api import video as bili_video
    except ImportError:
        return None

    v = bili_video.Video(bvid=bvid, credential=credential)

    try:
        info = await v.get_info()
        title = info.get('title', 'unknown').strip()
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stat = info.get('stat', {})
        view_count = stat.get('view', 0)
        cid = info['cid']
    except Exception as e:
        return None

    # æ¸…ç†æ–‡ä»¶å
    safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:80]

    try:
        player_info = await v.get_player_info(cid=cid)
        subtitles = player_info.get("subtitle", {}).get("subtitles", [])

        if not subtitles:
            return None

        # ä¸‹è½½ç¬¬ä¸€æ¡å­—å¹•
        subtitle_data = subtitles[0]

        import aiohttp
        url = "https:" + subtitle_data["subtitle_url"]
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as resp:
                data = await resp.json(content_type=None)

        # ä¿å­˜ä¸º SRT
        srt_path = output_dir / f"{safe_title}.srt"
        with open(srt_path, "w", encoding="utf-8") as f:
            for i, item in enumerate(data.get("body", []), 1):
                start = format_srt_time(item['from'])
                end = format_srt_time(item['to'])
                f.write(f"{i}\n{start} --> {end}\n{item['content']}\n\n")

        # è¿”å›å¸¦ç»Ÿè®¡ä¿¡æ¯çš„ç»“æœ
        return {
            'path': srt_path,
            'title': title,
            'view_count': view_count,
            'subtitle_count': len(data.get("body", [])),
        }

    except Exception:
        return None


def format_srt_time(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´ç æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def format_duration(seconds: int) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸ºå¯è¯»æ—¶é•¿"""
    if not seconds:
        return "æœªçŸ¥"
    seconds = int(seconds)  # ç¡®ä¿æ˜¯æ•´æ•°
    minutes = seconds // 60
    secs = seconds % 60
    return f"{minutes}:{secs:02d}"


def format_view_count(count: int) -> str:
    """æ ¼å¼åŒ–æ’­æ”¾é‡"""
    if not count:
        return "0"
    if count >= 10000:
        return f"{count / 10000:.1f}ä¸‡"
    return str(count)


# ============================================================================
# YouTube éƒ¨åˆ†
# ============================================================================

try:
    from youtube_transcript_api import YouTubeTranscriptApi
    YOUTUBE_AVAILABLE = True
except ImportError:
    YOUTUBE_AVAILABLE = False

try:
    import yt_dlp
    YT_DLP_AVAILABLE = True
except ImportError:
    YT_DLP_AVAILABLE = False


# ============================================================================
# Gemini åˆ†æéƒ¨åˆ†
# ============================================================================

try:
    import google.generativeai as genai
    import warnings
    warnings.filterwarnings("ignore", category=FutureWarning)
    GEMINI_AVAILABLE = True
except ImportError:
    try:
        from google import genai
        GEMINI_AVAILABLE = True
    except ImportError:
        GEMINI_AVAILABLE = False


# é»˜è®¤æç¤ºè¯
ANALYSIS_PROMPTS = {
    'brief': """è¯·ç”¨ä¸­æ–‡ç®€æ´æ€»ç»“è¿™ä¸ªè§†é¢‘å­—å¹•çš„æ ¸å¿ƒå†…å®¹ï¼ˆ200å­—ä»¥å†…ï¼‰ã€‚""",

    'summary': """è¯·ç”¨ä¸­æ–‡è¯¦ç»†æ€»ç»“è¿™ä¸ªè§†é¢‘å­—å¹•çš„ä¸»è¦å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. è§†é¢‘çš„ä¸»é¢˜å’Œæ ¸å¿ƒè§‚ç‚¹
2. ä¸»è¦è®¨è®ºçš„é—®é¢˜æˆ–è¯é¢˜
3. å…³é”®ä¿¡æ¯å’Œäº®ç‚¹""",

    'knowledge': """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿å°†è§†é¢‘å†…å®¹è½¬åŒ–ä¸ºç»“æ„åŒ–çš„çŸ¥è¯†åº“ç¬”è®°ã€‚è¯·è¯¦ç»†åˆ†æè¿™ä¸ªè§†é¢‘çš„å­—å¹•å†…å®¹ï¼Œè¾“å‡ºç”¨äºæ„å»º"ç¬¬äºŒå¤§è„‘"çš„ç¬”è®°ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ğŸ“‹ è§†é¢‘åŸºæœ¬ä¿¡æ¯
- **æ ¸å¿ƒä¸»é¢˜**: [ä¸€å¥è¯æ¦‚æ‹¬]
- **å†…å®¹ç±»å‹**: [æ•™è‚²è¯¾ç¨‹/çŸ¥è¯†ç§‘æ™®/æ–°é—»è¯„è®º/äº§å“æµ‹è¯„/Vlog/å…¶ä»–]

## ğŸ“– è§†é¢‘å¤§æ„ï¼ˆ100-200å­—ï¼‰
[ç”¨ç²¾ç‚¼çš„ä¹¦é¢è¯­è¨€æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹]

## ğŸ¯ æ ¸å¿ƒè§‚ç‚¹
1. [è§‚ç‚¹1]
   - è®ºè¿°å†…å®¹: [è¯¦ç»†è¯´æ˜]
   - æ”¯æŒè®ºæ®: [æ•°æ®ã€æ¡ˆä¾‹ã€é€»è¾‘æ¨ç†]

2. [è§‚ç‚¹2]
   - è®ºè¿°å†…å®¹: [è¯¦ç»†è¯´æ˜]
   - æ”¯æŒè®ºæ®: [æ•°æ®ã€æ¡ˆä¾‹ã€é€»è¾‘æ¨ç†]

## ğŸ’ é‡‘å¥/å¥½è¯å¥½å¥æå–
- "é‡‘å¥å†…å®¹"
- "é‡‘å¥å†…å®¹"

## ğŸ“ æ€»ç»“
[æ€»ç»“è¯„ä»·ï¼Œå€¼å¾—å­¦ä¹ çš„åœ°æ–¹]"""
}


def analyze_subtitle_with_gemini(srt_path: Path, mode: str = "knowledge", model: str = "flash-lite") -> Optional[str]:
    """ä½¿ç”¨ Gemini åˆ†æå­—å¹•æ–‡ä»¶"""
    if not GEMINI_AVAILABLE:
        return None

    if not GEMINI_API_KEY:
        return None

    genai.configure(api_key=GEMINI_API_KEY)

    # è¯»å–å­—å¹•å†…å®¹
    with open(srt_path, "r", encoding="utf-8") as f:
        srt_content = f.read()

    # å¦‚æœå­—å¹•å¤ªé•¿ï¼Œåˆ†æ®µå¤„ç†
    if len(srt_content) > 100000:
        srt_content = srt_content[:100000] + "\n\n...(å­—å¹•è¿‡é•¿ï¼Œå·²æˆªæ–­)"

    prompt = ANALYSIS_PROMPTS.get(mode, ANALYSIS_PROMPTS['summary'])
    full_prompt = f"""ä»¥ä¸‹æ˜¯è§†é¢‘çš„å­—å¹•å†…å®¹ï¼ˆSRTæ ¼å¼ï¼‰ï¼š

```
{srt_content}
```

{prompt}

è¯·ç›´æ¥è¾“å‡ºåˆ†æç»“æœï¼Œä¸è¦é‡å¤å­—å¹•å†…å®¹ã€‚"""

    model_names = {
        'flash-lite': 'models/gemini-2.5-flash-lite',
        'flash': 'models/gemini-2.5-flash',
        'pro': 'models/gemini-2.5-pro',
    }

    try:
        gemini_model = genai.GenerativeModel(model_names.get(model, model_names['flash-lite']))
        response = gemini_model.generate_content(full_prompt)
        return response.text
    except Exception:
        return None


# ============================================================================
# ä¸»åˆ†æå™¨
# ============================================================================

class UserContentAnalyzer:
    """ç”¨æˆ·å†…å®¹åˆ†æå™¨"""

    def __init__(self, base_dir: Path = None):
        self.base_dir = base_dir or OUTPUT_DIR
        self.base_dir.mkdir(parents=True, exist_ok=True)

        self.print_lock = threading.Lock()
        self.start_time = None

    def get_user_folder_name(self, user_info: Dict) -> str:
        """ç”Ÿæˆç”¨æˆ·æ–‡ä»¶å¤¹åç§°"""
        name = user_info.get('name', 'Unknown')
        # æ¸…ç†æ–‡ä»¶å¤¹åç§°
        safe_name = re.sub(r'[<>:"/\\|?*]', '_', name)[:50]
        return safe_name

    def setup_user_directory(self, user_info: Dict) -> Path:
        """è®¾ç½®ç”¨æˆ·ä¸“å±ç›®å½•"""
        folder_name = self.get_user_folder_name(user_info)
        user_dir = self.base_dir / folder_name
        user_dir.mkdir(exist_ok=True)

        subtitle_dir = user_dir / "subtitles"
        analysis_dir = user_dir / "analysis"
        subtitle_dir.mkdir(exist_ok=True)
        analysis_dir.mkdir(exist_ok=True)

        return user_dir, subtitle_dir, analysis_dir

    def get_videos_and_info(self, user_url: str, fetch_full_info: bool = False) -> Tuple[List[Dict], Dict]:
        """è·å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨å’Œä¿¡æ¯

        Args:
            user_url: ç”¨æˆ·é¡µé¢ URL
            fetch_full_info: æ˜¯å¦è·å–æ¯ä¸ªè§†é¢‘çš„å®Œæ•´ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æ’­æ”¾é‡ç­‰ï¼‰
        """
        print(f"è·å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨...")

        if 'bilibili.com' in user_url:
            # ä¼˜å…ˆä½¿ç”¨å…¬å¼€ API è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆä¸éœ€è¦ç™»å½•ï¼‰
            user_id = extract_user_id_from_url(user_url)
            user_info = None

            if user_id:
                # æ–¹æ³•1: ä½¿ç”¨å…¬å¼€ APIï¼ˆæœ€å¯é ï¼‰
                user_info = get_bilibili_user_info_public(user_id)
                if user_info:
                    print(f"  ç”¨æˆ·å: {user_info.get('name')}")

            # å¦‚æœå…¬å¼€APIå¤±è´¥ï¼Œå°è¯• bilibili_api
            if not user_info and BILIBILI_API_AVAILABLE:
                try:
                    user_info = asyncio.run(get_bilibili_user_info_api(user_url))
                    if user_info:
                        print(f"  ç”¨æˆ·å: {user_info.get('name')}")
                except Exception as e:
                    print(f"  bilibili_api è·å–å¤±è´¥: {e}")

            # è·å–è§†é¢‘åˆ—è¡¨
            videos, ytdlp_user_info = get_bilibili_user_videos_ytdlp(user_url, fetch_full_info=fetch_full_info)

            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨ yt-dlp çš„ç»“æœ
            if not user_info:
                user_info = ytdlp_user_info
                print(f"  ç”¨æˆ·å: {user_info.get('name')}")

        elif 'youtube.com' in user_url or 'youtu.be' in user_url:
            # YouTube æ”¯æŒ
            ydl_opts = {'quiet': True, 'extract_flat': True}
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(user_url, download=False)
                user_info = {'name': info.get('uploader', 'Unknown')}
                videos = []
                if 'entries' in info:
                    for entry in info['entries']:
                        if entry:
                            videos.append({
                                'id': entry.get('id'),
                                'title': entry.get('title', 'Unknown'),
                                'url': entry.get('url'),
                                'duration': entry.get('duration'),
                                'view_count': entry.get('view_count'),
                            })
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¹³å°: {user_url}")

        print(f"  æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
        return videos, user_info

    def download_subtitle(self, bvid: str, title: str, subtitle_dir: Path) -> Optional[Dict]:
        """ä¸‹è½½å•ä¸ªè§†é¢‘å­—å¹•"""
        if not BILIBILI_API_AVAILABLE:
            return None

        credential = get_credential()
        if not credential:
            return None

        try:
            result = asyncio.run(get_bilibili_subtitle(bvid, credential, subtitle_dir))
            if result and isinstance(result, dict):
                return result
            elif result and isinstance(result, Path):
                return {'path': result, 'title': title}
        except Exception:
            pass
        return None

    def download_all_subtitles(self, videos: List[Dict], subtitle_dir: Path) -> List[Dict]:
        """æ‰¹é‡ä¸‹è½½æ‰€æœ‰å­—å¹•"""
        print(f"\nå¼€å§‹ä¸‹è½½ {len(videos)} ä¸ªè§†é¢‘çš„å­—å¹•...")

        results = []
        failed = []

        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_DOWNLOADS) as executor:
            futures = {}
            for i, video in enumerate(videos):
                bvid = video.get('bvid')
                title = video.get('title')
                if bvid:
                    future = executor.submit(self.download_subtitle, bvid, title, subtitle_dir)
                    futures[future] = video

            for future in as_completed(futures):
                result = future.result()
                video = futures[future]
                if result:
                    results.append({**video, **result})
                    print(f"  âœ“ [{video.get('title', 'Unknown')[:30]}...]")
                else:
                    failed.append(video)
                    print(f"  âœ— [{video.get('title', 'Unknown')[:30]}...] æ— å­—å¹•")

        print(f"\nå­—å¹•ä¸‹è½½å®Œæˆ: {len(results)}/{len(videos)}")
        return results

    def analyze_subtitle(self, srt_path: Path, title: str, analysis_dir: Path, mode: str, model: str) -> Optional[str]:
        """åˆ†æå•ä¸ªå­—å¹•æ–‡ä»¶"""
        with self.print_lock:
            print(f"  åˆ†æ: {title[:30]}...")

        result = analyze_subtitle_with_gemini(srt_path, mode, model)

        if result:
            safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:80]
            output_path = analysis_dir / f"{safe_title}_analysis.md"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(f"# {title}\n\n")
                f.write(f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("---\n\n")
                f.write(result)

            with self.print_lock:
                print(f"    âœ“ åˆ†æå®Œæˆ")
            return str(output_path)

        return None

    def analyze_all_subtitles(self, subtitle_dir: Path, analysis_dir: Path, mode: str, model: str) -> List[Path]:
        """åˆ†ææ‰€æœ‰å­—å¹•æ–‡ä»¶"""
        srt_files = list(subtitle_dir.glob("*.srt"))
        if not srt_files:
            return []

        print(f"\nå¼€å§‹åˆ†æ {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶...")

        results = []
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_ANALYSIS) as executor:
            futures = {}
            for srt_path in srt_files:
                title = srt_path.stem
                future = executor.submit(self.analyze_subtitle, srt_path, title, analysis_dir, mode, model)
                futures[future] = srt_path

            for future in as_completed(futures):
                result = future.result()
                if result:
                    results.append(Path(result))

        print(f"\nåˆ†æå®Œæˆ: {len(results)}/{len(srt_files)}")
        return results

    def generate_summary_report(self, user_dir: Path, user_info: Dict, videos: List[Dict],
                               subtitle_results: List[Dict], analysis_results: List[Path],
                               elapsed_time: float) -> Path:
        """ç”Ÿæˆç”¨æˆ·åˆ†ææ€»ç»“æŠ¥å‘Š"""
        report_path = user_dir / "00_ç”¨æˆ·åˆ†ææŠ¥å‘Š.md"

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_videos = len(videos)
        total_subtitles = len(subtitle_results)
        total_views = sum(v.get('view_count', 0) for v in videos if v.get('view_count'))

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(f"# {user_info.get('name', 'Unknown')} - ç”¨æˆ·åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**ç”¨æˆ·é“¾æ¥**: {user_info.get('url', 'N/A')}\n\n")
            f.write("---\n\n")

            # æ¦‚è§ˆ
            f.write("## ğŸ“Š æ¦‚è§ˆç»Ÿè®¡\n\n")
            f.write(f"- **è§†é¢‘æ€»æ•°**: {total_videos} ä¸ª\n")
            f.write(f"- **æœ‰å­—å¹•è§†é¢‘**: {total_subtitles} ä¸ª\n")
            f.write(f"- **æ€»æ’­æ”¾é‡**: {format_view_count(total_views)} æ¬¡\n")
            f.write(f"- **çˆ¬å–è€—æ—¶**: {format_elapsed_time(elapsed_time)}\n")
            f.write(f"- **åˆ†ææ•°é‡**: {len(analysis_results)} ä¸ª\n\n")

            # è§†é¢‘åˆ—è¡¨
            f.write("## ğŸ“¹ è§†é¢‘åˆ—è¡¨\n\n")

            # æŒ‰æ’­æ”¾é‡æ’åº (ç¡®ä¿ view_count æ˜¯æœ‰æ•ˆæ•°å­—)
            sorted_videos = sorted(videos, key=lambda x: (x.get('view_count') or 0), reverse=True)

            for i, video in enumerate(sorted_videos, 1):
                title = video.get('title', 'Unknown')
                url = video.get('url', '')
                views = format_view_count(video.get('view_count', 0))
                duration = video.get('duration_string', format_duration(video.get('duration', 0)))
                has_subtitle = any(s.get('bvid') == video.get('bvid') or s.get('title') == title for s in subtitle_results)

                f.write(f"### {i}. {title}\n\n")
                f.write(f"- **é“¾æ¥**: {url}\n")
                f.write(f"- **æ’­æ”¾é‡**: {views}\n")
                f.write(f"- **æ—¶é•¿**: {duration}\n")
                f.write(f"- **å­—å¹•**: {'âœ… æœ‰' if has_subtitle else 'âŒ æ— '}\n")
                f.write("\n")

            # å†…å®¹åˆ†ææ±‡æ€»
            if analysis_results:
                f.write("## ğŸ“ å†…å®¹åˆ†ææ±‡æ€»\n\n")
                for analysis_path in sorted(analysis_results):
                    if analysis_path.exists():
                        title = analysis_path.stem.replace('_analysis', '')
                        f.write(f"### {title}\n\n")
                        with open(analysis_path, "r", encoding="utf-8") as af:
                            # è·³è¿‡æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯ï¼Œåªä¿ç•™æ ¸å¿ƒå†…å®¹
                            lines = af.readlines()
                            in_content = False
                            content_lines = []
                            for line in lines:
                                if line.startswith("##"):
                                    in_content = True
                                if in_content:
                                    content_lines.append(line)
                            if content_lines:
                                f.write(''.join(content_lines))
                                f.write("\n\n")

        return report_path


def format_elapsed_time(seconds: float) -> str:
    """æ ¼å¼åŒ–è€—æ—¶"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        mins = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{mins}åˆ†{secs}ç§’"
    else:
        hours = int(seconds // 3600)
        mins = int((seconds % 3600) // 60)
        return f"{hours}å°æ—¶{mins}åˆ†"


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="ç”¨æˆ·è§†é¢‘å†…å®¹åˆ†æå·¥å…· v2",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # Bç«™ç”¨æˆ· - è·å–æ‰€æœ‰è§†é¢‘
  python user_content_analyzer.py --user "https://space.bilibili.com/28554995" --all

  # åªä¸‹è½½å­—å¹•ï¼Œä¸åˆ†æ
  python user_content_analyzer.py --user "URL" --no-analysis

  # åˆ†æå·²æœ‰å­—å¹•ç›®å½•
  python user_content_analyzer.py --dir "user_folder"
        """
    )

    parser.add_argument("--user", "-u", help="ç”¨æˆ·/é¢‘é“é“¾æ¥")
    parser.add_argument("--dir", "-d", help="åˆ†æå·²æœ‰å­—å¹•ç›®å½•")
    parser.add_argument("--mode", "-m", default="brief",
                       choices=["brief", "summary", "knowledge"],
                       help="åˆ†ææ¨¡å¼ (é»˜è®¤: brief)")
    parser.add_argument("--model", default="flash-lite",
                       choices=["flash-lite", "flash", "pro"],
                       help="Gemini æ¨¡å‹ (é»˜è®¤: flash-lite)")
    parser.add_argument("--no-analysis", action="store_true",
                       help="åªä¸‹è½½å­—å¹•ï¼Œä¸è¿›è¡Œåˆ†æ")
    parser.add_argument("--all", action="store_true",
                       help="è·å–æ‰€æœ‰è§†é¢‘ï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰")
    parser.add_argument("--full-info", action="store_true",
                       help="è·å–å®Œæ•´è§†é¢‘ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æ’­æ”¾é‡ç­‰ï¼Œè¾ƒæ…¢ä½†æ›´å‡†ç¡®ï¼‰")

    args = parser.parse_args()

    analyzer = UserContentAnalyzer()

    if args.user:
        # åˆ†æç”¨æˆ·
        analyzer.start_time = time.time()

        print("=" * 60)
        print("ç”¨æˆ·è§†é¢‘å†…å®¹åˆ†æå·¥å…· v2")
        print("=" * 60)
        print(f"ç”¨æˆ·é“¾æ¥: {args.user}")
        print("=" * 60)

        # è·å–è§†é¢‘åˆ—è¡¨
        videos, user_info = analyzer.get_videos_and_info(args.user, fetch_full_info=args.full_info)

        if not videos:
            print("æœªæ‰¾åˆ°è§†é¢‘")
            return

        # åˆ›å»ºç”¨æˆ·ç›®å½•
        user_dir, subtitle_dir, analysis_dir = analyzer.setup_user_directory(user_info)
        print(f"è¾“å‡ºç›®å½•: {user_dir}")

        # ä¸‹è½½å­—å¹•
        subtitle_results = analyzer.download_all_subtitles(videos, subtitle_dir)

        # åˆ†æå­—å¹•
        analysis_results = []
        if not args.no_analysis and subtitle_results:
            analysis_results = analyzer.analyze_all_subtitles(subtitle_dir, analysis_dir, args.mode, args.model)

        # ç”ŸæˆæŠ¥å‘Š
        elapsed_time = time.time() - analyzer.start_time
        report_path = analyzer.generate_summary_report(
            user_dir, user_info, videos, subtitle_results, analysis_results, elapsed_time
        )

        print("\n" + "=" * 60)
        print("âœ… ä»»åŠ¡å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {user_dir}")
        print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_path.name}")
        print("=" * 60)

    elif args.dir:
        # åˆ†æå·²æœ‰ç›®å½•
        dir_path = Path(args.dir)
        subtitle_dir = dir_path / "subtitles"
        analysis_dir = dir_path / "analysis"

        analyzer.analyze_all_subtitles(subtitle_dir, analysis_dir, args.mode, args.model)

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
