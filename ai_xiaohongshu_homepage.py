#!/usr/bin/env python3
"""
AIè‡ªåŠ¨åˆ·å°çº¢ä¹¦æ¨èå¹¶æ€»ç»“

ä¸€é”®å®Œæˆï¼š
1. åˆ·æ–°å°çº¢ä¹¦æ¨èé¡µï¼ˆè‡ªå®šä¹‰æ¬¡æ•°ï¼‰
2. é‡‡é›†æ¨èå†…å®¹ï¼ˆè§†é¢‘/å›¾æ–‡ã€ä½œè€…ä¿¡æ¯ï¼‰
3. å¯¼å‡ºCSV
4. AIç”Ÿæˆåˆ†ææŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
    python ai_xiaohongshu_homepage.py
"""

import argparse
import asyncio
import sys
import csv
import re
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from playwright.async_api import async_playwright

# ==================== è·¯å¾„é…ç½® ====================
PROJECT_DIR = Path(__file__).parent
OUTPUT_DIR = PROJECT_DIR / "output" / "xiaohongshu_homepage"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ==================== Cookie è¯»å– ====================
def read_xhs_cookie():
    """ä» config/cookies.txt è¯»å–å°çº¢ä¹¦Cookie"""
    cookie_file = PROJECT_DIR / "config" / "cookies.txt"
    if not cookie_file.exists():
        print("âŒ Cookieæ–‡ä»¶ä¸å­˜åœ¨: config/cookies.txt")
        return ""

    with open(cookie_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŸ¥æ‰¾ xiaohongshu_full= æ ¼å¼
    match = re.search(r'xiaohongshu_full=([^\n]+)', content)
    if match:
        return match.group(1)

    # æŸ¥æ‰¾ [xiaohongshu] éƒ¨åˆ†
    xhs_section = re.search(r'\[xiaohongshu\](.*?)\[', content, re.DOTALL)
    if xhs_section:
        section = xhs_section.group(1)
        cookies = []
        for line in section.split('\n'):
            line = line.strip()
            if '=' in line and not line.startswith('#'):
                key, value = line.split('=', 1)
                cookies.append(f"{key.strip()}={value.strip()}")
        return '; '.join(cookies)

    return ""


# ==================== Playwright é‡‡é›† ====================
async def scrape_xiaohongshu_homepage(
    refresh_count: int = 3,
    max_notes: int = 50,
    cookie: str = ""
) -> list:
    """ä½¿ç”¨Playwrightçˆ¬å–å°çº¢ä¹¦æ¨èé¡µ"""
    notes_collected = []
    seen_urls = set()

    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )

        # è®¾ç½®Cookie
        if cookie:
            try:
                cookies = []
                for item in cookie.split(';'):
                    item = item.strip()
                    if '=' in item:
                        key, value = item.split('=', 1)
                        cookies.append({
                            'name': key,
                            'value': value,
                            'domain': '.xiaohongshu.com',
                            'path': '/'
                        })
                await context.add_cookies(cookies)
                print("âœ… Cookieå·²è®¾ç½®")
            except Exception as e:
                print(f"âš ï¸  Cookieè®¾ç½®å¤±è´¥: {e}")

        page = await context.new_page()

        print(f"\nğŸ“¡ è®¿é—®å°çº¢ä¹¦é¦–é¡µ...")
        try:
            await page.goto('https://www.xiaohongshu.com/', wait_until='domcontentloaded', timeout=60000)
            await asyncio.sleep(5)
        except Exception as e:
            print(f"âš ï¸  é¡µé¢åŠ è½½é—®é¢˜: {e}")
            print("ğŸ’¡ æµè§ˆå™¨å·²æ‰“å¼€ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        page_content = await page.content()
        if 'ç™»å½•' in page_content and 'æ³¨å†Œ' in page_content:
            print("\nâš ï¸  æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
            print("ğŸ’¡ è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•")
            print("â³ ç­‰å¾…90ç§’...ç™»å½•å®Œæˆåä¼šè‡ªåŠ¨ç»§ç»­")
            await asyncio.sleep(90)
            print("âœ… ç»§ç»­æ‰§è¡Œ...")

        print(f"\nğŸ”„ å¼€å§‹é‡‡é›†æ¨èå†…å®¹ï¼ˆåˆ·æ–°{refresh_count}æ¬¡ï¼‰...")

        for i in range(refresh_count):
            print(f"\n  åˆ·æ–° {i+1}/{refresh_count}")

            # æ»šåŠ¨åŠ è½½
            for scroll in range(10):
                await page.evaluate('window.scrollBy(0, window.innerHeight)')
                await asyncio.sleep(1)

            # ç­‰å¾…å†…å®¹åŠ è½½
            await asyncio.sleep(2)

            # è·å–æ‰€æœ‰é“¾æ¥å’Œä¿¡æ¯
            try:
                notes_data = await page.evaluate('''
                    () => {
                        const notes = [];
                        const seen = new Set();

                        // æŸ¥æ‰¾æ‰€æœ‰ç¬”è®°å¡ç‰‡
                        const cards = document.querySelectorAll('section, section > div');

                        cards.forEach(card => {
                            const link = card.querySelector('a[href*="/explore/"]');
                            if (!link) return;

                            const url = link.href;
                            const idMatch = url.match(/\\/explore\\/([a-f0-9]+)/);
                            if (!idMatch) return;
                            const noteId = idMatch[1];

                            if (seen.has(noteId)) return;
                            seen.add(noteId);

                            // å°è¯•è·å–æ ‡é¢˜
                            let title = "æ— æ ‡é¢˜";
                            const titleElems = card.querySelectorAll('span, div[class*="title"]');
                            for (const elem of titleElems) {
                                const text = elem.textContent?.trim();
                                if (text && text.length > 3 && text.length < 100) {
                                    title = text.substring(0, 50);
                                    break;
                                }
                            }

                            // å°è¯•è·å–ä½œè€…
                            let author = "æœªçŸ¥ä½œè€…";
                            const authorElems = card.querySelectorAll('span[class*="user"], span[class*="name"]');
                            for (const elem of authorElems) {
                                const text = elem.textContent?.trim();
                                if (text && text.length > 1 && text.length < 30) {
                                    author = text;
                                    break;
                                }
                            }

                            // åˆ¤æ–­ç±»å‹
                            const hasVideo = card.querySelector('video');
                            const type = hasVideo ? 'video' : 'image';

                            notes.push({
                                url: url,
                                noteId: noteId,
                                title: title,
                                author: author,
                                type: type
                            });
                        });

                        return notes;
                    }
                ''')

                print(f"    æ‰¾åˆ° {len(notes_data)} ä¸ªç¬”è®°")

                for note in notes_data:
                    note_id = note['noteId']

                    # å»é‡
                    if note_id in seen_urls:
                        continue
                    seen_urls.add(note_id)

                    note_data = {
                        'åºå·': len(notes_collected) + 1,
                        'æ ‡é¢˜': note['title'],
                        'é“¾æ¥': note['url'],
                        'ç¬”è®°ID': note_id,
                        'ä½œè€…': note['author'],
                        'ç‚¹èµæ•°': '0',
                        'ç±»å‹': note['type'],
                        'é‡‡é›†æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }

                    notes_collected.append(note_data)
                    print(f"    âœ“ [{len(notes_collected)}] {note['type']} - {note['title']}")

                    if len(notes_collected) >= max_notes:
                        break

            except Exception as e:
                print(f"    âš ï¸  è§£æå‡ºé”™: {e}")

            # åˆ·æ–°
            if i < refresh_count - 1:
                print("    åˆ·æ–°é¡µé¢...")
                await page.reload(wait_until='domcontentloaded', timeout=60000)
                await asyncio.sleep(3)

        await browser.close()

    print(f"\nâœ… é‡‡é›†å®Œæˆï¼å…±è·å– {len(notes_collected)} ä¸ªç¬”è®°")
    return notes_collected


# ==================== CSVå¯¼å‡º ====================
def export_to_csv(notes, output_path):
    """å¯¼å‡ºç¬”è®°åˆ°CSV"""
    csv_columns = ['åºå·', 'æ ‡é¢˜', 'é“¾æ¥', 'ç¬”è®°ID', 'ä½œè€…', 'ç‚¹èµæ•°', 'ç±»å‹', 'é‡‡é›†æ—¶é—´']

    with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=csv_columns)
        writer.writeheader()
        writer.writerows(notes)

    print(f"ğŸ“ CSVå·²ä¿å­˜: {output_path}")


# ==================== ä¸»ç¨‹åº ====================
async def main():
    parser = argparse.ArgumentParser(description='AIè‡ªåŠ¨åˆ·å°çº¢ä¹¦æ¨èå¹¶æ€»ç»“')

    parser.add_argument('--refresh-count', type=int, default=3,
                       help='åˆ·æ–°æ¬¡æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    parser.add_argument('--max-notes', type=int, default=50,
                       help='æœ€å¤šé‡‡é›†ç¬”è®°æ•°ï¼ˆé»˜è®¤: 50ï¼‰')
    parser.add_argument('--mode', type=str, default='scrape',
                       choices=['scrape', 'full'],
                       help='æ¨¡å¼: scrape=ä»…é‡‡é›†, full=é‡‡é›†+AIåˆ†æ')

    args = parser.parse_args()

    print(f"\n{'='*70}")
    print(f"  AIè‡ªåŠ¨åˆ·å°çº¢ä¹¦æ¨è")
    print(f"{'='*70}")
    print(f"\nğŸ“Š é…ç½®:")
    print(f"  â€¢ åˆ·æ–°æ¬¡æ•°: {args.refresh_count}")
    print(f"  â€¢ æœ€å¤šç¬”è®°: {args.max_notes}")
    print(f"  â€¢ åˆ†ææ¨¡å¼: {args.mode}")

    # è¯»å–Cookie
    cookie = read_xhs_cookie()
    if not cookie:
        print("\nâš ï¸  æœªæ‰¾åˆ°Cookieï¼Œå°†ä½¿ç”¨æ— Cookieæ¨¡å¼ï¼ˆéœ€è¦æ‰‹åŠ¨ç™»å½•ï¼‰")

    # é‡‡é›†æ•°æ®
    notes = await scrape_xiaohongshu_homepage(
        refresh_count=args.refresh_count,
        max_notes=args.max_notes,
        cookie=cookie
    )

    if not notes:
        print("\nâŒ æœªé‡‡é›†åˆ°ä»»ä½•ç¬”è®°")
        return

    # å¯¼å‡ºCSV
    date_str = datetime.now().strftime('%Y-%m-%d')
    csv_path = OUTPUT_DIR / f"xiaohongshu_homepage_{date_str}.csv"
    export_to_csv(notes, csv_path)

    # AIåˆ†æï¼ˆå¾…å®ç°ï¼‰
    if args.mode == 'full':
        print("\nâš ï¸  AIåˆ†æåŠŸèƒ½å¾…å®ç°")

    print(f"\n{'='*70}")
    print(f"  âœ… å®Œæˆï¼")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    asyncio.run(main())
