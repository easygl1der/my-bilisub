#!/usr/bin/env python3
"""
å°çº¢ä¹¦å›¾æ–‡æå–æµ‹è¯• - éäº¤äº’ç‰ˆæœ¬

ä½¿ç”¨æ–¹æ³•:
1. ä»å°çº¢ä¹¦APPæˆ–ç½‘é¡µå¤åˆ¶ç¬”è®°é“¾æ¥ï¼ˆå¿…é¡»å¸¦xsec_tokenï¼‰
2. ä¿®æ”¹ä¸‹é¢çš„ test_url å˜é‡
3. è¿è¡Œè„šæœ¬: python test_xhs_final.py
"""

import os
import sys
import re
import json
import requests
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


# ==================== é…ç½®åŒº ====================
# TODO: åœ¨è¿™é‡Œç²˜è´´ä½ çš„å°çº¢ä¹¦ç¬”è®°é“¾æ¥ï¼ˆå¿…é¡»å¸¦ xsec_tokenï¼‰
test_url = ""
# ================================================


def extract_xhs_images(note_url: str) -> dict:
    """æå–å°çº¢ä¹¦ç¬”è®°çš„å›¾ç‰‡å’Œæ–‡å­—"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    }

    print(f"ğŸ“¡ è¯·æ±‚: {note_url[:80]}...")
    print()

    try:
        response = requests.get(note_url, headers=headers, timeout=30)
        print(f"çŠ¶æ€ç : {response.status_code}")
        print(f"é¡µé¢é•¿åº¦: {len(response.text)}")

        if response.status_code != 200:
            return None

        # æ£€æŸ¥æ˜¯å¦æ˜¯404é¡µé¢
        if 'ä½ è®¿é—®çš„é¡µé¢ä¸è§äº†' in response.text or '404' in response.url:
            print("\nâŒ é¡µé¢æ— æ³•è®¿é—®")
            print("   åŸå› : é“¾æ¥ç¼ºå°‘ xsec_token æˆ–å·²è¿‡æœŸ")
            print("   è§£å†³: è¯·ä»å°çº¢ä¹¦APPå¤åˆ¶å®Œæ•´é“¾æ¥")
            return None

        html = response.text

    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

    # æå–æ ‡é¢˜
    title = "å°çº¢ä¹¦ç¬”è®°"
    title_match = re.search(r'<title[^>]*>(.+?)</title>', html)
    if title_match:
        title = title_match.group(1).replace(' - å°çº¢ä¹¦', '').strip()

    # æå–ç¬”è®°ID
    note_id = ""
    note_id_match = re.search(r'/explore/([a-f0-9]+)', note_url)
    if note_id_match:
        note_id = note_id_match.group(1)

    # æå–æ–‡å­—
    text_content = ""
    desc_match = re.search(r'"desc":"([^"]+)"', html)
    if desc_match:
        try:
            text_content = desc_match.group(1).encode('utf-8').decode('unicode_escape')
        except:
            text_content = desc_match.group(1)

    # æå–å›¾ç‰‡
    images = []

    # ä» JSON æå–
    start_idx = html.find('window.__INITIAL_STATE__=')
    if start_idx >= 0:
        start_idx += len('window.__INITIAL_STATE__=')
        end_idx = html.find('</script>', start_idx)
        json_str = html[start_idx:end_idx]

        try:
            data = json.loads(json_str)
            note = data.get('note', {})
            note_detail = note.get('noteDetail', {})
            image_list = note_detail.get('imageList', [])

            for i, img in enumerate(image_list):
                url = (img.get('urlDefault') or img.get('url'))
                if url:
                    images.append(url)

        except:
            pass

    # å¤‡ç”¨ï¼šç›´æ¥æœç´¢
    if not images:
        urls = re.findall(r'"urlDefault":"(https://[^"]+)"', html)
        images = urls

    return {
        'note_id': note_id,
        'title': title,
        'text': text_content,
        'images': images
    }


def format_and_save(result: dict, url: str):
    """æ ¼å¼åŒ–æ˜¾ç¤ºå¹¶ä¿å­˜ç»“æœ"""

    # è¾“å‡ºç›®å½•
    output_dir = Path("output/test_xhs")
    output_dir.mkdir(parents=True, exist_ok=True)

    # æ„å»ºè¾“å‡º
    lines = []
    lines.append("=" * 100)
    lines.append("ğŸ“‹ å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æå–ç»“æœ".center(100))
    lines.append("=" * 100)
    lines.append("")
    lines.append(f"ğŸ†” ç¬”è®°ID: {result['note_id']}")
    lines.append("")
    lines.append(f"ğŸ“ æ ‡é¢˜:")
    lines.append(f"   {result['title']}")
    lines.append("")
    lines.append(f"ğŸ“„ æ–‡å­—å†…å®¹:")
    lines.append(f"   {result['text'] if result['text'] else '(æ— )'}")
    lines.append("")
    lines.append(f"ğŸ–¼ï¸  å›¾ç‰‡åˆ—è¡¨ ({len(result['images'])} å¼ ):")
    lines.append("")

    for i, img_url in enumerate(result['images'], 1):
        lines.append(f"   [{i}] {img_url}")

    lines.append("")
    lines.append("=" * 100)

    output = "\n".join(lines)
    print(output)

    # ä¿å­˜åˆ°æ–‡ä»¶
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    safe_title = re.sub(r'[<>:"/\\|?*]', '_', result['title'])[:30]
    result_file = output_dir / f"{safe_title}_{timestamp}.txt"

    with open(result_file, 'w', encoding='utf-8') as f:
        f.write(output)
        f.write(f"\n\nåŸå§‹é“¾æ¥: {url}\n")
        f.write(f"æå–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file}")

    # ä¸‹è½½å›¾ç‰‡
    if result['images']:
        print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½å›¾ç‰‡...")
        img_dir = output_dir / f"{safe_title}_{timestamp}_images"
        img_dir.mkdir(exist_ok=True)

        headers = {'Referer': 'https://www.xiaohongshu.com/'}

        for i, img_url in enumerate(result['images'], 1):
            print(f"   [{i}/{len(result['images'])}] ", end='', flush=True)
            try:
                resp = requests.get(img_url, headers=headers, timeout=30)
                if resp.status_code == 200:
                    ext = '.png' if 'png' in resp.headers.get('Content-Type', '') else '.jpg'
                    filepath = img_dir / f"image_{i:02d}{ext}"
                    with open(filepath, 'wb') as f:
                        f.write(resp.content)
                    size = len(resp.content) / 1024
                    print(f"âœ… {size:.1f}KB")
                else:
                    print(f"âŒ HTTP {resp.status_code}")
            except Exception as e:
                print(f"âŒ {e}")

        print(f"ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {img_dir}")


def main():
    print("\n" + "=" * 100)
    print("ğŸ” å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æå–æµ‹è¯•")
    print("=" * 100)
    print()

    if not test_url:
        print("âŒ è¯·å…ˆåœ¨è„šæœ¬ä¸­è®¾ç½® test_url å˜é‡")
        print()
        print("ğŸ“ ä½¿ç”¨æ–¹æ³•:")
        print("   1. æ‰“å¼€å°çº¢ä¹¦APPæˆ–ç½‘é¡µ")
        print("   2. æ‰¾åˆ°ä¸€ä¸ªå›¾æ–‡ç¬”è®°ï¼ˆéè§†é¢‘ï¼‰")
        print("   3. ç‚¹å‡»åˆ†äº« -> å¤åˆ¶é“¾æ¥")
        print("   4. å°†é“¾æ¥ç²˜è´´åˆ°è„šæœ¬çš„ test_url å˜é‡ä¸­")
        print()
        print("ğŸ’¡ é“¾æ¥ç¤ºä¾‹:")
        print("   https://www.xiaohongshu.com/explore/xxxxxx?xsec_token=xxxxx")
        return

    result = extract_xhs_images(test_url)

    if result and result['images']:
        format_and_save(result, test_url)
    else:
        print("\nâŒ æå–å¤±è´¥æˆ–æœªæ‰¾åˆ°å›¾ç‰‡")
        print()
        print("å¯èƒ½åŸå› :")
        print("   1. é“¾æ¥ç¼ºå°‘ xsec_token å‚æ•°")
        print("   2. ç¬”è®°æ˜¯è§†é¢‘ç±»å‹")
        print("   3. é“¾æ¥å·²è¿‡æœŸ")
        print()
        print("è¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦å®Œæ•´ä¸”åŒ…å« xsec_token å‚æ•°")


if __name__ == "__main__":
    main()
