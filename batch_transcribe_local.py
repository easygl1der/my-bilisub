#!/usr/bin/env python3
"""
æ‰¹é‡æœ¬åœ°è§†é¢‘ Whisper è½¬å½•å·¥å…·

åŠŸèƒ½:
1. æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶
2. ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«
3. ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶

æ”¯æŒæ ¼å¼: mp4, mkv, avi, mov, flv, wmv, webm

ä½¿ç”¨ç¤ºä¾‹:
    # å¤„ç† downloaded_videos ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘
    python batch_transcribe_local.py -i downloaded_videos

    # åªå¤„ç†æŒ‡å®šä½œè€…çš„è§†é¢‘
    python batch_transcribe_local.py -i downloaded_videos/ä½œè€…å

    # æŒ‡å®š Whisper æ¨¡å‹
    python batch_transcribe_local.py -i downloaded_videos -m medium

    # è·³è¿‡å·²å­˜åœ¨å­—å¹•çš„è§†é¢‘
    python batch_transcribe_local.py -i downloaded_videos --skip-existing
"""

import os
import sys
import time
import subprocess
import argparse
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ==================== é…ç½® ====================
WHISPER_MODEL = "small"  # tiny/base/small/medium/large
OUTPUT_DIR = "output/transcripts"
VIDEO_EXTENSIONS = {'.mp4', '.mkv', '.avi', '.mov', '.flv', '.wmv', '.webm', '.m4v'}
# ==============================================


def find_videos(input_dir: Path, recursive: bool = True) -> list:
    """æŸ¥æ‰¾ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
    videos = []

    if recursive:
        for ext in VIDEO_EXTENSIONS:
            videos.extend(input_dir.rglob(f'*{ext}'))
    else:
        for ext in VIDEO_EXTENSIONS:
            videos.extend(input_dir.glob(f'*{ext}'))

    return sorted(videos, key=lambda p: p.stat().st_mtime)


def extract_audio(video_path: Path, output_dir: Path) -> Path:
    """ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘"""
    output_dir.mkdir(parents=True, exist_ok=True)
    audio_path = output_dir / f"{video_path.stem}.wav"

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if audio_path.exists():
        return audio_path

    print(f"   â¬‡ï¸  æå–éŸ³é¢‘...")
    start = time.time()

    cmd = [
        'ffmpeg', '-i', str(video_path),
        '-vn', '-acodec', 'pcm_s16le',
        '-ar', '16000', '-ac', '1',
        '-y', str(audio_path),
        '-loglevel', 'error'
    ]

    result = subprocess.run(cmd, capture_output=True)
    if result.returncode != 0:
        raise RuntimeError(f"ffmpeg å¤±è´¥: {result.stderr.decode('utf-8', errors='ignore')}")

    print(f"   âœ… éŸ³é¢‘æå–å®Œæˆ ({time.time()-start:.1f}ç§’)")
    return audio_path


def transcribe_whisper(audio_path: Path, model: str = "small", language: str = "zh") -> dict:
    """ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘"""
    import whisper

    print(f"   ğŸ™ï¸  Whisper è½¬å½•ä¸­ (æ¨¡å‹: {model})...")
    start = time.time()

    # æ£€æµ‹ GPU
    import torch
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"   ğŸ”§ è®¾å¤‡: {device.upper()}")

    # åŠ è½½æ¨¡å‹
    load_start = time.time()
    model_obj = whisper.load_model(model, device=device)
    print(f"   âœ… æ¨¡å‹åŠ è½½ ({time.time()-load_start:.1f}ç§’)")

    # è½¬å½•
    result = model_obj.transcribe(
        str(audio_path),
        language=language,
        verbose=False
    )

    transcribe_time = time.time() - start
    print(f"   âœ… è½¬å½•å®Œæˆ ({transcribe_time:.1f}ç§’)")

    return result


def save_srt(result: dict, output_path: Path, video_name: str):
    """ä¿å­˜ä¸º SRT æ ¼å¼"""
    output_path.mkdir(parents=True, exist_ok=True)
    srt_path = output_path / f"{video_name}.srt"

    with open(srt_path, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(result['segments'], 1):
            def fmt(t):
                h, m, s = int(t//3600), int((t%3600)//60), int(t%60)
                ms = int((t%1)*1000)
                return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"
            f.write(f"{i}\n{fmt(seg['start'])} --> {fmt(seg['end'])}\n{seg['text'].strip()}\n\n")

    print(f"   ğŸ“„ å­—å¹•å·²ä¿å­˜: {srt_path.name}")
    return srt_path


def save_txt(result: dict, output_path: Path, video_name: str):
    """ä¿å­˜ä¸ºçº¯æ–‡æœ¬"""
    output_path.mkdir(parents=True, exist_ok=True)
    txt_path = output_path / f"{video_name}.txt"

    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(result['text'])

    return txt_path


def process_video(video_path: Path, model: str, output_dir: Path, skip_existing: bool = False) -> dict:
    """å¤„ç†å•ä¸ªè§†é¢‘"""
    result = {
        'video': str(video_path),
        'video_name': video_path.stem,
        'success': False,
        'error': None,
        'elapsed': 0,
        'srt_path': None,
        'txt_path': None
    }

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å­—å¹•
    srt_path = output_dir / f"{video_path.stem}.srt"
    if skip_existing and srt_path.exists():
        result['success'] = True
        result['skip_reason'] = 'å­—å¹•å·²å­˜åœ¨'
        result['srt_path'] = str(srt_path)
        return result

    start = time.time()

    try:
        print(f"\n{'='*70}")
        print(f"ğŸ¬ å¤„ç†: {video_path.name}")
        print(f"{'='*70}")

        # æå–éŸ³é¢‘
        audio_dir = Path("output/audio")
        audio_path = extract_audio(video_path, audio_dir)

        # Whisper è½¬å½•
        transcribe_result = transcribe_whisper(audio_path, model)

        # ä¿å­˜ç»“æœ
        srt_path = save_srt(transcribe_result, output_dir, video_path.stem)
        txt_path = save_txt(transcribe_result, output_dir, video_path.stem)

        result['success'] = True
        result['elapsed'] = time.time() - start
        result['srt_path'] = str(srt_path)
        result['txt_path'] = str(txt_path)
        result['duration'] = transcribe_result.get('segments', [-1])[-1].get('end', 0) if transcribe_result.get('segments') else 0

        print(f"   âœ… å®Œæˆ! æ€»è€—æ—¶: {result['elapsed']:.1f}ç§’")

    except Exception as e:
        result['error'] = str(e)
        result['elapsed'] = time.time() - start
        print(f"   âŒ å¤±è´¥: {e}")

    return result


def batch_process(input_dir: str, model: str = "small", skip_existing: bool = False):
    """æ‰¹é‡å¤„ç†"""
    input_path = Path(input_dir)
    output_path = Path(OUTPUT_DIR)
    output_path.mkdir(parents=True, exist_ok=True)

    # æŸ¥æ‰¾è§†é¢‘
    print(f"ğŸ“ æ‰«æç›®å½•: {input_path}")
    videos = find_videos(input_path)

    if not videos:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return

    print(f"âœ… æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘æ–‡ä»¶\n")

    # ç»Ÿè®¡ä¿¡æ¯
    results = []
    success_count = 0
    skip_count = 0
    fail_count = 0
    total_time = 0

    for i, video_path in enumerate(videos, 1):
        print(f"\n[è¿›åº¦: {i}/{len(videos)}]")

        result = process_video(video_path, model, output_path, skip_existing)
        results.append(result)

        if result['success']:
            if 'skip_reason' in result:
                skip_count += 1
            else:
                success_count += 1
                total_time += result['elapsed']
        else:
            fail_count += 1

        # é¿å…è¿‡è½½
        if i < len(videos):
            time.sleep(1)

    # æ‰“å°æ€»ç»“
    print(f"\n{'='*70}")
    print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
    print(f"{'='*70}")
    print(f"   æ€»æ•°: {len(videos)}")
    print(f"   æˆåŠŸ: {success_count}")
    print(f"   è·³è¿‡: {skip_count}")
    print(f"   å¤±è´¥: {fail_count}")

    if success_count > 0:
        print(f"   æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"   å¹³å‡: {total_time/success_count:.1f}ç§’/è§†é¢‘")

    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_path.absolute()}")

    # ä¿å­˜æŠ¥å‘Š
    report_path = output_path / f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"æ‰¹é‡è½¬å½•æŠ¥å‘Š\n")
        f.write(f"{'='*60}\n")
        f.write(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"è¾“å…¥ç›®å½•: {input_path}\n")
        f.write(f"Whisperæ¨¡å‹: {model}\n\n")
        f.write(f"æ€»æ•°: {len(videos)} | æˆåŠŸ: {success_count} | è·³è¿‡: {skip_count} | å¤±è´¥: {fail_count}\n\n")

        for i, r in enumerate(results, 1):
            status = "âœ…" if r['success'] else "âŒ"
            if r['success'] and 'skip_reason' in r:
                status = "â­ï¸ "
            f.write(f"{i}. {status} {Path(r['video']).name}\n")
            if r.get('error'):
                f.write(f"   é”™è¯¯: {r['error']}\n")

    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path.name}")


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡æœ¬åœ°è§†é¢‘ Whisper è½¬å½•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. å¤„ç† downloaded_videos ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘:
   python batch_transcribe_local.py -i downloaded_videos

2. æŒ‡å®š Whisper æ¨¡å‹:
   python batch_transcribe_local.py -i downloaded_videos -m medium

3. è·³è¿‡å·²å­˜åœ¨å­—å¹•çš„è§†é¢‘:
   python batch_transcribe_local.py -i downloaded_videos --skip-existing

4. åªå¤„ç†å•ä¸ªç›®å½•ï¼ˆä¸é€’å½’ï¼‰:
   python batch_transcribe_local.py -i downloaded_videos --no-recursive
        """
    )

    parser.add_argument(
        '-i', '--input',
        required=True,
        help='è¾“å…¥ç›®å½•ï¼ˆåŒ…å«è§†é¢‘æ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼‰'
    )
    parser.add_argument(
        '-m', '--model',
        default='small',
        choices=['tiny', 'base', 'small', 'medium', 'large'],
        help='Whisper æ¨¡å‹ï¼ˆé»˜è®¤: smallï¼‰'
    )
    parser.add_argument(
        '--skip-existing',
        action='store_true',
        help='è·³è¿‡å·²å­˜åœ¨å­—å¹•çš„è§†é¢‘'
    )
    parser.add_argument(
        '--no-recursive',
        action='store_true',
        help='ä¸é€’å½’æ‰«æå­ç›®å½•'
    )

    args = parser.parse_args()

    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.input}")
        return

    batch_process(
        input_dir=str(input_path),
        model=args.model,
        skip_existing=args.skip_existing
    )


if __name__ == "__main__":
    main()
