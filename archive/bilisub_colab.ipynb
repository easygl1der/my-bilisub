{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¬ Bç«™/å°çº¢ä¹¦è§†é¢‘å­—å¹•æå– - Colabç‰ˆ\n",
    "\n",
    "ä»“åº“: https://github.com/easygl1der/my-bilisub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ æŒ‚è½½ Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# é¡¹ç›®è·¯å¾„\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/my-projects/my-bilisub\"\n",
    "import os\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"âœ… å·¥ä½œç›®å½•: {PROJECT_DIR}\")\n",
    "print(f\"ğŸ“ æ–‡ä»¶åˆ—è¡¨:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "!pip install -q openai-whisper yt-dlp tqdm requests\n",
    "\n",
    "# æ£€æŸ¥ GPU\n",
    "import torch\n",
    "print(f\"\\nğŸ”¥ GPU å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= é…ç½®åŒºåŸŸ =============\n",
    "\n",
    "# è§†é¢‘é“¾æ¥\n",
    "VIDEO_URL = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Whisper æ¨¡å‹\n",
    "WHISPER_MODEL = \"small\"  # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "\n",
    "# æ™ºè°± APIï¼ˆå¯é€‰ï¼Œç”¨äºå­—å¹•ä¼˜åŒ–ï¼‰\n",
    "ZHIPU_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# æ˜¯å¦å¯ç”¨ GLM ä¼˜åŒ–\n",
    "ENABLE_GLM = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# =====================================\n",
    "\n",
    "import os\n",
    "if ZHIPU_API_KEY:\n",
    "    os.environ['ZHIPU_API_KEY'] = ZHIPU_API_KEY\n",
    "\n",
    "print(f\"ğŸ¬ è§†é¢‘é“¾æ¥: {VIDEO_URL[:60] if VIDEO_URL else '(æœªè®¾ç½®)'}...\")\n",
    "print(f\"ğŸ“¦ Whisper æ¨¡å‹: {WHISPER_MODEL}\")\n",
    "print(f\"ğŸ¤– GLM ä¼˜åŒ–: {'å¯ç”¨' if ENABLE_GLM and ZHIPU_API_KEY else 'ç¦ç”¨'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ è¿è¡Œ Whisper è½¬å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import yt_dlp\n",
    "import whisper\n",
    "\n",
    "if not VIDEO_URL:\n",
    "    print(\"âŒ è¯·å…ˆè®¾ç½® VIDEO_URL\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    # 1. ä¸‹è½½éŸ³é¢‘\n",
    "    print(\"\\nâ¬‡ï¸ æ­¥éª¤ 1/2: ä¸‹è½½éŸ³é¢‘\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': 'output/audio.%(ext)s',\n",
    "        'quiet': True,\n",
    "    }\n",
    "    \n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    \n",
    "    start = time.time()\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(VIDEO_URL, download=True)\n",
    "        title = info.get('title', 'unknown')\n",
    "        duration = info.get('duration', 0)\n",
    "    \n",
    "    audio_file = list(Path('output').glob('audio.*'))[0]\n",
    "    print(f\"âœ… ä¸‹è½½: {time.time()-start:.1f}ç§’ | æ—¶é•¿: {duration//60}åˆ†{duration%60}ç§’\")\n",
    "    print(f\"ğŸ“Œ æ ‡é¢˜: {title}\")\n",
    "    \n",
    "    # 2. Whisper è½¬å½•\n",
    "    print(\"\\nğŸ™ï¸ æ­¥éª¤ 2/2: Whisper è½¬å½•\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"ğŸ”§ è®¾å¤‡: {device.upper()}\")\n",
    "    \n",
    "    load_start = time.time()\n",
    "    model = whisper.load_model(WHISPER_MODEL, device=device)\n",
    "    print(f\"âœ… æ¨¡å‹åŠ è½½: {time.time()-load_start:.1f}ç§’\")\n",
    "    \n",
    "    transcribe_start = time.time()\n",
    "    result = model.transcribe(str(audio_file), language='zh', verbose=False)\n",
    "    transcribe_time = time.time() - transcribe_start\n",
    "    \n",
    "    print(f\"âœ… è½¬å½•å®Œæˆ: {transcribe_time:.1f}ç§’\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    safe_title = re.sub(r'[<>:\"/\\\\|?*]', '_', title)[:80]\n",
    "    output_dir = Path('output/transcripts')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ä¿å­˜ SRT\n",
    "    srt_path = output_dir / f\"{safe_title}.srt\"\n",
    "    with open(srt_path, 'w', encoding='utf-8') as f:\n",
    "        for i, seg in enumerate(result['segments'], 1):\n",
    "            def fmt(t):\n",
    "                h, m, s = int(t//3600), int((t%3600)//60), int(t%60)\n",
    "                ms = int((t%1)*1000)\n",
    "                return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
    "            f.write(f\"{i}\\n{fmt(seg['start'])} --> {fmt(seg['end'])}\\n{seg['text'].strip()}\\n\\n\")\n",
    "    \n",
    "    # ä¿å­˜ TXT\n",
    "    txt_path = output_dir / f\"{safe_title}.txt\"\n",
    "    with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(result['text'])\n",
    "    \n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… å¤„ç†å®Œæˆ!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"â±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’\")\n",
    "    print(f\"ğŸ“Š æ®µè½æ•°: {len(result['segments'])}\")\n",
    "    print(f\"\\nğŸ“ è¾“å‡ºæ–‡ä»¶:\")\n",
    "    print(f\"   SRT: {srt_path}\")\n",
    "    print(f\"   TXT: {txt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ GLM å­—å¹•ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_GLM and ZHIPU_API_KEY:\n",
    "    import requests\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # è·å–æœ€æ–° SRT æ–‡ä»¶\n",
    "    srt_files = list(Path('output/transcripts').glob('*.srt'))\n",
    "    if not srt_files:\n",
    "        print(\"âŒ æœªæ‰¾åˆ° SRT æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè½¬å½•\")\n",
    "    else:\n",
    "        srt_path = max(srt_files, key=lambda p: p.stat().st_mtime)\n",
    "        print(f\"ğŸ“„ å¤„ç†æ–‡ä»¶: {srt_path.name}\")\n",
    "        \n",
    "        # è§£æ SRT\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\n(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})\\n(.+?)(?=\\n\\n|$)'\n",
    "        with open(srt_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        segments = re.findall(pattern, content, re.DOTALL)\n",
    "        \n",
    "        print(f\"ğŸ“Š å…± {len(segments)} ä¸ªæ®µè½\")\n",
    "        \n",
    "        BATCH_SIZE = 5\n",
    "        optimized_segments = []\n",
    "        \n",
    "        for i in range(0, len(segments), BATCH_SIZE):\n",
    "            batch = segments[i:i+BATCH_SIZE]\n",
    "            batch_num = i // BATCH_SIZE + 1\n",
    "            total_batches = (len(segments) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "            \n",
    "            combined_text = '\\n'.join([s[3].strip() for s in batch])\n",
    "            \n",
    "            prompt = f\"\"\"è¯·ä¼˜åŒ–ä»¥ä¸‹è§†é¢‘å­—å¹•ï¼š\\n\\n1. ä¿®æ­£é”™åˆ«å­—\\n2. æ·»åŠ æ ‡ç‚¹\\n3. æ”¹å–„æµç•…åº¦\\n4. ä¿æŒåŸæ„\\n\\nåŸæ–‡ï¼ˆ{len(batch)}è¡Œï¼‰ï¼š\\n{combined_text}\\n\\nä¼˜åŒ–åï¼ˆ{len(batch)}è¡Œï¼Œæ¯è¡Œä¸€ä¸ªï¼‰ï¼š\"\"\"\n",
    "            \n",
    "            try:\n",
    "                resp = requests.post(\n",
    "                    \"https://open.bigmodel.cn/api/paas/v4/chat/completions\",\n",
    "                    headers={\n",
    "                        \"Authorization\": f\"Bearer {ZHIPU_API_KEY}\",\n",
    "                        \"Content-Type\": \"application/json\"\n",
    "                    },\n",
    "                    json={\n",
    "                        \"model\": \"glm-4-flash\",\n",
    "                        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                        \"temperature\": 0.3\n",
    "                    },\n",
    "                    timeout=30\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "                opt_text = resp.json()['choices'][0]['message']['content'].strip()\n",
    "                opt_lines = opt_text.split('\\n')\n",
    "                \n",
    "                for j, seg in enumerate(batch):\n",
    "                    if j < len(opt_lines):\n",
    "                        optimized_segments.append((seg[0], seg[1], seg[2], opt_lines[j].strip()))\n",
    "                    else:\n",
    "                        optimized_segments.append(seg)\n",
    "                \n",
    "                print(f\"   æ‰¹æ¬¡ [{batch_num}/{total_batches}] å®Œæˆ\")\n",
    "            except Exception as e:\n",
    "                print(f\"   æ‰¹æ¬¡ [{batch_num}/{total_batches}] å¤±è´¥: {e}\")\n",
    "                optimized_segments.extend(batch)\n",
    "        \n",
    "        # ä¿å­˜ä¼˜åŒ–åçš„ SRT\n",
    "        opt_srt_path = srt_path.parent / f\"{srt_path.stem}_optimized.srt\"\n",
    "        with open(opt_srt_path, 'w', encoding='utf-8') as f:\n",
    "            for seg in optimized_segments:\n",
    "                f.write(f\"{seg[0]}\\n{seg[1]} --> {seg[2]}\\n{seg[3]}\\n\\n\")\n",
    "        \n",
    "        print(f\"\\nâœ… ä¼˜åŒ–å®Œæˆ!\")\n",
    "        print(f\"ğŸ“„ è¾“å‡º: {opt_srt_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ GLM ä¼˜åŒ–æœªå¯ç”¨\")\n",
    "    print(\"   å¦‚éœ€å¯ç”¨ï¼Œè¯·è®¾ç½® ENABLE_GLM=True å’Œ ZHIPU_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ ä¸‹è½½ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "# åˆ—å‡ºè¾“å‡ºæ–‡ä»¶\n",
    "output_dir = Path('output/transcripts')\n",
    "if output_dir.exists():\n",
    "    print(\"ğŸ“ å¯ä¸‹è½½çš„æ–‡ä»¶:\\n\")\n",
    "    for f in output_dir.glob('*'):\n",
    "        size = f.stat().st_size / 1024\n",
    "        print(f\"  â€¢ {f.name} ({size:.1f} KB)\")\n",
    "    \n",
    "    # ä¸‹è½½æ‰€æœ‰æ–‡ä»¶\n",
    "    print(\"\\nâ¬‡ï¸ ä¸‹è½½ä¸­...\")\n",
    "    for f in output_dir.glob('*'):\n",
    "        files.download(str(f))\n",
    "else:\n",
    "    print(\"âŒ æ²¡æœ‰è¾“å‡ºæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè½¬å½•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### å¿«é€Ÿå¼€å§‹\n",
    "1. **å¯ç”¨ GPU**: è¿è¡Œæ—¶ â†’ æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ â†’ T4 GPU\n",
    "2. è®¾ç½® `VIDEO_URL` (ä½ çš„ Bç«™/å°çº¢ä¹¦è§†é¢‘é“¾æ¥)\n",
    "3. æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰å•å…ƒæ ¼\n",
    "\n",
    "### å¯é€‰åŠŸèƒ½\n",
    "- **GLM ä¼˜åŒ–**: è®¾ç½® `ENABLE_GLM=True` å’Œ `ZHIPU_API_KEY`\n",
    "\n",
    "### æ¨¡å‹é€‰æ‹©\n",
    "| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | å‡†ç¡®åº¦ |\n",
    "|------|------|------|--------|\n",
    "| tiny | ~1GB | æœ€å¿« | ä¸€èˆ¬ |\n",
    "| base | ~1GB | å¿« | ä¸€èˆ¬ |\n",
    "| small | ~2GB | è¾ƒå¿« | è¾ƒå¥½ |\n",
    "| medium | ~5GB | ä¸­ç­‰ | å¥½ |\n",
    "| large | ~10GB | æ…¢ | æœ€å¥½ |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
