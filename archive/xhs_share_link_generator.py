#!/usr/bin/env python3
"""
å°çº¢ä¹¦é“¾æ¥å¤„ç†å·¥å…·

åŠŸèƒ½ï¼š
- ä»å°çº¢ä¹¦é“¾æ¥æå–ç¬”è®°ID
- ç”Ÿæˆç®€åŒ–é“¾æ¥æ ¼å¼
- æ”¯æŒæ‰¹é‡å¤„ç† CSV/JSON

ä½¿ç”¨ç¤ºä¾‹:
    # å¤„ç†å•ä¸ªé“¾æ¥
    python xhs_share_link_generator.py --url "https://www.xiaohongshu.com/explore/69983ebb00000000150304d8"

    # æ‰¹é‡å¤„ç† CSV
    python xhs_share_link_generator.py --csv notes.csv

    # ä» JSON æ–‡ä»¶è¯»å–
    python xhs_share_link_generator.py --json videos.json
"""

import sys
import re
import json
import csv
import argparse
from pathlib import Path

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import requests


# ==================== é…ç½® ====================

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
}

# ==================== é“¾æ¥å¤„ç† ====================

def extract_note_id(url: str) -> str:
    """
    ä»å°çº¢ä¹¦é“¾æ¥ä¸­æå–ç¬”è®°ID

    Args:
        url: å°çº¢ä¹¦é“¾æ¥ï¼ˆå¯ä»¥æ˜¯ xhslink.com æˆ– xiaohongshu.comï¼‰

    Returns:
        ç¬”è®°IDï¼ˆ24ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
    """
    # å¤„ç†çŸ­é“¾æ¥ï¼Œéœ€è¦å…ˆé‡å®šå‘è·å–åŸå§‹é“¾æ¥
    if 'xhslink.com' in url:
        try:
            response = requests.get(url, headers=HEADERS, timeout=10, allow_redirects=True)
            url = response.url
        except:
            pass

    # ä»åŸå§‹é“¾æ¥æå–ç¬”è®°ID
    patterns = [
        r'/explore/([a-f0-9]{24})',
        r'/discovery/item/([a-f0-9]{24})',
        r'noteId=([a-f0-9]{24})',
        r'/item/([a-f0-9]{24})',
        r'([a-f0-9]{24})',  # æœ€åå°è¯•ç›´æ¥åŒ¹é…24ä½åå…­è¿›åˆ¶
    ]

    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            return match.group(1)

    return ''


def generate_short_url(note_id: str) -> dict:
    """
    ç”Ÿæˆå°çº¢ä¹¦ç®€åŒ–é“¾æ¥

    Args:
        note_id: ç¬”è®°IDï¼ˆ24ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰

    Returns:
        {'success': bool, 'short_url': str, 'original_url': str, 'error': str}
    """
    result = {'success': False, 'short_url': '', 'original_url': '', 'error': ''}

    if not note_id or len(note_id) != 24:
        result['error'] = f"æ— æ•ˆçš„ç¬”è®°ID: {note_id}"
        return result

    # ç”ŸæˆåŸå§‹é“¾æ¥
    original_url = f"https://www.xiaohongshu.com/explore/{note_id}"
    result['original_url'] = original_url

    # å°çº¢ä¹¦çš„ xhslink.com åˆ†äº«é“¾æ¥éœ€è¦é€šè¿‡ App æˆ–ç™»å½•åçš„ç½‘é¡µç”Ÿæˆ
    # è¿™é‡Œæä¾›å‡ ç§æ›¿ä»£æ–¹æ¡ˆï¼š

    # æ–¹æ¡ˆ1: å°è¯•ä» API è·å–ï¼ˆéœ€è¦ Cookieï¼‰
    try:
        api_url = "https://edith.xiaohongshu.com/api/sns/web/v1/note/share/short_url"

        # è¯»å– Cookie
        cookies = {}
        cookie_file = Path(__file__).parent / "config" / "cookies.txt"
        if cookie_file.exists():
            try:
                with open(cookie_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    start = content.find('[xiaohongshu]')
                    if start >= 0:
                        end = content.find('\n[', start + 1)
                        if end == -1:
                            end = len(content)
                        xhs_section = content[start:end]
                        for line in xhs_section.split('\n'):
                            line = line.strip()
                            if '=' in line and not line.startswith('#') and not line.startswith('['):
                                key, value = line.split('=', 1)
                                cookies[key.strip()] = value.strip()
            except:
                pass

        if cookies:
            headers = {
                **HEADERS,
                'Referer': original_url,
                'Accept': 'application/json',
            }
            params = {'note_id': note_id}

            response = requests.get(api_url, headers=headers, params=params, cookies=cookies, timeout=10)

            if response.status_code == 200:
                try:
                    data = response.json()
                    if 'data' in data and data['data']:
                        share_url = data['data'].get('short_url') or data['data'].get('share_url')
                        if share_url:
                            result['success'] = True
                            result['short_url'] = share_url
                            return result
                except:
                    pass

        # æ–¹æ¡ˆ2: å°è¯•ä»é¡µé¢è·å–åˆ†äº«é“¾æ¥
        response = requests.get(original_url, headers=HEADERS, cookies=cookies, timeout=15, allow_redirects=True)

        if response.status_code == 200:
            html = response.text

            # æŸ¥æ‰¾åˆ†äº«é“¾æ¥æ¨¡å¼
            share_patterns = [
                r'"shareUrl":"([^"]+)"',
                r'"share_url":"([^"]+)"',
                r'"shortUrl":"([^"]+)"',
                r'"short_url":"([^"]+)"',
            ]

            for pattern in share_patterns:
                match = re.search(pattern, html)
                if match:
                    share_candidate = match.group(1).replace(r'\/', '/')
                    if 'xhslink.com' in share_candidate:
                        result['success'] = True
                        result['short_url'] = share_candidate
                        return result

    except Exception as e:
        result['error'] = str(e)

    # å¦‚æœæ²¡æœ‰è·å–åˆ° xhslink.comï¼Œè¿”å›åŸå§‹é“¾æ¥ä½œä¸º"çŸ­é“¾æ¥"
    result['error'] = "æ— æ³•è·å– xhslink.com åˆ†äº«é“¾æ¥ï¼ˆéœ€è¦ç™»å½•æˆ–ä½¿ç”¨ Appï¼‰"
    result['short_url'] = original_url

    return result


def process_url(url: str) -> dict:
    """
    å¤„ç†å•ä¸ªé“¾æ¥

    Args:
        url: å°çº¢ä¹¦é“¾æ¥

    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    result = {
        'original_url': url,
        'note_id': '',
        'short_url': '',
        'original_explore_url': '',
        'success': False,
        'error': ''
    }

    print(f"\nå¤„ç†: {url[:70]}...")
    print("-" * 70)

    # æå–ç¬”è®°ID
    note_id = extract_note_id(url)
    if not note_id:
        result['error'] = "æ— æ³•æå–ç¬”è®°ID"
        print(f"âŒ {result['error']}")
        return result

    result['note_id'] = note_id
    print(f"ç¬”è®°ID: {note_id}")

    # ç”Ÿæˆé“¾æ¥
    link_result = generate_short_url(note_id)
    result.update(link_result)

    # è¾“å‡ºç»“æœ
    if result['success'] and 'xhslink.com' in result['short_url']:
        print(f"âœ… åˆ†äº«é“¾æ¥: {result['short_url']}")
    elif result['short_url']:
        print(f"ğŸ“ ç®€åŒ–é“¾æ¥: {result['short_url']}")
        print(f"   (å¦‚éœ€ xhslink.com åˆ†äº«é“¾æ¥ï¼Œè¯·åœ¨å°çº¢ä¹¦ App æˆ–ç™»å½•åç½‘é¡µä¸­ç‚¹å‡»åˆ†äº«)")
    else:
        print(f"âŒ {result['error']}")

    return result


def process_csv(csv_path: str, output_path: str = None):
    """
    æ‰¹é‡å¤„ç† CSV æ–‡ä»¶

    Args:
        csv_path: CSV æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    csv_path = Path(csv_path)
    if not csv_path.exists():
        print(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = csv_path.parent / f"{csv_path.stem}_processed.csv"

    # è¯»å– CSV
    results = []
    links = []

    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames or []

        # æŸ¥æ‰¾åŒ…å«é“¾æ¥çš„åˆ—
        link_col = None
        for col in ['é“¾æ¥', 'url', 'link', 'video_url', 'note_url']:
            if col in fieldnames:
                link_col = col
                break

        if not link_col:
            print(f"âŒ æœªæ‰¾åˆ°é“¾æ¥åˆ—ï¼Œå¯ç”¨çš„åˆ—: {fieldnames}")
            return

        print(f"\nğŸ“‹ ä»åˆ— '{link_col}' è¯»å–é“¾æ¥...")
        print("=" * 70)

        for row in reader:
            url = row.get(link_col, '').strip()
            if url:
                links.append({
                    'url': url,
                    'title': row.get('æ ‡é¢˜', '') or row.get('title', '') or '',
                    'row_data': row
                })

    print(f"\næ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")
    print("=" * 70)

    # å¤„ç†æ¯ä¸ªé“¾æ¥
    for i, link_info in enumerate(links, 1):
        print(f"\n[{i}/{len(links)}]", end='')
        result = process_url(link_info['url'])
        result['title'] = link_info['title']
        result['original_row'] = link_info['row_data']
        results.append(result)

    # ä¿å­˜ç»“æœ
    print(f"\n\n{'=' * 70}")
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("=" * 70)

    success = sum(1 for r in results if r['success'] and 'xhslink.com' in r['short_url'])
    simplified = sum(1 for r in results if r['short_url'] and 'xiaohongshu.com/explore/' in r['short_url'])
    failed = len(results) - success - simplified
    print(f"æ€»è®¡: {len(results)} | xhslinkåˆ†äº«é“¾æ¥: {success} | ç®€åŒ–é“¾æ¥: {simplified} | å¤±è´¥: {failed}")

    # å†™å…¥ CSV
    if results:
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            original_fields = list(results[0].get('original_row', {}).keys())

            writer = csv.DictWriter(f, fieldnames=original_fields + ['ç¬”è®°ID', 'åˆ†äº«é“¾æ¥', 'ç®€åŒ–é“¾æ¥', 'çŠ¶æ€', 'é”™è¯¯ä¿¡æ¯'])
            writer.writeheader()

            for r in results:
                row_data = r.get('original_row', {})
                row_data.update({
                    'ç¬”è®°ID': r['note_id'],
                    'åˆ†äº«é“¾æ¥': r['short_url'] if 'xhslink.com' in r['short_url'] else '',
                    'ç®€åŒ–é“¾æ¥': r['short_url'] if 'xiaohongshu.com/explore/' in r['short_url'] else '',
                    'çŠ¶æ€': 'æˆåŠŸ' if r['success'] or r['short_url'] else 'å¤±è´¥',
                    'é”™è¯¯ä¿¡æ¯': r['error']
                })
                writer.writerow(row_data)

        print(f"ğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")


def process_json(json_path: str, output_path: str = None):
    """
    å¤„ç† JSON æ–‡ä»¶

    Args:
        json_path: JSON æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    json_path = Path(json_path)
    if not json_path.exists():
        print(f"âŒ JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = json_path.parent / f"{json_path.stem}_processed.json"

    # è¯»å– JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    if not isinstance(data, list):
        print("âŒ JSON æ ¼å¼å¿…é¡»æ˜¯æ•°ç»„")
        return

    print(f"\nğŸ“‹ æ‰¾åˆ° {len(data)} æ¡è®°å½•")
    print("=" * 70)

    results = []
    for i, item in enumerate(data, 1):
        url = ''
        for field in ['url', 'video_url', 'note_url', 'link', 'é“¾æ¥']:
            if field in item and item[field]:
                url = item[field]
                break

        if not url:
            print(f"\n[{i}/{len(data)}] âš ï¸  æœªæ‰¾åˆ°é“¾æ¥")
            results.append({
                'original_item': item,
                'note_id': '',
                'short_url': '',
                'success': False,
                'error': 'æœªæ‰¾åˆ°é“¾æ¥'
            })
            continue

        print(f"\n[{i}/{len(data)}]", end='')
        result = process_url(url)
        result['original_item'] = item
        results.append(result)

    # ä¿å­˜ç»“æœ
    print(f"\n\n{'=' * 70}")
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("=" * 70)

    success = sum(1 for r in results if r['success'] and 'xhslink.com' in r['short_url'])
    simplified = sum(1 for r in results if r['short_url'] and 'xiaohongshu.com/explore/' in r['short_url'])
    failed = len(results) - success - simplified
    print(f"æ€»è®¡: {len(results)} | xhslinkåˆ†äº«é“¾æ¥: {success} | ç®€åŒ–é“¾æ¥: {simplified} | å¤±è´¥: {failed}")

    # å†™å…¥ JSON
    output_data = []
    for r in results:
        item = r.get('original_item', {})
        item.update({
            'note_id': r['note_id'],
            'share_link': r['short_url'] if 'xhslink.com' in r['short_url'] else '',
            'short_link': r['short_url'] if 'xiaohongshu.com/explore/' in r['short_url'] else '',
            'share_success': r['success'] if 'xhslink.com' in r['short_url'] else False,
            'share_error': r['error']
        })
        output_data.append(item)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦é“¾æ¥å¤„ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. å¤„ç†å•ä¸ªé“¾æ¥:
   python xhs_share_link_generator.py --url "https://www.xiaohongshu.com/explore/69983ebb00000000150304d8"

2. æ‰¹é‡å¤„ç† CSV:
   python xhs_share_link_generator.py --csv notes.csv

3. ä» JSON æ–‡ä»¶è¯»å–:
   python xhs_share_link_generator.py --json videos.json

4. æŒ‡å®šè¾“å‡ºæ–‡ä»¶:
   python xhs_share_link_generator.py --csv notes.csv --output result.csv

æ³¨æ„äº‹é¡¹:
- xhslink.com åˆ†äº«é“¾æ¥éœ€è¦åœ¨å°çº¢ä¹¦ App æˆ–ç™»å½•åçš„ç½‘é¡µä¸­ç‚¹å‡»åˆ†äº«æŒ‰é’®ç”Ÿæˆ
- å¦‚æœé…ç½®äº† config/cookies.txt ä¸­çš„å°çº¢ä¹¦ Cookieï¼Œå¯ä»¥å°è¯•è·å–åˆ†äº«é“¾æ¥
- å¦‚æœæ— æ³•è·å– xhslink.comï¼Œå·¥å…·ä¼šè¿”å›ç®€åŒ–çš„ xiaohongshu.com/explore/ é“¾æ¥
        """
    )

    parser.add_argument('--url', help='å•ä¸ªå°çº¢ä¹¦é“¾æ¥')
    parser.add_argument('--csv', help='CSV æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', help='JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    if not any([args.url, args.csv, args.json]):
        parser.print_help()
        print("\nâŒ è¯·æä¾› --urlã€--csv æˆ– --json å‚æ•°")
        return

    print("=" * 70)
    print("å°çº¢ä¹¦é“¾æ¥å¤„ç†å·¥å…·")
    print("=" * 70)

    if args.url:
        result = process_url(args.url)
        if result['short_url']:
            print(f"\n{'=' * 70}")
            print("å¤„ç†ç»“æœ:")
            print("=" * 70)
            print(f"ç¬”è®°ID: {result['note_id']}")
            print(f"åŸå§‹é“¾æ¥: {result['original_url']}")
            print(f"å¤„ç†ç»“æœ: {result['short_url']}")
            if result['error']:
                print(f"æç¤º: {result['error']}")

    elif args.csv:
        process_csv(args.csv, args.output)

    elif args.json:
        process_json(args.json, args.output)


if __name__ == "__main__":
    main()
