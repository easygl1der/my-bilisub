#!/usr/bin/env python3
"""
å°çº¢ä¹¦ xsec_token è·å–å·¥å…·

é€šè¿‡å°çº¢ä¹¦æœç´¢æ¥å£ï¼Œä½¿ç”¨ note_id è·å–å¸¦ xsec_token çš„å®Œæ•´é“¾æ¥

åŸç†ï¼š
1. ä½¿ç”¨ Cookie è°ƒç”¨å°çº¢ä¹¦æœç´¢æ¥å£
2. ç”¨ note_id ä½œä¸ºå…³é”®è¯æœç´¢
3. ä»æœç´¢ç»“æœä¸­æå– xsec_token
4. ç”Ÿæˆå®Œæ•´è®¿é—®é“¾æ¥

ä½¿ç”¨ç¤ºä¾‹:
    # å¤„ç†å•ä¸ª note_id
    python xhs_xsec_token_fetcher.py --note-id "690eaf15000000000700d395"

    # å¤„ç†å®Œæ•´ URLï¼ˆè‡ªåŠ¨æå– note_idï¼‰
    python xhs_xsec_token_fetcher.py --url "https://www.xiaohongshu.com/explore/69983ebb00000000150304d8"

    # æ‰¹é‡å¤„ç† CSV
    python xhs_xsec_token_fetcher.py --csv notes.csv

    # ä» JSON æ–‡ä»¶è¯»å–
    python xhs_xsec_token_fetcher.py --json videos.json

æ³¨æ„äº‹é¡¹:
- éœ€è¦åœ¨ config/cookies.txt ä¸­é…ç½®å°çº¢ä¹¦ Cookie
- Cookie å¿…é¡»åŒ…å« web_sessionï¼ˆç™»å½•æ€ä»¤ç‰Œï¼‰
- å»ºè®®æ·»åŠ éšæœºå»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
"""

import sys
import re
import json
import csv
import argparse
import random
import time
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import requests


# ==================== é…ç½® ====================

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'application/json, text/plain, */*',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    'Origin': 'https://www.xiaohongshu.com',
    'Referer': 'https://www.xiaohongshu.com/',
    'Content-Type': 'application/json',
}

SEARCH_URL = "https://edith.xiaohongshu.com/api/sns/web/v1/search/notes"
NOTE_DETAIL_URL = "https://edith.xiaohongshu.com/api/sns/web/v1/feed"


# ==================== Cookie è¯»å– ====================

def read_xhs_cookie() -> dict:
    """
    ä» config/cookies.txt è¯»å–å°çº¢ä¹¦ Cookie

    Returns:
        Cookie å­—å…¸
    """
    cookie_file = Path(__file__).parent / "config" / "cookies.txt"

    if not cookie_file.exists():
        print("âŒ Cookie æ–‡ä»¶ä¸å­˜åœ¨: config/cookies.txt")
        print("ğŸ’¡ è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼é…ç½®:")
        print("   [xiaohongshu]")
        print("   a1=xxx")
        print("   web_session=xxx  # æœ€é‡è¦ï¼Œç™»å½•æ€ä»¤ç‰Œ")
        print("   webId=xxx")
        return {}

    with open(cookie_file, 'r', encoding='utf-8') as f:
        content = f.read()

    cookies = {}

    # æŸ¥æ‰¾ [xiaohongshu] éƒ¨åˆ†
    xhs_section = re.search(r'\[xiaohongshu\](.*?)(?:\[|$)', content, re.DOTALL)
    if xhs_section:
        section = xhs_section.group(1)
        for line in section.split('\n'):
            line = line.strip()
            if '=' in line and not line.startswith('#') and not line.startswith('['):
                key, value = line.split('=', 1)
                cookies[key.strip()] = value.strip()
    else:
        # å°è¯•æŸ¥æ‰¾ xiaohongshu_full= æ ¼å¼
        match = re.search(r'xiaohongshu_full=([^\n]+)', content)
        if match:
            cookie_str = match.group(1)
            for item in cookie_str.split(';'):
                item = item.strip()
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies[key.strip()] = value.strip()

    if not cookies:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å°çº¢ä¹¦ Cookie")
        print("ğŸ’¡ è¯·åœ¨ config/cookies.txt ä¸­é…ç½® [xiaohongshu] éƒ¨åˆ†")
        return {}

    # æ£€æŸ¥æ˜¯å¦åŒ…å« web_session
    if 'web_session' not in cookies:
        print("âš ï¸  Cookie ä¸­ç¼ºå°‘ web_sessionï¼ˆç™»å½•æ€ä»¤ç‰Œï¼‰")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²ç™»å½•å°çº¢ä¹¦ç½‘é¡µç‰ˆå¹¶è·å–æ­£ç¡®çš„ Cookie")

    print(f"âœ… å·²è¯»å– Cookieï¼ŒåŒ…å« {len(cookies)} ä¸ªå­—æ®µ")
    return cookies


# ==================== URL è§£æ ====================

def extract_note_id_from_url(url: str) -> str:
    """
    ä»å°çº¢ä¹¦ URL ä¸­æå– note_id

    æ”¯æŒçš„ URL æ ¼å¼ï¼š
    - https://www.xiaohongshu.com/explore/69983ebb00000000150304d8
    - https://www.xiaohongshu.com/discovery/item/69983ebb00000000150304d8
    - http://xhslink.com/xxx (ä¼šè‡ªåŠ¨é‡å®šå‘)
    - çº¯ note_id: 69983ebb00000000150304d8

    Args:
        url: å°çº¢ä¹¦ URL æˆ– note_id

    Returns:
        æå–çš„ note_idï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not url:
        return ""

    url = url.strip()

    # å¦‚æœå·²ç»æ˜¯çº¯ note_idï¼ˆ24ä½åå…­è¿›åˆ¶ï¼‰
    if re.match(r'^[a-f0-9]{24}$', url, re.IGNORECASE):
        return url

    # å¦‚æœæ˜¯çŸ­é“¾æ¥ï¼Œå°è¯•é‡å®šå‘è·å–çœŸå® URL
    if 'xhslink.com' in url:
        try:
            response = requests.get(url, headers=HEADERS, timeout=10, allow_redirects=True)
            url = response.url
        except:
            pass

    # ä» URL ä¸­æå– note_id
    patterns = [
        r'/explore/([a-f0-9]{24})',
        r'/discovery/item/([a-f0-9]{24})',
        r'/item/([a-f0-9]{24})',
        r'noteId=([a-f0-9]{24})',
        r'note_id=([a-f0-9]{24})',
    ]

    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            return match.group(1)

    # æœ€åå°è¯•æå–ä»»æ„24ä½åå…­è¿›åˆ¶
    match = re.search(r'([a-f0-9]{24})', url, re.IGNORECASE)
    if match:
        return match.group(1)

    return ""


# ==================== xsec_token è·å– ====================

def get_xsec_token_via_note_detail(note_id: str, cookies: dict) -> dict:
    """
    é€šè¿‡ç¬”è®°è¯¦æƒ…æ¥å£è·å– note_id å¯¹åº”çš„ xsec_token

    Args:
        note_id: ç¬”è®°IDï¼ˆ24ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        cookies: å°çº¢ä¹¦ Cookie å­—å…¸

    Returns:
        {'success': bool, 'note_id': str, 'xsec_token': str, 'full_url': str, 'error': str}
    """
    result = {
        'success': False,
        'note_id': note_id,
        'xsec_token': '',
        'full_url': '',
        'error': ''
    }

    # éªŒè¯ note_id æ ¼å¼
    if not note_id or len(note_id) < 10:
        result['error'] = f"æ— æ•ˆçš„ note_id: {note_id}"
        return result

    # å°è¯•å¤šä¸ªç¬”è®°è¯¦æƒ…æ¥å£
    urls_to_try = [
        f"https://edith.xiaohongshu.com/api/sns/web/v1/note/feed",
        f"https://edith.xiaohongshu.com/api/sns/web/v1/note",
        f"https://edith.xiaohongshu.com/api/sns/web/v1/feed",
    ]

    headers = {
        **HEADERS,
        'Cookie': '; '.join([f"{k}={v}" for k, v in cookies.items()]),
    }

    for url in urls_to_try:
        try:
            # æ–¹å¼1: GET è¯·æ±‚ï¼Œä½¿ç”¨ note_id æŸ¥è¯¢å‚æ•°
            params = {
                'note_id': note_id,
                'source_note_id': '',
                'image_formats': 'jpg,webp,avif',
            }
            response = requests.get(url, headers=headers, params=params, timeout=15)

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                print(f"    è°ƒè¯•: {url} è¿”å›çŠ¶æ€ç  {response.status_code}")
                continue

            # æ£€æŸ¥æ˜¯å¦è¿”å›äº† HTMLï¼ˆå¯èƒ½æ˜¯é‡å®šå‘åˆ°éªŒè¯é¡µï¼‰
            content_type = response.headers.get('content-type', '')
            if 'text/html' in content_type or '<!DOCTYPE' in response.text[:100] or '<html' in response.text[:100]:
                print(f"    è°ƒè¯•: {url} è¿”å›äº† HTML (content-type: {content_type})ï¼Œè·³è¿‡")
                continue

            data = response.json()

            # æ£€æŸ¥å“åº”
            if data.get('code') == 0:
                # å°è¯•ä»å“åº”ä¸­æå– xsec_token
                note_data = data.get('data', {}).get('items', [{}])[0] if data.get('data', {}).get('items') else data.get('data', {})
                if isinstance(note_data, dict) and 'xsec_token' in note_data:
                    xsec_token = note_data['xsec_token']
                    result['xsec_token'] = xsec_token
                    result['full_url'] = f"https://www.xiaohongshu.com/discovery/item/{note_id}?xsec_token={xsec_token}&xsec_source=pc_feed"
                    result['success'] = True
                    result['error'] = ''
                    return result
        except Exception as e:
            print(f"    è°ƒè¯•: {url} å¤±è´¥: {e}")
            continue

    # æ–¹å¼2: å°è¯• POST è¯·æ±‚
    try:
        payload = {
            'note_id': note_id,
            'num': 1,
            'cursor': '',
        }
        response = requests.post("https://edith.xiaohongshu.com/api/sns/web/v1/feed", headers=headers, json=payload, timeout=15)
        data = response.json()

        if data.get('code') == 0:
            items = data.get('data', {}).get('items', [])
            for item in items:
                if item.get('id') == note_id or item.get('model', {}).get('note', {}).get('id') == note_id:
                    xsec_token = item.get('xsec_token', '')
                    if xsec_token:
                        result['xsec_token'] = xsec_token
                        result['full_url'] = f"https://www.xiaohongshu.com/discovery/item/{note_id}?xsec_token={xsec_token}&xsec_source=pc_feed"
                        result['success'] = True
                        return result
    except Exception as e:
        result['error'] = f"ç¬”è®°è¯¦æƒ…æ¥å£è¯·æ±‚å¤±è´¥: {e}"

    return result


def get_xsec_token_via_search(note_id: str, cookies: dict) -> dict:
    """
    é€šè¿‡æœç´¢æ¥å£è·å– note_id å¯¹åº”çš„ xsec_token

    Args:
        note_id: ç¬”è®°IDï¼ˆ24ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        cookies: å°çº¢ä¹¦ Cookie å­—å…¸

    Returns:
        {'success': bool, 'note_id': str, 'xsec_token': str, 'full_url': str, 'error': str}
    """
    result = {
        'success': False,
        'note_id': note_id,
        'xsec_token': '',
        'full_url': '',
        'error': ''
    }

    # éªŒè¯ note_id æ ¼å¼
    if not note_id or len(note_id) < 10:
        result['error'] = f"æ— æ•ˆçš„ note_id: {note_id}"
        return result

    # è°ƒç”¨æœç´¢æ¥å£
    payload = {
        "keyword": note_id,
        "page": 1,
        "page_size": 20,
        "search_id": "",
        "sort": "general",
        "note_type": 0,
    }

    headers = {
        **HEADERS,
        'Cookie': '; '.join([f"{k}={v}" for k, v in cookies.items()])
    }

    try:
        response = requests.post(SEARCH_URL, headers=headers, json=payload, timeout=15)
        response.raise_for_status()

        data = response.json()

        # æ£€æŸ¥æ˜¯å¦ç™»å½•
        if data.get('code') == -101:
            result['error'] = "æœªç™»å½•æˆ– Cookie å·²å¤±æ•ˆï¼ˆcode: -101ï¼‰"
            return result

        # æ£€æŸ¥å“åº”çŠ¶æ€
        if data.get('success', False) is False and data.get('code') != 0:
            result['error'] = f"æ¥å£è¿”å›é”™è¯¯: {data.get('msg', 'Unknown error')} (code: {data.get('code')})"
            return result

        # è§£ææœç´¢ç»“æœ
        items = data.get('data', {}).get('items', [])

        for item in items:
            # æ–¹æ³•1: ä» item.id åˆ¤æ–­
            if item.get('id') == note_id:
                xsec_token = item.get('xsec_token', '')
                if xsec_token:
                    result['xsec_token'] = xsec_token
                    result['full_url'] = f"https://www.xiaohongshu.com/discovery/item/{note_id}?xsec_token={xsec_token}&xsec_source=pc_search"
                    result['success'] = True
                    return result

            # æ–¹æ³•2: ä» note_card.id åˆ¤æ–­
            note_card = item.get('note_card', {})
            if note_card.get('id') == note_id:
                xsec_token = item.get('xsec_token', '')
                if xsec_token:
                    result['xsec_token'] = xsec_token
                    result['full_url'] = f"https://www.xiaohongshu.com/discovery/item/{note_id}?xsec_token={xsec_token}&xsec_source=pc_search"
                    result['success'] = True
                    return result

        # æ–¹æ³•3: ä» note_card.note_id åˆ¤æ–­
        for item in items:
            note_card = item.get('note_card', {})
            if note_card.get('note_id') == note_id:
                xsec_token = item.get('xsec_token', '')
                if xsec_token:
                    result['xsec_token'] = xsec_token
                    result['full_url'] = f"https://www.xiaohongshu.com/discovery/item/{note_id}?xsec_token={xsec_token}&xsec_source=pc_search"
                    result['success'] = True
                    return result

        # æœç´¢ç»“æœä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ note_id
        result['error'] = f"æœç´¢ç»“æœä¸­æœªæ‰¾åˆ° note_id: {note_id}ï¼ˆå¯èƒ½ç¬”è®°å·²è¢«åˆ é™¤æˆ–ä¸å¯è§ï¼‰"

    except requests.exceptions.Timeout:
        result['error'] = "è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
    except requests.exceptions.RequestException as e:
        result['error'] = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
    except json.JSONDecodeError:
        result['error'] = "æ¥å£è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼"
    except Exception as e:
        result['error'] = f"æœªçŸ¥é”™è¯¯: {e}"

    return result


def get_xsec_token(note_id: str, cookies: dict) -> dict:
    """
    è·å– note_id å¯¹åº”çš„ xsec_token
    å…ˆå°è¯•ç¬”è®°è¯¦æƒ…æ¥å£ï¼Œå¤±è´¥åå°è¯•æœç´¢æ¥å£

    Args:
        note_id: ç¬”è®°IDï¼ˆ24ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        cookies: å°çº¢ä¹¦ Cookie å­—å…¸

    Returns:
        {'success': bool, 'note_id': str, 'xsec_token': str, 'full_url': str, 'error': str}
    """
    result = {
        'success': False,
        'note_id': note_id,
        'xsec_token': '',
        'full_url': '',
        'error': ''
    }

    # éªŒè¯ note_id æ ¼å¼
    if not note_id or len(note_id) < 10:
        result['error'] = f"æ— æ•ˆçš„ note_id: {note_id}"
        return result

    # æ–¹æ³•1: å°è¯•ç¬”è®°è¯¦æƒ…æ¥å£ï¼ˆä¸å®¹æ˜“è¢«é£æ§ï¼‰
    print("  ğŸ“ å°è¯•ç¬”è®°è¯¦æƒ…æ¥å£...")
    result = get_xsec_token_via_note_detail(note_id, cookies)
    if result['success']:
        return result
    print(f"  âš ï¸  ç¬”è®°è¯¦æƒ…æ¥å£å¤±è´¥: {result['error']}")

    # æ–¹æ³•2: å°è¯•æœç´¢æ¥å£
    print("  ğŸ” å°è¯•æœç´¢æ¥å£...")
    result = get_xsec_token_via_search(note_id, cookies)

    return result


def process_single_note(note_id: str, cookies: dict, delay: bool = True) -> dict:
    """
    å¤„ç†å•ä¸ª note_id

    Args:
        note_id: ç¬”è®°ID
        cookies: Cookie å­—å…¸
        delay: æ˜¯å¦æ·»åŠ éšæœºå»¶è¿Ÿ

    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    result = get_xsec_token(note_id, cookies)

    print(f"  Note ID: {note_id}")
    if result['success']:
        print(f"  âœ… xsec_token: {result['xsec_token'][:20]}...")
        print(f"  ğŸ”— å®Œæ•´é“¾æ¥: {result['full_url']}")
    else:
        print(f"  âŒ {result['error']}")

    # éšæœºå»¶è¿Ÿï¼Œé¿å…é¢‘ç‡é™åˆ¶
    if delay and result['success']:
        sleep_time = random.uniform(1, 3)
        time.sleep(sleep_time)

    return result


# ==================== æ‰¹é‡å¤„ç† ====================

def process_csv(csv_path: str, cookies: dict, output_path: str = None, delay: bool = True):
    """
    æ‰¹é‡å¤„ç† CSV æ–‡ä»¶ä¸­çš„ note_id

    Args:
        csv_path: CSV æ–‡ä»¶è·¯å¾„
        cookies: Cookie å­—å…¸
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        delay: æ˜¯å¦æ·»åŠ éšæœºå»¶è¿Ÿ
    """
    csv_path = Path(csv_path)
    if not csv_path.exists():
        print(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = csv_path.parent / f"{csv_path.stem}_xsec.csv"

    # è¯»å– CSV
    results = []
    note_ids = []

    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames or []

        # æŸ¥æ‰¾åŒ…å«ç¬”è®°IDçš„åˆ—
        note_id_col = None
        url_col = None
        for col in ['ç¬”è®°ID', 'note_id', 'noteid', 'id', 'ç¬”è®°id']:
            if col in fieldnames:
                note_id_col = col
                break
        for col in ['é“¾æ¥', 'url', 'link', 'video_url', 'note_url']:
            if col in fieldnames:
                url_col = col
                break

        if not note_id_col and not url_col:
            print(f"âŒ æœªæ‰¾åˆ°ç¬”è®°IDæˆ–é“¾æ¥åˆ—ï¼Œå¯ç”¨çš„åˆ—: {fieldnames}")
            return

        print(f"\nğŸ“‹ ä»åˆ— '{note_id_col or url_col}' è¯»å–...")
        print("=" * 70)

        for row in reader:
            note_id = ''
            if note_id_col:
                note_id = row.get(note_id_col, '').strip()

            # å¦‚æœæ²¡æœ‰ç¬”è®°IDï¼Œå°è¯•ä»é“¾æ¥ä¸­æå–
            if not note_id and url_col:
                url = row.get(url_col, '').strip()
                # ä»é“¾æ¥ä¸­æå– note_id
                patterns = [
                    r'/explore/([a-f0-9]{24})',
                    r'/discovery/item/([a-f0-9]{24})',
                    r'([a-f0-9]{24})',
                ]
                for pattern in patterns:
                    match = re.search(pattern, url, re.IGNORECASE)
                    if match:
                        note_id = match.group(1)
                        break

            if note_id:
                note_ids.append({
                    'note_id': note_id,
                    'row_data': row
                })

    print(f"\næ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°ID")
    print("=" * 70)

    # å¤„ç†æ¯ä¸ª note_id
    for i, note_info in enumerate(note_ids, 1):
        print(f"\n[{i}/{len(note_ids)}]", end='')
        result = process_single_note(note_info['note_id'], cookies, delay)
        result['original_row'] = note_info['row_data']
        results.append(result)

    # ä¿å­˜ç»“æœ
    print(f"\n\n{'=' * 70}")
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("=" * 70)

    success = sum(1 for r in results if r['success'])
    failed = len(results) - success
    print(f"æ€»è®¡: {len(results)} | æˆåŠŸ: {success} | å¤±è´¥: {failed}")

    # å†™å…¥ CSV
    if results:
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            original_fields = list(results[0].get('original_row', {}).keys())

            writer = csv.DictWriter(f, fieldnames=original_fields + ['xsec_token', 'å®Œæ•´é“¾æ¥', 'çŠ¶æ€', 'é”™è¯¯ä¿¡æ¯'])
            writer.writeheader()

            for r in results:
                row_data = r.get('original_row', {})
                row_data.update({
                    'xsec_token': r['xsec_token'],
                    'å®Œæ•´é“¾æ¥': r['full_url'],
                    'çŠ¶æ€': 'æˆåŠŸ' if r['success'] else 'å¤±è´¥',
                    'é”™è¯¯ä¿¡æ¯': r['error']
                })
                writer.writerow(row_data)

        print(f"ğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")


def process_json(json_path: str, cookies: dict, output_path: str = None, delay: bool = True):
    """
    å¤„ç† JSON æ–‡ä»¶ä¸­çš„ note_id

    Args:
        json_path: JSON æ–‡ä»¶è·¯å¾„
        cookies: Cookie å­—å…¸
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        delay: æ˜¯å¦æ·»åŠ éšæœºå»¶è¿Ÿ
    """
    json_path = Path(json_path)
    if not json_path.exists():
        print(f"âŒ JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = json_path.parent / f"{json_path.stem}_xsec.json"

    # è¯»å– JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    if not isinstance(data, list):
        print("âŒ JSON æ ¼å¼å¿…é¡»æ˜¯æ•°ç»„")
        return

    print(f"\nğŸ“‹ æ‰¾åˆ° {len(data)} æ¡è®°å½•")
    print("=" * 70)

    results = []
    for i, item in enumerate(data, 1):
        note_id = ''

        # æŸ¥æ‰¾ note_id å­—æ®µ
        for field in ['note_id', 'noteId', 'id', 'ç¬”è®°id', 'ç¬”è®°ID']:
            if field in item and item[field]:
                note_id = item[field]
                break

        # å¦‚æœæ²¡æœ‰ note_idï¼Œå°è¯•ä»é“¾æ¥ä¸­æå–
        if not note_id:
            for field in ['url', 'video_url', 'note_url', 'link', 'é“¾æ¥']:
                if field in item and item[field]:
                    url = item[field]
                    patterns = [
                        r'/explore/([a-f0-9]{24})',
                        r'/discovery/item/([a-f0-9]{24})',
                        r'([a-f0-9]{24})',
                    ]
                    for pattern in patterns:
                        match = re.search(pattern, url, re.IGNORECASE)
                        if match:
                            note_id = match.group(1)
                            break
                    break

        if not note_id:
            print(f"\n[{i}/{len(data)}] âš ï¸  æœªæ‰¾åˆ°ç¬”è®°ID")
            results.append({
                'original_item': item,
                'note_id': '',
                'xsec_token': '',
                'full_url': '',
                'success': False,
                'error': 'æœªæ‰¾åˆ°ç¬”è®°ID'
            })
            continue

        print(f"\n[{i}/{len(data)}]", end='')
        result = process_single_note(note_id, cookies, delay)
        result['original_item'] = item
        results.append(result)

    # ä¿å­˜ç»“æœ
    print(f"\n\n{'=' * 70}")
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("=" * 70)

    success = sum(1 for r in results if r['success'])
    failed = len(results) - success
    print(f"æ€»è®¡: {len(results)} | æˆåŠŸ: {success} | å¤±è´¥: {failed}")

    # å†™å…¥ JSON
    output_data = []
    for r in results:
        item = r.get('original_item', {})
        item.update({
            'xsec_token': r['xsec_token'],
            'full_url': r['full_url'],
            'xsec_success': r['success'],
            'xsec_error': r['error']
        })
        output_data.append(item)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦ xsec_token è·å–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. å¤„ç†å•ä¸ª note_id:
   python xhs_xsec_token_fetcher.py --note-id "690eaf15000000000700d395"

2. å¤„ç†å®Œæ•´ URL:
   python xhs_xsec_token_fetcher.py --url "https://www.xiaohongshu.com/explore/69983ebb00000000150304d8"

3. æ‰¹é‡å¤„ç† CSV:
   python xhs_xsec_token_fetcher.py --csv notes.csv

4. ä» JSON æ–‡ä»¶è¯»å–:
   python xhs_xsec_token_fetcher.py --json videos.json

5. æŒ‡å®šè¾“å‡ºæ–‡ä»¶:
   python xhs_xsec_token_fetcher.py --csv notes.csv --output result.csv

6. ç¦ç”¨å»¶è¿Ÿï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œå¯èƒ½æœ‰é£é™©ï¼‰:
   python xhs_xsec_token_fetcher.py --csv notes.csv --no-delay

æ³¨æ„äº‹é¡¹:
- éœ€è¦åœ¨ config/cookies.txt ä¸­é…ç½®å°çº¢ä¹¦ Cookie
- Cookie å¿…é¡»åŒ…å« web_sessionï¼ˆç™»å½•æ€ä»¤ç‰Œï¼‰
- å»ºè®®å¯ç”¨å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        """
    )

    parser.add_argument('--note-id', help='å•ä¸ªç¬”è®°ID')
    parser.add_argument('--url', help='å°çº¢ä¹¦å®Œæ•´URLï¼ˆä¼šè‡ªåŠ¨æå–note_idï¼‰')
    parser.add_argument('--csv', help='CSV æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', help='JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-delay', action='store_true', help='ç¦ç”¨éšæœºå»¶è¿Ÿï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œå¯èƒ½æœ‰é£é™©ï¼‰')

    args = parser.parse_args()

    if not any([args.note_id, args.url, args.csv, args.json]):
        parser.print_help()
        print("\nâŒ è¯·æä¾› --note-idã€--urlã€--csv æˆ– --json å‚æ•°")
        return

    print("=" * 70)
    print("å°çº¢ä¹¦ xsec_token è·å–å·¥å…·")
    print("=" * 70)

    # è¯»å– Cookie
    cookies = read_xhs_cookie()
    if not cookies:
        print("\nâŒ æœªè¯»å–åˆ°æœ‰æ•ˆ Cookieï¼Œæ— æ³•ç»§ç»­")
        return

    if 'web_session' not in cookies:
        print("\nâš ï¸  Cookie ä¸­ç¼ºå°‘ web_sessionï¼Œå¯èƒ½å¯¼è‡´å¤±è´¥")

    delay = not args.no_delay
    if delay:
        print(f"\nâ±ï¸  å»¶è¿Ÿæ¨¡å¼: å¯ç”¨ï¼ˆéšæœº 1-3 ç§’ï¼‰")
    else:
        print(f"\nâ±ï¸  å»¶è¿Ÿæ¨¡å¼: ç¦ç”¨ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œå¯èƒ½æœ‰é£é™©ï¼‰")

    # å¤„ç† URL æˆ– note_id
    note_id = None
    if args.url:
        note_id = extract_note_id_from_url(args.url)
        if not note_id:
            print(f"\nâŒ æ— æ³•ä» URL æå– note_id: {args.url}")
            return
        print(f"\nä» URL æå– note_id: {note_id}")
    elif args.note_id:
        note_id = args.note_id

    if note_id:
        print(f"\nå¤„ç†ç¬”è®°: {note_id}")
        print("-" * 70)
        result = process_single_note(note_id, cookies, delay)

        # ä¿å­˜ç»“æœ
        output_dir = Path(__file__).parent / "output" / "xsec_tokens"
        output_dir.mkdir(parents=True, exist_ok=True)
        date_str = datetime.now().strftime('%Y%m%d')
        output_path = output_dir / f"xsec_tokens_{date_str}.json"

        # è¯»å–ç°æœ‰ç»“æœ
        existing_data = []
        if output_path.exists():
            with open(output_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)

        # æ·»åŠ æ–°ç»“æœ
        existing_data.append({
            'input': args.url or args.note_id,
            'note_id': result['note_id'],
            'xsec_token': result['xsec_token'],
            'full_url': result['full_url'],
            'success': result['success'],
            'error': result['error'],
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })

        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")

    elif args.csv:
        process_csv(args.csv, cookies, args.output, delay)

    elif args.json:
        process_json(args.json, cookies, args.output, delay)


if __name__ == "__main__":
    main()
