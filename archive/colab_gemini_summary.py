#!/usr/bin/env python3
"""
åœ¨ Google Colab ä¸Šè¿è¡Œçš„ Gemini å­—å¹•æ‘˜è¦ç”Ÿæˆå™¨

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨ Colab ä¸­åˆ›å»ºæ–°ç¬”è®°æœ¬
2. å¤åˆ¶æ­¤ä»£ç åˆ°ä¸€ä¸ªå•å…ƒæ ¼
3. è¿è¡Œå¹¶æŒ‰æç¤ºæ“ä½œ
"""

import os
import time
import threading
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict
from google.colab import files, output

# ==================== é…ç½®åŒº ====================

# è¯·åœ¨è¿™é‡Œå¡«å…¥ä½ çš„ Gemini API Key
GEMINI_API_KEY = ""  # æˆ–è€…è¿è¡Œåæ‰‹åŠ¨è¾“å…¥

# å­—å¹•æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆColab ä¸­å»ºè®®ä¸Šä¼ åˆ° /content/subtitles/ï¼‰
SUBTITLE_DIR = "/content/subtitles"

# å¹¶å‘æ•°ï¼ˆå»ºè®® 3-5ï¼‰
MAX_WORKERS = 3

# æ¨¡å‹é€‰æ‹©
MODEL = 'gemini-2.5-flash-lite'  # æˆ– 'gemini-2.5-flash', 'gemini-2.5-pro'

# ==================== å®‰è£…ä¾èµ– ====================

def install_dependencies():
    """å®‰è£…å¿…è¦çš„ä¾èµ–"""
    print("ğŸ“¦ å®‰è£…ä¾èµ–...")
    !pip install -q google-generativeai

# ==================== Gemini API ====================

def setup_gemini(api_key: str):
    """è®¾ç½® Gemini API"""
    import google.generativeai as genai
    genai.configure(api_key=api_key)
    return genai

# ==================== SRT å¤„ç† ====================

def parse_srt(srt_path: Path) -> List[Dict]:
    """è§£æ SRT æ–‡ä»¶"""
    import re
    entries = []

    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?=\n\n|\n\d+\n|$)'
    matches = re.findall(pattern, content, re.DOTALL)

    for match in matches:
        index, start, end, text = match
        entries.append({
            'index': int(index),
            'start': start,
            'end': end,
            'text': text.strip().replace('\n', ' ')
        })

    return entries


def srt_to_text(srt_path: Path, max_length: int = 15000) -> str:
    """å°† SRT è½¬æ¢ä¸ºçº¯æ–‡æœ¬"""
    entries = parse_srt(srt_path)
    full_text = ' '.join([e['text'] for e in entries])

    if len(full_text) > max_length:
        full_text = full_text[:int(max_length * 0.8)] + '\n\n[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­...]'

    return full_text


# ==================== æ‘˜è¦ç”Ÿæˆ ====================

KNOWLEDGE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿å°†è§†é¢‘å­—å¹•å†…å®¹è½¬åŒ–ä¸ºç»“æ„åŒ–çš„çŸ¥è¯†åº“ç¬”è®°ã€‚è¯·è¯¦ç»†åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•ï¼Œè¾“å‡ºç”¨äºæ„å»º"ç¬¬äºŒå¤§è„‘"çš„ç¬”è®°ã€‚

# {title}

## ğŸ“‹ è§†é¢‘åŸºæœ¬ä¿¡æ¯
- **æ ¸å¿ƒä¸»é¢˜**: [ä¸€å¥è¯æ¦‚æ‹¬]
- **å†…å®¹ç»“æ„**: [æµæ°´è´¦å¼/è§‚ç‚¹è®ºè¯å¼/æ–°é—»æ±‡æ€»å¼/æ•…äº‹å™è¿°å¼]

## ğŸ“– è§†é¢‘å¤§æ„ï¼ˆ100-200å­—ï¼‰
[ç”¨ç²¾ç‚¼çš„ä¹¦é¢è¯­è¨€æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹ï¼Œå»é™¤å†—ä½™çš„å‰æƒ…æè¦å’Œæ— å…³ä¿¡æ¯]

## ğŸ¯ æ ¸å¿ƒè§‚ç‚¹ï¼ˆä¸‰æ®µè®ºï¼‰
[å¦‚æœè§†é¢‘æœ‰æ˜ç¡®è®ºç‚¹ï¼Œç”¨ä¸‰æ®µè®ºå½¢å¼å‘ˆç°]
- **å¤§å‰æ**: [æ™®éæ€§å‰ææˆ–èƒŒæ™¯]
- **å°å‰æ**: [å…·ä½“æƒ…å¢ƒæˆ–æ¡ä»¶]
- **ç»“è®º**: [æœ€ç»ˆè§‚ç‚¹æˆ–ä¸»å¼ ]

[å¦‚æœæ˜¯æ–°é—»åˆ†äº«ç±»ï¼Œåˆ™åˆ—å‡º]
- **æ–°é—»æ¡ç›®1**: [æ ‡é¢˜ + å…³é”®ä¿¡æ¯]
- **æ–°é—»æ¡ç›®2**: [æ ‡é¢˜ + å…³é”®ä¿¡æ¯]

## ğŸ“Š è®ºç‚¹è®ºæ®ç»“æ„
1. **ä¸»è¦è®ºç‚¹**
   - è®ºè¿°å†…å®¹: [è¯¦ç»†è¯´æ˜]
   - æ”¯æŒè®ºæ®: [æ•°æ®ã€æ¡ˆä¾‹ã€é€»è¾‘æ¨ç†]
   - å¯ä¿¡åº¦è¯„ä¼°: [é«˜/ä¸­/ä½ï¼Œè¯´æ˜ç†ç”±]

2. **æ¬¡è¦è®ºç‚¹**ï¼ˆå¦‚æœ‰ï¼‰
   - è®ºè¿°å†…å®¹: [è¯¦ç»†è¯´æ˜]
   - æ”¯æŒè®ºæ®: [æ•°æ®ã€æ¡ˆä¾‹ã€é€»è¾‘æ¨ç†]

## ğŸ’ é‡‘å¥/å¥½è¯å¥½å¥æå–
[è¯·æå–ä»¥ä¸‹ç±»å‹çš„å¥å­]

### 1. å¼•ç»æ®å…¸
- åŸå¥: "..."

### 2. æ•…äº‹/æ¡ˆä¾‹
- åŸå¥/æè¿°: "..."

### 3. ç²¾è¾Ÿè®ºæ®
- åŸå¥: "..."

### 4. æ·±åˆ»è§‚ç‚¹
- åŸå¥: "..."

### 5. å¥½è¯å¥½å¥
- åŸå¥: "..."

## ğŸ“ ä¹¦é¢æ–‡ç¨¿
[å°†å­—å¹•å†…å®¹æ•´ç†æˆç²¾ç‚¼çš„ä¹¦é¢è¡¨è¾¾æ–‡ç¨¿ï¼Œè¦æ±‚ï¼š
- å»é™¤æ‰€æœ‰å£è¯­åŒ–å†—ä½™ï¼ˆå¦‚"é‚£ä¸ª"ã€"å°±æ˜¯"ã€"ç„¶å"ç­‰ï¼‰
- ä½¿ç”¨æ­£å¼ã€ç»“æ„åŒ–çš„ä¹¦é¢è¯­è¨€
- ä¿ç•™æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘é“¾æ¡
- é€‚åˆä½œä¸ºæ¨¡å‹è®­ç»ƒçš„è¯­è¨€ææ–™
- å­—æ•°æ§åˆ¶åœ¨åŸæ–‡çš„30%-50%]

## âš ï¸ å†…å®¹è´¨é‡åˆ†æ
### æƒ…ç»ªæ“æ§æ£€æµ‹
- **åˆ¶é€ ç„¦è™‘/FOMOæƒ…ç»ª**: [æ˜¯/å¦]
- **åˆ†æ**: [å¦‚æœæœ‰ï¼Œè¯´æ˜ä½¿ç”¨äº†ä»€ä¹ˆæ‰‹æ³•]

### ä¿¡æ¯å¯é æ€§
- **ä¿¡æ¯æºå¯ä¿¡åº¦**: [é«˜/ä¸­/ä½]
- **äº‹å®æ ¸æŸ¥**: [æœ‰å“ªäº›å¯éªŒè¯çš„äº‹å®]
- **æ½œåœ¨åè§**: [æ˜¯å¦å­˜åœ¨æ˜æ˜¾åè§]

### çŸ¥è¯†ä»·å€¼è¯„ä¼°
- **æ–°é¢–æ€§**: [â˜…â˜…â˜…â˜…â˜…]
- **å®ç”¨æ€§**: [â˜…â˜…â˜…â˜…â˜…]
- **æ·±åº¦**: [â˜…â˜…â˜…â˜…â˜…]
- **æ¨èæ”¶è—**: [æ˜¯/å¦]

---
è¯·ç¡®ä¿è¾“å‡ºç»“æ„å®Œæ•´ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰å®è´¨å†…å®¹ã€‚å¦‚æœæŸéƒ¨åˆ†ç¡®å®ä¸é€‚ç”¨ï¼Œè¯·æ ‡æ³¨"[ä¸é€‚ç”¨]"å¹¶è¯´æ˜åŸå› ã€‚

---

## å­—å¹•å†…å®¹

{text}"""

def generate_summary(genai, srt_path: Path, model: str, index: int, total: int) -> Dict:
    """ç”Ÿæˆå•ä¸ªè§†é¢‘çš„æ‘˜è¦"""
    start_time = time.time()
    title = srt_path.stem

    print(f"\n[{index}/{total}] å¤„ç†: {title}")

    try:
        # è½¬æ¢ SRT ä¸ºæ–‡æœ¬
        srt_text = srt_to_text(srt_path)
        print(f"  æ–‡æœ¬é•¿åº¦: {len(srt_text):,} å­—ç¬¦")

        # è°ƒç”¨ Gemini API
        prompt = KNOWLEDGE_PROMPT.format(title=title, text=srt_text)
        gemini_model = genai.GenerativeModel(model)
        response = gemini_model.generate_content(prompt)

        elapsed = time.time() - start_time

        # è·å– token ä¿¡æ¯
        input_tokens = 0
        output_tokens = 0
        if hasattr(response, 'usage_metadata') and response.usage_metadata:
            input_tokens = response.usage_metadata.prompt_token_count or 0
            output_tokens = response.usage_metadata.candidates_token_count or 0

        print(f"  âœ… æˆåŠŸ! Tokens: {input_tokens + output_tokens:,} | è€—æ—¶: {elapsed:.2f}ç§’")

        return {
            'title': title,
            'summary': response.text.strip(),
            'file': srt_path.name,
            'index': index,
            'success': True,
            'tokens': input_tokens + output_tokens,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens
        }

    except Exception as e:
        elapsed = time.time() - start_time
        print(f"  âŒ å¤±è´¥: {str(e)} | è€—æ—¶: {elapsed:.2f}ç§’")

        return {
            'title': title,
            'summary': f"**å¤„ç†å¤±è´¥**: {str(e)}",
            'file': srt_path.name,
            'index': index,
            'success': False,
            'failed': True,
            'error': str(e)
        }


# ==================== ä¸»å¤„ç†å‡½æ•° ====================

def process_subtitles_colab(api_key: str, subtitle_dir: str, model: str, max_workers: int = 3):
    """åœ¨ Colab ä¸­å¤„ç†å­—å¹•"""
    import google.generativeai as genai

    # è®¾ç½® API
    genai.configure(api_key=api_key)

    subtitle_path = Path(subtitle_dir)

    if not subtitle_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {subtitle_path}")
        print(f"\nè¯·å…ˆä¸Šä¼ å­—å¹•æ–‡ä»¶åˆ° {subtitle_dir}")
        print(f"å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åˆ›å»ºç›®å½•å¹¶ä¸Šä¼ :")
        print(f"  !mkdir -p {subtitle_dir}")
        print(f"  ç„¶ååœ¨å·¦ä¾§æ–‡ä»¶é¢æ¿ä¸­ä¸Šä¼  SRT æ–‡ä»¶")
        return

    # è·å–æ‰€æœ‰ SRT æ–‡ä»¶
    srt_files = list(subtitle_path.glob("*.srt"))

    if not srt_files:
        print(f"âŒ æœªæ‰¾åˆ° SRT æ–‡ä»¶")
        return

    author_name = subtitle_path.name
    print(f"ğŸ“‚ ä½œè€…: {author_name}")
    print(f"ğŸ“„ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
    print(f"âš¡ å¹¶å‘æ•°: {max_workers}")
    print(f"ğŸ¤– æ¨¡å‹: {model}")
    print("=" * 60)

    start_time = time.time()
    all_results = []

    # å¹¶å‘å¤„ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(generate_summary, genai, srt_file, model, i, len(srt_files))
            for i, srt_file in enumerate(srt_files, 1)
        ]

        for future in futures:
            result = future.result()
            all_results.append(result)

    # æŒ‰åŸå§‹é¡ºåºæ’åº
    all_results.sort(key=lambda x: x['index'])

    # ç»Ÿè®¡
    summaries = []
    success_count = 0
    fail_count = 0
    total_tokens = 0
    total_input_tokens = 0
    total_output_tokens = 0

    for r in all_results:
        summaries.append(r)
        if r['success']:
            success_count += 1
            total_tokens += r.get('tokens', 0)
            total_input_tokens += r.get('input_tokens', 0)
            total_output_tokens += r.get('output_tokens', 0)
        else:
            fail_count += 1

    # ç”ŸæˆæŠ¥å‘Š
    report_path = Path(subtitle_dir).parent / f"{author_name}_AIæ€»ç»“.md"

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"# {author_name} è§†é¢‘å†…å®¹åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**è§†é¢‘æ•°é‡**: {len(srt_files)}\n\n")
        f.write(f"**æˆåŠŸå¤„ç†**: {success_count}\n\n")
        f.write(f"**Token ç»Ÿè®¡**: è¾“å…¥ {total_input_tokens:,} | è¾“å‡º {total_output_tokens:,} | æ€»è®¡ {total_tokens:,}\n\n")
        f.write("---\n\n")
        f.write("## å„è§†é¢‘æ‘˜è¦\n\n")

        for item in summaries:
            f.write(f"### {item['title']}\n\n")
            f.write(f"{item['summary']}\n\n")
            f.write(f"*æ¥æºæ–‡ä»¶: {item['file']}*\n\n")

    total_elapsed = time.time() - start_time

    print("\n" + "=" * 60)
    print(f"ğŸ“Š å¤„ç†å®Œæˆ!")
    print(f"  æˆåŠŸ: {success_count} | å¤±è´¥: {fail_count}")
    print(f"  æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
    print(f"  å¹³å‡æ¯è§†é¢‘: {total_elapsed/len(srt_files):.2f}ç§’")
    print(f"ğŸ“Š Token ç»Ÿè®¡:")
    print(f"  è¾“å…¥: {total_input_tokens:,} | è¾“å‡º: {total_output_tokens:,} | æ€»è®¡: {total_tokens:,}")
    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # ä¸‹è½½æŠ¥å‘Š
    print(f"\nğŸ“¥ æ­£åœ¨ä¸‹è½½æŠ¥å‘Š...")
    files.download(str(report_path))


# ==================== å…¥å£å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•° - åœ¨ Colab ä¸­è¿è¡Œ"""

    # å®‰è£…ä¾èµ–
    install_dependencies()

    # è·å– API Key
    api_key = GEMINI_API_KEY
    if not api_key:
        print("è¯·è¾“å…¥ä½ çš„ Gemini API Key:")
        api_key = input().strip()

    if not api_key:
        print("âŒ æœªæä¾› API Key")
        return

    # æ£€æŸ¥ç›®å½•
    subtitle_dir = SUBTITLE_DIR
    subtitle_path = Path(subtitle_dir)

    if not subtitle_path.exists():
        print(f"\nâš ï¸ ç›®å½• {subtitle_dir} ä¸å­˜åœ¨")
        print("æ­£åœ¨åˆ›å»ºç›®å½•...")
        subtitle_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ç›®å½•å·²åˆ›å»º: {subtitle_dir}")
        print("\nè¯·åœ¨å·¦ä¾§æ–‡ä»¶é¢æ¿ä¸­ä¸Šä¼  SRT å­—å¹•æ–‡ä»¶åˆ°è¯¥ç›®å½•ï¼Œç„¶åé‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼")
        return

    # ç¡®è®¤è¿è¡Œ
    print(f"\nğŸ“‚ å­—å¹•ç›®å½•: {subtitle_dir}")
    print(f"âš¡ å¹¶å‘æ•°: {MAX_WORKERS}")
    print(f"ğŸ¤– æ¨¡å‹: {MODEL}")

    response = input("\nå¼€å§‹å¤„ç†? (y/n): ").strip().lower()
    if response != 'y':
        print("å·²å–æ¶ˆ")
        return

    # å¤„ç†
    process_subtitles_colab(api_key, subtitle_dir, MODEL, MAX_WORKERS)


# è¿è¡Œ
if __name__ == "__main__":
    main()
