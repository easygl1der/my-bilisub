#!/usr/bin/env python3
"""
å°çº¢ä¹¦åˆ†äº«é“¾æ¥ç”Ÿæˆå·¥å…·ï¼ˆæµè§ˆå™¨ç‰ˆï¼‰

ä½¿ç”¨ Playwright è‡ªåŠ¨åŒ–æµè§ˆå™¨æ¥è·å– xhslink.com åˆ†äº«é“¾æ¥

ä½¿ç”¨æ–¹æ³•:
    python xhs_share_link_browser.py --url "https://www.xiaohongshu.com/explore/69983ebb00000000150304d8"
    python xhs_share_link_browser.py --csv notes.csv
"""

import asyncio
import sys
import re
import json
import csv
import argparse
from pathlib import Path

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

try:
    from playwright.async_api import async_playwright
except ImportError:
    print("âŒ æœªå®‰è£… playwright")
    print("è¯·è¿è¡Œ: pip install playwright && playwright install chromium")
    sys.exit(1)


# ==================== é…ç½® ====================

COOKIE_FILE = Path(__file__).parent / "config" / "cookies_xhs.json"


# ==================== Cookie å¤„ç† ====================

def load_cookies_from_file(cookie_file: Path) -> list:
    """ä»æ–‡ä»¶åŠ è½½ Cookies"""
    if cookie_file.exists():
        try:
            with open(cookie_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return []


def save_cookies_to_file(cookies: list, cookie_file: Path):
    """ä¿å­˜ Cookies åˆ°æ–‡ä»¶"""
    cookie_file.parent.mkdir(parents=True, exist_ok=True)
    with open(cookie_file, 'w', encoding='utf-8') as f:
        json.dump(cookies, f, ensure_ascii=False, indent=2)


def parse_cookies_txt(cookie_file: Path) -> list:
    """ä» cookies.txt è§£æ Cookie"""
    cookies = []
    if cookie_file.exists():
        try:
            with open(cookie_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # æŸ¥æ‰¾ [xiaohongshu] éƒ¨åˆ†
                start = content.find('[xiaohongshu]')
                if start >= 0:
                    end = content.find('\n[', start + 1)
                    if end == -1:
                        end = len(content)
                    xhs_section = content[start:end]

                    for line in xhs_section.split('\n'):
                        line = line.strip()
                        if '=' in line and not line.startswith('#') and not line.startswith('['):
                            key, value = line.split('=', 1)
                            cookies.append({
                                'name': key.strip(),
                                'value': value.strip(),
                                'domain': '.xiaohongshu.com',
                                'path': '/'
                            })
        except:
            pass
    return cookies


# ==================== åˆ†äº«é“¾æ¥è·å– ====================

async def get_share_link(browser, note_id: str, cookies: list = None) -> dict:
    """
    è·å–å°çº¢ä¹¦åˆ†äº«é“¾æ¥

    Args:
        browser: Playwright æµè§ˆå™¨å®ä¾‹
        note_id: ç¬”è®°ID
        cookies: Cookie åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        {'success': bool, 'share_url': str, 'error': str}
    """
    result = {'success': False, 'share_url': '', 'error': ''}

    url = f"https://www.xiaohongshu.com/explore/{note_id}"

    try:
        page = await browser.new_page()

        # è®¾ç½® Cookies
        if cookies:
            await page.context.add_cookies(cookies)

        # å¯¼èˆªåˆ°é¡µé¢
        response = await page.goto(url, wait_until='networkidle', timeout=30000)

        if response.status != 200:
            result['error'] = f"é¡µé¢è®¿é—®å¤±è´¥: {response.status}"
            await page.close()
            return result

        # ç­‰å¾…é¡µé¢åŠ è½½
        await asyncio.sleep(2)

        # å°è¯•å¤šç§æ–¹å¼è·å–åˆ†äº«é“¾æ¥

        # æ–¹æ³•1: ä»é¡µé¢ HTML ä¸­æŸ¥æ‰¾
        html = await page.content()

        share_patterns = [
            r'"shareUrl":"([^"]+)"',
            r'"share_url":"([^"]+)"',
            r'"shortUrl":"([^"]+)"',
            r'"short_url":"([^"]+)"',
            r'xhslink\.com/([a-zA-Z0-9]+)',
        ]

        for pattern in share_patterns:
            matches = re.findall(pattern, html)
            for match in matches:
                share_candidate = match.replace(r'\/', '/')
                if 'xhslink.com' in share_candidate:
                    result['success'] = True
                    result['share_url'] = share_candidate
                    await page.close()
                    return result

        # æ–¹æ³•2: å°è¯•ç‚¹å‡»åˆ†äº«æŒ‰é’®ï¼ˆå¦‚æœå·²ç™»å½•ï¼‰
        try:
            # æŸ¥æ‰¾åˆ†äº«æŒ‰é’®
            share_selectors = [
                'button:has-text("åˆ†äº«")',
                '[class*="share"]',
                '[data-testid*="share"]',
                'span:has-text("åˆ†äº«")',
            ]

            for selector in share_selectors:
                share_btn = page.locator(selector).first
                if await share_btn.count() > 0:
                    # ç‚¹å‡»åˆ†äº«æŒ‰é’®
                    await share_btn.click(timeout=5000)
                    await asyncio.sleep(1)

                    # æŸ¥æ‰¾å¤åˆ¶é“¾æ¥æŒ‰é’®
                    copy_selectors = [
                        'button:has-text("å¤åˆ¶é“¾æ¥")',
                        'span:has-text("å¤åˆ¶é“¾æ¥")',
                        '[class*="copy"]',
                    ]

                    for copy_selector in copy_selectors:
                        copy_btn = page.locator(copy_selector).first
                        if await copy_btn.count() > 0:
                            # è·å–åˆ†äº«é“¾æ¥æ–‡æœ¬
                            share_text = await copy_btn.get_attribute('data-clipboard-text') or ''
                            if not share_text:
                                # å°è¯•ä»é¡µé¢ä¸­æŸ¥æ‰¾
                                share_text = await page.evaluate("""
                                    () => {
                                        // æŸ¥æ‰¾åŒ…å« xhslink çš„æ–‡æœ¬
                                        const walker = document.createTreeWalker(
                                            document.body,
                                            NodeFilter.SHOW_TEXT,
                                            null,
                                            false
                                        );
                                        let node;
                                        while (node = walker.nextNode()) {
                                            if (node.nodeValue && node.nodeValue.includes('xhslink.com')) {
                                                return node.nodeValue.trim();
                                            }
                                        }
                                        return '';
                                    }
                                """)

                            if share_text and 'xhslink.com' in share_text:
                                result['success'] = True
                                result['share_url'] = share_text
                                await page.close()
                                return result

                    break
        except Exception as e:
            pass  # åˆ†äº«æŒ‰é’®ç‚¹å‡»å¤±è´¥ï¼Œç»§ç»­å…¶ä»–æ–¹æ³•

        # æ–¹æ³•3: å°è¯•é€šè¿‡ API è·å–ï¼ˆéœ€è¦ç™»å½•ï¼‰
        try:
            share_url = await page.evaluate("""
                async () => {
                    try {
                        // å°è¯•è°ƒç”¨åˆ†äº« API
                        const response = await fetch('https://edith.xiaohongshu.com/api/sns/web/v1/note/share/short_url?note_id=' + window.location.pathname.split('/').pop(), {
                            method: 'GET',
                            credentials: 'include',
                            headers: {
                                'Accept': 'application/json'
                            }
                        });
                        const data = await response.json();
                        if (data.data && (data.data.short_url || data.data.share_url)) {
                            return data.data.short_url || data.data.share_url;
                        }
                    } catch (e) {
                        console.error(e);
                    }
                    return '';
                }
            """)

            if share_url and 'xhslink.com' in share_url:
                result['success'] = True
                result['share_url'] = share_url
                await page.close()
                return result
        except:
            pass

        # å¦‚æœéƒ½å¤±è´¥äº†
        result['error'] = "æ— æ³•è·å–åˆ†äº«é“¾æ¥ï¼ˆå¯èƒ½éœ€è¦ç™»å½•æˆ–ç¬”è®°ä¸å­˜åœ¨ï¼‰"

        await page.close()

    except Exception as e:
        result['error'] = str(e)

    return result


async def process_url(url: str) -> dict:
    """å¤„ç†å•ä¸ªé“¾æ¥"""
    result = {
        'original_url': url,
        'note_id': '',
        'share_url': '',
        'success': False,
        'error': ''
    }

    # æå–ç¬”è®°ID
    patterns = [
        r'/explore/([a-f0-9]{24})',
        r'/discovery/item/([a-f0-9]{24})',
        r'([a-f0-9]{24})',
    ]

    note_id = ''
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            note_id = match.group(1)
            break

    if not note_id:
        result['error'] = "æ— æ³•æå–ç¬”è®°ID"
        return result

    result['note_id'] = note_id

    # åŠ è½½ Cookies
    cookies = load_cookies_from_file(COOKIE_FILE)
    if not cookies:
        # å°è¯•ä» cookies.txt è§£æ
        cookies = parse_cookies_txt(Path(__file__).parent / "config" / "cookies.txt")

    print(f"\nå¤„ç†: {url[:60]}...")
    print(f"ç¬”è®°ID: {note_id}")
    print("-" * 60)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)

        share_result = await get_share_link(browser, note_id, cookies)

        await browser.close()

        result.update(share_result)

    if result['success']:
        print(f"âœ… åˆ†äº«é“¾æ¥: {result['share_url']}")
    else:
        print(f"âŒ {result['error']}")
        if cookies:
            print(f"ğŸ’¡ æç¤º: Cookie å¯èƒ½å·²è¿‡æœŸï¼Œè¯·å°è¯•åˆ é™¤ {COOKIE_FILE.name} é‡æ–°ç™»å½•")

    return result


async def process_csv(csv_path: str, output_path: str = None):
    """æ‰¹é‡å¤„ç† CSV æ–‡ä»¶"""
    csv_path = Path(csv_path)
    if not csv_path.exists():
        print(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return

    if output_path is None:
        output_path = csv_path.parent / f"{csv_path.stem}_share_links.csv"

    # è¯»å– CSV
    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames or []

        link_col = None
        for col in ['é“¾æ¥', 'url', 'link', 'video_url', 'note_url']:
            if col in fieldnames:
                link_col = col
                break

        if not link_col:
            print(f"âŒ æœªæ‰¾åˆ°é“¾æ¥åˆ—")
            return

        rows = []
        for row in reader:
            url = row.get(link_col, '').strip()
            if url:
                rows.append({
                    'url': url,
                    'title': row.get('æ ‡é¢˜', '') or row.get('title', ''),
                    'row_data': row
                })

    print(f"\næ‰¾åˆ° {len(rows)} ä¸ªé“¾æ¥")
    print("=" * 60)

    # åŠ è½½ Cookies
    cookies = load_cookies_from_file(COOKIE_FILE)
    if not cookies:
        cookies = parse_cookies_txt(Path(__file__).parent / "config" / "cookies.txt")

    results = []
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)

        for i, row_info in enumerate(rows, 1):
            print(f"\n[{i}/{len(rows)}]", end='')
            result = await process_url(row_info['url'])
            result['title'] = row_info['title']
            result['original_row'] = row_info['row_data']
            results.append(result)

            # é¿å…è¯·æ±‚è¿‡å¿«
            if i < len(rows):
                await asyncio.sleep(1)

        await browser.close()

    # ä¿å­˜ç»“æœ
    print(f"\n\n{'=' * 60}")
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("=" * 60)

    success = sum(1 for r in results if r['success'])
    failed = len(results) - success
    print(f"æ€»è®¡: {len(results)} | æˆåŠŸ: {success} | å¤±è´¥: {failed}")

    with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
        original_fields = list(results[0].get('original_row', {}).keys())
        writer = csv.DictWriter(f, fieldnames=original_fields + ['ç¬”è®°ID', 'åˆ†äº«é“¾æ¥', 'çŠ¶æ€'])
        writer.writeheader()

        for r in results:
            row_data = r.get('original_row', {})
            row_data.update({
                'ç¬”è®°ID': r['note_id'],
                'åˆ†äº«é“¾æ¥': r['share_url'],
                'çŠ¶æ€': 'æˆåŠŸ' if r['success'] else 'å¤±è´¥'
            })
            writer.writerow(row_data)

    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")


# ==================== ç™»å½•åŠŸèƒ½ ====================

async def login_and_save_cookies():
    """ä½¿ç”¨æµè§ˆå™¨ç™»å½•å¹¶ä¿å­˜ Cookies"""
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        print("\nğŸ“± æ‰“å¼€å°çº¢ä¹¦ç™»å½•é¡µé¢...")
        print("è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•æ“ä½œ")
        print("ç™»å½•æˆåŠŸåï¼ŒæŒ‰ Ctrl+C ä¿å­˜ Cookie å¹¶é€€å‡º\n")

        await page.goto("https://www.xiaohongshu.com")

        try:
            # ç­‰å¾…ç”¨æˆ·ç™»å½•
            while True:
                await asyncio.sleep(1)
                # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ï¼ˆå¯ä»¥é€šè¿‡æ£€æŸ¥ç‰¹å®šå…ƒç´ æˆ– URL å˜åŒ–ï¼‰
        except KeyboardInterrupt:
            print("\n\nğŸ’¾ æ­£åœ¨ä¿å­˜ Cookies...")

            cookies = await page.context.cookies()
            save_cookies_to_file(cookies, COOKIE_FILE)

            print(f"âœ… Cookies å·²ä¿å­˜åˆ°: {COOKIE_FILE}")
            print("ğŸ“ åç»­å¯ä»¥é‡ç”¨è¿™äº› Cookies è¿›è¡Œæ“ä½œ")

        await browser.close()


# ==================== ä¸»ç¨‹åº ====================

async def main():
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦åˆ†äº«é“¾æ¥ç”Ÿæˆå·¥å…·ï¼ˆæµè§ˆå™¨ç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. å¤„ç†å•ä¸ªé“¾æ¥:
   python xhs_share_link_browser.py --url "https://www.xiaohongshu.com/explore/69983ebb00000000150304d8"

2. æ‰¹é‡å¤„ç† CSV:
   python xhs_share_link_browser.py --csv notes.csv

3. ç™»å½•å¹¶ä¿å­˜ Cookie:
   python xhs_share_link_browser.py --login

æ³¨æ„äº‹é¡¹:
- é¦–æ¬¡ä½¿ç”¨éœ€è¦æ‰§è¡Œ --login ç™»å½•å¹¶ä¿å­˜ Cookie
- Cookie ä¿å­˜åœ¨ config/cookies_xhs.json
- Cookie æœ‰æ•ˆæœŸé€šå¸¸ä¸ºå‡ å¤©ï¼Œè¿‡æœŸåéœ€è¦é‡æ–°ç™»å½•
        """
    )

    parser.add_argument('--url', help='å•ä¸ªå°çº¢ä¹¦é“¾æ¥')
    parser.add_argument('--csv', help='CSV æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', help='JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--login', action='store_true', help='ç™»å½•å¹¶ä¿å­˜ Cookie')

    args = parser.parse_args()

    if args.login:
        await login_and_save_cookies()
        return

    if not any([args.url, args.csv, args.json]):
        parser.print_help()
        return

    print("=" * 60)
    print("å°çº¢ä¹¦åˆ†äº«é“¾æ¥ç”Ÿæˆå·¥å…·ï¼ˆæµè§ˆå™¨ç‰ˆï¼‰")
    print("=" * 60)

    if args.url:
        await process_url(args.url)

    elif args.csv:
        await process_csv(args.csv, args.output)

    elif args.json:
        print("âš ï¸  JSON å¤„ç†åŠŸèƒ½æš‚æœªå®ç°")
        print("è¯·ä½¿ç”¨ CSV æ ¼å¼")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ å·²å–æ¶ˆ")
