# ğŸ¬ Colab å¿«é€Ÿä½¿ç”¨ - å¤åˆ¶åˆ° Colab å•å…ƒæ ¼è¿è¡Œ

# ============= å®‰è£…ä¾èµ– =============
!pip install -q openai-whisper yt-dlp

# ============= é…ç½® =============
VIDEO_URL = "https://www.bilibili.com/video/BVxxxxx"  # ğŸ‘ˆ æ”¹æˆä½ çš„é“¾æ¥
MODEL = "small"  # tiny/base/small/medium/large

# ============= ä¸‹è½½éŸ³é¢‘ + Whisper è½¬å½• =============
import yt_dlp, whisper, torch, re
from pathlib import Path

# ä¸‹è½½éŸ³é¢‘
print("â¬‡ï¸ ä¸‹è½½éŸ³é¢‘...")
ydl_opts = {'format': 'bestaudio/best', 'outtmpl': 'audio.%(ext)s', 'quiet': True}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(VIDEO_URL, download=True)
    title = info.get('title', 'video')

audio_file = list(Path('.').glob('audio.*'))[0]
print(f"âœ… éŸ³é¢‘: {audio_file}")

# Whisper è½¬å½•
print(f"ğŸ™ï¸ Whisper è½¬å½• ({MODEL})...")
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model(MODEL, device=device)
result = model.transcribe(str(audio_file), language='zh')

# ä¿å­˜ SRT
safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:50]
srt_file = f"{safe_title}.srt"
with open(srt_file, 'w', encoding='utf-8') as f:
    for i, seg in enumerate(result['segments'], 1):
        h1, m1, s1 = int(seg['start']//3600), int((seg['start']%3600)//60), int(seg['start']%60)
        h2, m2, s2 = int(seg['end']//3600), int((seg['end']%3600)//60), int(seg['end']%60)
        ms1, ms2 = int((seg['start']%1)*1000), int((seg['end']%1)*1000)
        f.write(f"{i}\n{h1:02d}:{m1:02d}:{s1:02d},{ms1:03d} --> {h2:02d}:{m2:02d}:{s2:02d},{ms2:03d}\n{seg['text'].strip()}\n\n")

print(f"âœ… å®Œæˆ: {srt_file}")

# ============= ä¸‹è½½åˆ°æœ¬åœ° =============
from google.colab import files
files.download(srt_file)
