#!/usr/bin/env python3
"""
Bç«™ç”¨æˆ·è§†é¢‘è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹

ä¸€é”®å®Œæˆï¼š
1. æŠ“å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨
2. æ‰¹é‡æå–å­—å¹•
3. ç”ŸæˆAIæ‘˜è¦æŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
    # åŸºæœ¬ç”¨æ³• - è·å–æœ€æ–°10ä¸ªè§†é¢‘å¹¶å®Œæˆå…¨éƒ¨æµç¨‹
    python auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 10

    # æŒ‡å®š Gemini æ¨¡å‹å’Œå¹¶å‘æ•°
    python auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 20 --model flash -j 5

    # ä»å·²æœ‰CSVå¼€å§‹ï¼Œè·³è¿‡è§†é¢‘æŠ“å–
    python auto_bili_workflow.py --csv "MediaCrawler/bilibili_videos_output/ç”¨æˆ·å.csv" --count 20

    # ä»…æŠ“å–è§†é¢‘å’Œæå–å­—å¹•ï¼Œä¸ç”ŸæˆAIæ‘˜è¦
    python auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 30 --no-summary
"""

import argparse
import asyncio
import sys
import re
import subprocess
from pathlib import Path
from datetime import datetime

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


# ==================== è·¯å¾„é…ç½® ====================

SCRIPT_DIR = Path(__file__).parent
MEDIA_CRAWLER_DIR = SCRIPT_DIR / "MediaCrawler"
SUBTITLE_FETCH_SCRIPT = SCRIPT_DIR / "utils" / "batch_subtitle_fetch.py"
SUMMARY_SCRIPT = SCRIPT_DIR / "analysis" / "gemini_subtitle_summary.py"

# è¾“å‡ºè·¯å¾„
MEDIA_CRAWLER_OUTPUT = MEDIA_CRAWLER_DIR / "bilibili_videos_output"
SUBTITLE_OUTPUT = SCRIPT_DIR / "output" / "subtitles"


# ==================== æ­¥éª¤1: æŠ“å–è§†é¢‘åˆ—è¡¨ ====================

def fetch_video_list(url: str, count: int = None) -> tuple:
    """
    æ­¥éª¤1: æŠ“å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨

    Returns:
        (success: bool, user_name: str, csv_path: Path)
    """
    print("\n" + "=" * 70)
    print("ğŸ“‹ æ­¥éª¤ 1/3: æŠ“å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨")
    print("=" * 70)

    # æå–UID
    uid = extract_uid_from_url(url)
    if not uid:
        print(f"âŒ æ— æ³•ä»URLæå–UID: {url}")
        return False, None, None

    print(f"ğŸ” ç”¨æˆ·UID: {uid}")

    # è°ƒç”¨ MediaCrawler çš„ fetch è„šæœ¬
    # ç”±äºè¯¥è„šæœ¬ä½¿ç”¨äº¤äº’å¼è¾“å…¥ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªä¸´æ—¶è„šæœ¬æˆ–ä½¿ç”¨ stdin

    fetch_script = MEDIA_CRAWLER_DIR / "fetch_bilibili_videos.py"

    if not fetch_script.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {fetch_script}")
        return False, None, None

    print(f"ğŸ“¡ æ­£åœ¨æŠ“å–è§†é¢‘åˆ—è¡¨...")

    # ä½¿ç”¨ stdin ä¼ é€’ URL
    try:
        result = subprocess.run(
            [sys.executable, str(fetch_script)],
            input=f"{url}\n",
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
        )

        # è¾“å‡ºç»“æœ
        if result.stdout:
            # åªæ‰“å°å…³é”®ä¿¡æ¯
            for line in result.stdout.split('\n'):
                if any(keyword in line for keyword in ['âœ…', 'âŒ', 'âš ï¸', 'ç”¨æˆ·å', 'CSV', 'æ–°å¢è§†é¢‘']):
                    print(line)

        if result.returncode != 0 and result.stderr:
            print(f"âš ï¸ æŠ“å–è¿‡ç¨‹æœ‰è­¦å‘Š: {result.stderr[:200]}")

    except subprocess.TimeoutExpired:
        print("âš ï¸ è§†é¢‘æŠ“å–è¶…æ—¶")
        return False, None, None
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        return False, None, None

    # æŸ¥æ‰¾ç”Ÿæˆçš„CSVæ–‡ä»¶
    csv_files = list(MEDIA_CRAWLER_OUTPUT.glob("*.csv"))
    if csv_files:
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
        latest_csv = max(csv_files, key=lambda p: p.stat().st_mtime)
        user_name = latest_csv.stem
        print(f"\nğŸ“ æ‰¾åˆ°CSV: {latest_csv}")
        print(f"ğŸ‘¤ ç”¨æˆ·å: {user_name}")
        return True, user_name, latest_csv
    else:
        print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„CSVæ–‡ä»¶")
        return False, None, None


# ==================== æ­¥éª¤2: æ‰¹é‡æå–å­—å¹• ====================

async def fetch_subtitles(csv_path: Path, count: int = None) -> bool:
    """
    æ­¥éª¤2: æ‰¹é‡æå–å­—å¹• (è°ƒç”¨ utils/batch_subtitle_fetch.py)
    """
    print("\n" + "=" * 70)
    print("ğŸ“ æ­¥éª¤ 2/3: æ‰¹é‡æå–å­—å¹•")
    print("=" * 70)

    if not csv_path or not csv_path.exists():
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return False

    if not SUBTITLE_FETCH_SCRIPT.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {SUBTITLE_FETCH_SCRIPT}")
        return False

    print(f"ğŸ“„ CSVæ–‡ä»¶: {csv_path}")
    if count:
        print(f"ğŸ”¢ é™åˆ¶æ•°é‡: {count}")

    # åŠ¨æ€å¯¼å…¥å¹¶è¿è¡Œ
    try:
        # æ·»åŠ  utils ç›®å½•åˆ°è·¯å¾„
        sys.path.insert(0, str(SUBTITLE_FETCH_SCRIPT.parent))

        # å¯¼å…¥æ¨¡å—
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "batch_subtitle_fetch",
            SUBTITLE_FETCH_SCRIPT
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # è°ƒç”¨ä¸»å‡½æ•°
        await module.process_batch(str(csv_path), limit=count)

        print("\nâœ… å­—å¹•æå–å®Œæˆ!")
        return True

    except Exception as e:
        print(f"âŒ å­—å¹•æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ==================== æ­¥éª¤3: ç”ŸæˆAIæ‘˜è¦ ====================

def generate_summary(user_name: str, model: str = 'flash-lite', jobs: int = 3) -> bool:
    """
    æ­¥éª¤3: ç”ŸæˆAIæ‘˜è¦æŠ¥å‘Š (è°ƒç”¨ analysis/gemini_subtitle_summary.py)
    """
    print("\n" + "=" * 70)
    print("ğŸ¤– æ­¥éª¤ 3/3: ç”ŸæˆAIæ‘˜è¦æŠ¥å‘Š")
    print("=" * 70)

    subtitle_dir = SUBTITLE_OUTPUT / user_name

    if not subtitle_dir.exists():
        print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {subtitle_dir}")
        return False

    # æ£€æŸ¥SRTæ–‡ä»¶
    srt_files = list(subtitle_dir.glob("*.srt"))
    if not srt_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°SRTæ–‡ä»¶: {subtitle_dir}")
        return False

    print(f"ğŸ“ å­—å¹•ç›®å½•: {subtitle_dir}")
    print(f"ğŸ“„ SRTæ–‡ä»¶æ•°: {len(srt_files)}")
    print(f"ğŸ¤– æ¨¡å‹: {model}")
    print(f"âš¡ å¹¶å‘æ•°: {jobs}")

    if not SUMMARY_SCRIPT.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {SUMMARY_SCRIPT}")
        return False

    # è°ƒç”¨æ‘˜è¦è„šæœ¬
    try:
        # å¯¼å…¥æ¨¡å—
        sys.path.insert(0, str(SUMMARY_SCRIPT.parent))
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "gemini_subtitle_summary",
            SUMMARY_SCRIPT
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # è°ƒç”¨å¤„ç†å‡½æ•°
        module.process_subtitles(str(subtitle_dir), model=model, max_workers=jobs)

        print("\nâœ… AIæ‘˜è¦ç”Ÿæˆå®Œæˆ!")
        return True

    except Exception as e:
        print(f"âŒ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ==================== å·¥å…·å‡½æ•° ====================

def extract_uid_from_url(url: str) -> str:
    """ä»Bç«™ç”¨æˆ·é“¾æ¥ä¸­æå–UID"""
    try:
        if '?' in url:
            url = url.split('?')[0]
        if 'space.bilibili.com/' in url:
            uid = url.split('space.bilibili.com/')[-1].strip('/')
            return uid
    except Exception:
        pass
    return None


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="Bç«™ç”¨æˆ·è§†é¢‘è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³• - è·å–æœ€æ–°10ä¸ªè§†é¢‘
  python auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 10

  # æŒ‡å®š Gemini æ¨¡å‹å’Œå¹¶å‘æ•°
  python auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 20 --model flash -j 5

  # ä»å·²æœ‰CSVå¼€å§‹ï¼Œè·³è¿‡è§†é¢‘æŠ“å–
  python auto_bili_workflow.py --csv "MediaCrawler/bilibili_videos_output/ç”¨æˆ·å.csv" --count 20

  # ä»…æŠ“å–è§†é¢‘å’Œæå–å­—å¹•ï¼Œä¸ç”ŸæˆAIæ‘˜è¦
  python auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 30 --no-summary

  # ä»…ç”ŸæˆAIæ‘˜è¦ï¼ˆå·²æœ‰å­—å¹•ï¼‰
  python auto_bili_workflow.py --user "èµ›é›·è¯é‡‘" --summary-only
        """
    )

    parser.add_argument("--url", "-u", help="Bç«™ç”¨æˆ·ä¸»é¡µé“¾æ¥")
    parser.add_argument("--csv", "-c", help="ç›´æ¥ä½¿ç”¨å·²æœ‰çš„CSVæ–‡ä»¶ï¼ˆè·³è¿‡æ­¥éª¤1ï¼‰")
    parser.add_argument("--user", help="æŒ‡å®šç”¨æˆ·åï¼ˆç”¨äºæ­¥éª¤2å’Œ3ï¼‰")
    parser.add_argument("--count", "-n", type=int, default=None,
                        help="å¤„ç†çš„è§†é¢‘æ•°é‡ï¼ˆé»˜è®¤ï¼šå…¨éƒ¨ï¼‰")
    parser.add_argument("--model", "-m", choices=['flash', 'flash-lite', 'pro'],
                        default='flash-lite', help="Geminiæ¨¡å‹ï¼ˆé»˜è®¤: flash-liteï¼‰")
    parser.add_argument("--jobs", "-j", type=int, default=3,
                        help="å¹¶å‘å¤„ç†æ•°ï¼ˆé»˜è®¤: 3ï¼‰")
    parser.add_argument("--no-summary", action="store_true",
                        help="è·³è¿‡AIæ‘˜è¦ç”Ÿæˆæ­¥éª¤")
    parser.add_argument("--summary-only", action="store_true",
                        help="ä»…ç”ŸæˆAIæ‘˜è¦ï¼ˆè·³è¿‡æ­¥éª¤1å’Œ2ï¼‰")

    args = parser.parse_args()

    # éªŒè¯å‚æ•°
    if not args.summary_only and not args.csv and not args.url:
        print("âŒ é”™è¯¯: å¿…é¡»æä¾› --url, --csv æˆ–ä½¿ç”¨ --summary-only")
        parser.print_help()
        return 1

    print("\n" + "=" * 70)
    print("ğŸš€ Bç«™ç”¨æˆ·è§†é¢‘è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹")
    print("=" * 70)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åˆå§‹åŒ–å˜é‡
    user_name = args.user
    csv_path = None

    # ==================== æ­¥éª¤1: æŠ“å–è§†é¢‘ ====================
    if not args.summary_only and not args.csv:
        success, name, path = fetch_video_list(args.url, args.count)
        if not success and not path:
            print("\nâŒ è§†é¢‘æŠ“å–å¤±è´¥ï¼Œå·¥ä½œæµç¨‹ç»ˆæ­¢")
            return 1

        if not user_name:
            user_name = name
        csv_path = path

    # ==================== ä½¿ç”¨å·²æœ‰CSV ====================
    elif args.csv:
        csv_path = Path(args.csv)
        if not csv_path.exists():
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            return 1
        if not user_name:
            user_name = csv_path.stem
        print(f"\nğŸ“ ä½¿ç”¨æŒ‡å®šCSV: {csv_path}")
        print(f"ğŸ‘¤ ç”¨æˆ·å: {user_name}")

    # ==================== æ­¥éª¤2: æå–å­—å¹• ====================
    if not args.summary_only:
        if csv_path:
            # æ­¥éª¤2æ˜¯å¼‚æ­¥çš„
            success = asyncio.run(fetch_subtitles(csv_path, args.count))
            if not success:
                print("\nâš ï¸ å­—å¹•æå–å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•ç”Ÿæˆæ‘˜è¦...")
        else:
            print("\nâš ï¸ æ²¡æœ‰CSVæ–‡ä»¶ï¼Œè·³è¿‡å­—å¹•æå–")

    # ==================== æ­¥éª¤3: ç”ŸæˆAIæ‘˜è¦ ====================
    if not args.no_summary or args.summary_only:
        if user_name:
            success = generate_summary(user_name, args.model, args.jobs)

            if success:
                print("\n" + "=" * 70)
                print("ğŸ‰ å·¥ä½œæµç¨‹å®Œæˆ!")
                print("=" * 70)
                print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
                if csv_path:
                    print(f"  - CSV: {csv_path}")
                print(f"  - å­—å¹•: {SUBTITLE_OUTPUT / user_name}")
                print(f"  - AIæ‘˜è¦: {SUBTITLE_OUTPUT / f'{user_name}_AIæ€»ç»“.md'}")
            else:
                print("\nâš ï¸ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥")
                return 1
        else:
            print("\nâŒ æ— æ³•ç¡®å®šç”¨æˆ·åï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦")
            return 1
    else:
        print("\n" + "=" * 70)
        print("âœ… å·¥ä½œæµç¨‹å®Œæˆ (è·³è¿‡AIæ‘˜è¦)")
        print("=" * 70)

    print(f"\nâ° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
