#!/usr/bin/env python3
"""
Bç«™ç”¨æˆ·è§†é¢‘è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹

ä¸€é”®å®Œæˆï¼š
1. æŠ“å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨
2. æ‰¹é‡æå–å­—å¹•
3. ç”ŸæˆAIæ‘˜è¦æŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
    # åŸºæœ¬ç”¨æ³• - è·å–æœ€æ–°10ä¸ªè§†é¢‘å¹¶å®Œæˆå…¨éƒ¨æµç¨‹
    python utils/auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 10

    # å¢é‡æ¨¡å¼ - è·³è¿‡å·²å¤„ç†çš„è§†é¢‘
    python utils/auto_bili_workflow.py --user "ç”¨æˆ·å" --incremental

    # æŒ‡å®š Gemini æ¨¡å‹å’Œå¹¶å‘æ•°
    python utils/auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 20 --model flash -j 5

    # ä»å·²æœ‰CSVå¼€å§‹ï¼Œè·³è¿‡è§†é¢‘æŠ“å–
    python utils/auto_bili_workflow.py --csv "MediaCrawler/bilibili_videos_output/ç”¨æˆ·å.csv" --count 20

    # ä»…æŠ“å–è§†é¢‘å’Œæå–å­—å¹•ï¼Œä¸ç”ŸæˆAIæ‘˜è¦
    python utils/auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 30 --no-summary

    # ä»…ç”ŸæˆAIæ‘˜è¦ï¼ˆå·²æœ‰å­—å¹•ï¼‰
    python utils/auto_bili_workflow.py --user "ç”¨æˆ·å" --summary-only
"""

import argparse
import asyncio
import sys
import re
import subprocess
from pathlib import Path
from datetime import datetime

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


# ==================== è·¯å¾„é…ç½® ====================
# è„šæœ¬ç°åœ¨åœ¨ utils/ ç›®å½•ä¸‹ï¼Œéœ€è¦å›åˆ°çˆ¶ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
SCRIPT_DIR = Path(__file__).parent.parent  # é¡¹ç›®æ ¹ç›®å½•
MEDIA_CRAWLER_DIR = SCRIPT_DIR / "MediaCrawler"
SUBTITLE_FETCH_SCRIPT = SCRIPT_DIR / "utils" / "batch_subtitle_fetch.py"
SUMMARY_SCRIPT = SCRIPT_DIR / "analysis" / "gemini_subtitle_summary.py"

# è¾“å‡ºè·¯å¾„ - ç»Ÿä¸€ä¿å­˜åˆ° MediaCrawler ç›®å½•
MEDIA_CRAWLER_OUTPUT = MEDIA_CRAWLER_DIR / "bilibili_videos_output"
SUBTITLE_OUTPUT = MEDIA_CRAWLER_DIR / "bilibili_subtitles"


# ==================== æ­¥éª¤1: æŠ“å–è§†é¢‘åˆ—è¡¨ ====================

def fetch_video_list(url: str, count: int = None) -> tuple:
    """
    æ­¥éª¤1: æŠ“å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨ï¼ˆç›´æ¥è°ƒç”¨æ¨¡å—ï¼Œé¿å…subprocessï¼‰

    Returns:
        (success: bool, user_name: str, csv_path: Path)
    """
    print("\n" + "=" * 70)
    print("ğŸ“‹ æ­¥éª¤ 1/3: æŠ“å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨")
    print("=" * 70)

    # æå–UID
    uid = extract_uid_from_url(url)
    if not uid:
        print(f"âŒ æ— æ³•ä»URLæå–UID: {url}")
        return False, None, None

    print(f"ğŸ” ç”¨æˆ·UID: {uid}")

    fetch_script = MEDIA_CRAWLER_DIR / "fetch_bilibili_videos.py"

    if not fetch_script.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {fetch_script}")
        return False, None, None

    print(f"ğŸ“¡ æ­£åœ¨æŠ“å–è§†é¢‘åˆ—è¡¨...")

    # ç›´æ¥å¯¼å…¥æ¨¡å—å¹¶è°ƒç”¨å‡½æ•°ï¼ˆé¿å…subprocessçš„å¼€é”€ï¼‰
    try:
        import importlib.util

        # åŠ è½½æ¨¡å—
        spec = importlib.util.spec_from_file_location(
            "fetch_bilibili_videos",
            fetch_script
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # è°ƒç”¨åº•å±‚å‡½æ•°ï¼Œç»•è¿‡äº¤äº’å¼è¾“å…¥
        print("  â†’ è·å–ç”¨æˆ·ä¿¡æ¯...")
        user_info = module.get_user_info(uid)
        if not user_info:
            print("âŒ æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯")
            return False, None, None

        user_name = user_info.get('name', f'ç”¨æˆ·{uid}')

        print(f"  â†’ è·å–è§†é¢‘åˆ—è¡¨...")
        videos = module.get_user_videos(uid)
        if not videos:
            print("âŒ æœªè·å–åˆ°è§†é¢‘")
            return False, None, None

        # é™åˆ¶æ•°é‡
        if count and count < len(videos):
            videos = videos[:count]
            print(f"  â†’ é™åˆ¶å¤„ç†æ•°é‡: {count}")

        # å¤„ç†è§†é¢‘æ•°æ®
        print(f"  â†’ å¤„ç† {len(videos)} ä¸ªè§†é¢‘...")
        processed_videos, author_name = module.process_video_data(videos)

        # ä¼˜å…ˆä½¿ç”¨UPä¸»å
        if author_name:
            user_name = author_name

        # æ¸…ç†ç”¨æˆ·å
        import re
        user_name = re.sub(r'[\/\\:*?"<>|]', '_', user_name)

        # è¯»å–å†å²è®°å½•
        historical_links = module.load_historical_links(user_name)

        # è¿‡æ»¤æ–°è§†é¢‘
        new_videos = module.filter_new_videos(processed_videos, historical_links)

        # ä¿å­˜ç»“æœ
        csv_out = module.save_results(new_videos, user_name, url)

        print(f"âœ… æŠ“å–å®Œæˆï¼")
        print(f"   ç”¨æˆ·: {user_name}")
        print(f"   æ–°è§†é¢‘: {len(new_videos)} ä¸ª")

        if csv_out:
            return True, user_name, Path(csv_out)
        else:
            # æ²¡æœ‰æ–°è§†é¢‘ï¼Œä½†è¿”å›ç°æœ‰CSVè·¯å¾„
            existing_csv = MEDIA_CRAWLER_OUTPUT / f"{user_name}.csv"
            if existing_csv.exists():
                return True, user_name, existing_csv
            return False, None, None

    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None


# ==================== æ­¥éª¤2: æ‰¹é‡æå–å­—å¹• ====================

async def fetch_subtitles(csv_path: Path, count: int = None) -> bool:
    """
    æ­¥éª¤2: æ‰¹é‡æå–å­—å¹• (è°ƒç”¨ utils/batch_subtitle_fetch.py)
    """
    print("\n" + "=" * 70)
    print("ğŸ“ æ­¥éª¤ 2/3: æ‰¹é‡æå–å­—å¹•")
    print("=" * 70)

    if not csv_path or not csv_path.exists():
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return False

    if not SUBTITLE_FETCH_SCRIPT.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {SUBTITLE_FETCH_SCRIPT}")
        return False

    print(f"ğŸ“„ CSVæ–‡ä»¶: {csv_path}")
    if count:
        print(f"ğŸ”¢ é™åˆ¶æ•°é‡: {count}")

    # åŠ¨æ€å¯¼å…¥å¹¶è¿è¡Œ
    try:
        # æ·»åŠ  utils ç›®å½•åˆ°è·¯å¾„
        sys.path.insert(0, str(SUBTITLE_FETCH_SCRIPT.parent))

        # å¯¼å…¥æ¨¡å—
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "batch_subtitle_fetch",
            SUBTITLE_FETCH_SCRIPT
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # è°ƒç”¨ä¸»å‡½æ•°
        await module.process_batch(str(csv_path), limit=count)

        print("\nâœ… å­—å¹•æå–å®Œæˆ!")
        return True

    except Exception as e:
        print(f"âŒ å­—å¹•æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ==================== æ­¥éª¤3: ç”ŸæˆAIæ‘˜è¦ ====================

def generate_summary(user_name: str, model: str = 'flash-lite', jobs: int = 3, incremental: bool = False, append: bool = False) -> bool:
    """
    æ­¥éª¤3: ç”ŸæˆAIæ‘˜è¦æŠ¥å‘Š (è°ƒç”¨ analysis/gemini_subtitle_summary.py)
    """
    print("\n" + "=" * 70)
    print("ğŸ¤– æ­¥éª¤ 3/3: ç”ŸæˆAIæ‘˜è¦æŠ¥å‘Š")
    print("=" * 70)

    subtitle_dir = SUBTITLE_OUTPUT / user_name

    if not subtitle_dir.exists():
        print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {subtitle_dir}")
        return False

    # æ£€æŸ¥SRTæ–‡ä»¶
    srt_files = list(subtitle_dir.glob("*.srt"))
    if not srt_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°SRTæ–‡ä»¶: {subtitle_dir}")
        return False

    print(f"ğŸ“ å­—å¹•ç›®å½•: {subtitle_dir}")
    print(f"ğŸ“„ SRTæ–‡ä»¶æ•°: {len(srt_files)}")
    print(f"ğŸ¤– æ¨¡å‹: {model}")
    print(f"âš¡ å¹¶å‘æ•°: {jobs}")
    if incremental:
        print(f"ğŸ”„ å¢é‡æ¨¡å¼: è·³è¿‡å·²å¤„ç†è§†é¢‘")

    if not SUMMARY_SCRIPT.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {SUMMARY_SCRIPT}")
        return False

    # è°ƒç”¨æ‘˜è¦è„šæœ¬
    try:
        # å¯¼å…¥æ¨¡å—
        sys.path.insert(0, str(SUMMARY_SCRIPT.parent))
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "gemini_subtitle_summary",
            SUMMARY_SCRIPT
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # è°ƒç”¨å¤„ç†å‡½æ•°
        module.process_subtitles(str(subtitle_dir), model=model, max_workers=jobs,
                                 incremental=incremental, append=append)

        print("\nâœ… AIæ‘˜è¦ç”Ÿæˆå®Œæˆ!")
        return True

    except Exception as e:
        print(f"âŒ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ==================== å·¥å…·å‡½æ•° ====================

def extract_uid_from_url(url: str) -> str:
    """ä»Bç«™ç”¨æˆ·é“¾æ¥ä¸­æå–UID"""
    try:
        if '?' in url:
            url = url.split('?')[0]
        if 'space.bilibili.com/' in url:
            uid = url.split('space.bilibili.com/')[-1].strip('/')
            return uid
    except Exception:
        pass
    return None


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="Bç«™ç”¨æˆ·è§†é¢‘è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³• - è·å–æœ€æ–°10ä¸ªè§†é¢‘
  python utils/auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 10

  # å¢é‡æ¨¡å¼ - è·³è¿‡å·²å¤„ç†çš„è§†é¢‘
  python utils/auto_bili_workflow.py --user "ç”¨æˆ·å" --incremental

  # æŒ‡å®š Gemini æ¨¡å‹å’Œå¹¶å‘æ•°
  python utils/auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 20 --model flash -j 5

  # ä»å·²æœ‰CSVå¼€å§‹ï¼Œè·³è¿‡è§†é¢‘æŠ“å–
  python utils/auto_bili_workflow.py --csv "MediaCrawler/bilibili_videos_output/ç”¨æˆ·å.csv" --count 20

  # ä»…æŠ“å–è§†é¢‘å’Œæå–å­—å¹•ï¼Œä¸ç”ŸæˆAIæ‘˜è¦
  python utils/auto_bili_workflow.py --url "https://space.bilibili.com/3546607314274766" --count 30 --no-summary

  # ä»…ç”ŸæˆAIæ‘˜è¦ï¼ˆå·²æœ‰å­—å¹•ï¼‰
  python utils/auto_bili_workflow.py --user "ç”¨æˆ·å" --summary-only

  # è¿½åŠ æ¨¡å¼ - å°†æ–°ç»“æœè¿½åŠ åˆ°ç°æœ‰æ‘˜è¦
  python utils/auto_bili_workflow.py --user "ç”¨æˆ·å" --append --incremental
        """
    )

    parser.add_argument("--url", "-u", help="Bç«™ç”¨æˆ·ä¸»é¡µé“¾æ¥")
    parser.add_argument("--csv", "-c", help="ç›´æ¥ä½¿ç”¨å·²æœ‰çš„CSVæ–‡ä»¶ï¼ˆè·³è¿‡æ­¥éª¤1ï¼‰")
    parser.add_argument("--user", help="æŒ‡å®šç”¨æˆ·åï¼ˆç”¨äºæ­¥éª¤2å’Œ3ï¼‰")
    parser.add_argument("--count", "-n", type=int, default=None,
                        help="å¤„ç†çš„è§†é¢‘æ•°é‡ï¼ˆé»˜è®¤ï¼šå…¨éƒ¨ï¼‰")
    parser.add_argument("--model", "-m", choices=['flash', 'flash-lite', 'pro'],
                        default='flash-lite', help="Geminiæ¨¡å‹ï¼ˆé»˜è®¤: flash-liteï¼‰")
    parser.add_argument("--jobs", "-j", type=int, default=3,
                        help="å¹¶å‘å¤„ç†æ•°ï¼ˆé»˜è®¤: 3ï¼‰")
    parser.add_argument("--no-summary", action="store_true",
                        help="è·³è¿‡AIæ‘˜è¦ç”Ÿæˆæ­¥éª¤")
    parser.add_argument("--summary-only", action="store_true",
                        help="ä»…ç”ŸæˆAIæ‘˜è¦ï¼ˆè·³è¿‡æ­¥éª¤1å’Œ2ï¼‰")
    parser.add_argument("--incremental", "-i", action="store_true",
                        help="å¢é‡æ¨¡å¼ï¼šè·³è¿‡å·²å¤„ç†çš„è§†é¢‘")
    parser.add_argument("--append", "-a", action="store_true",
                        help="è¿½åŠ æ¨¡å¼ï¼šå°†æ–°ç»“æœè¿½åŠ åˆ°ç°æœ‰æ‘˜è¦æ–‡ä»¶")

    args = parser.parse_args()

    # éªŒè¯å‚æ•°
    if not args.summary_only and not args.csv and not args.url:
        print("âŒ é”™è¯¯: å¿…é¡»æä¾› --url, --csv æˆ–ä½¿ç”¨ --summary-only")
        parser.print_help()
        return 1

    print("\n" + "=" * 70)
    print("ğŸš€ Bç«™ç”¨æˆ·è§†é¢‘è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹")
    print("=" * 70)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åˆå§‹åŒ–å˜é‡
    user_name = args.user
    csv_path = None

    # ==================== æ­¥éª¤1: æŠ“å–è§†é¢‘ ====================
    if not args.summary_only and not args.csv:
        success, name, path = fetch_video_list(args.url, args.count)
        if not success and not path:
            print("\nâŒ è§†é¢‘æŠ“å–å¤±è´¥ï¼Œå·¥ä½œæµç¨‹ç»ˆæ­¢")
            return 1

        if not user_name:
            user_name = name
        csv_path = path

    # ==================== ä½¿ç”¨å·²æœ‰CSV ====================
    elif args.csv:
        csv_path = Path(args.csv)
        if not csv_path.exists():
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            return 1
        if not user_name:
            user_name = csv_path.stem
        print(f"\nğŸ“ ä½¿ç”¨æŒ‡å®šCSV: {csv_path}")
        print(f"ğŸ‘¤ ç”¨æˆ·å: {user_name}")

    # ==================== æ­¥éª¤2: æå–å­—å¹• ====================
    if not args.summary_only:
        if csv_path:
            # æ­¥éª¤2æ˜¯å¼‚æ­¥çš„
            success = asyncio.run(fetch_subtitles(csv_path, args.count))
            if not success:
                print("\nâš ï¸ å­—å¹•æå–å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•ç”Ÿæˆæ‘˜è¦...")
        else:
            print("\nâš ï¸ æ²¡æœ‰CSVæ–‡ä»¶ï¼Œè·³è¿‡å­—å¹•æå–")

    # ==================== æ­¥éª¤3: ç”ŸæˆAIæ‘˜è¦ ====================
    if not args.no_summary or args.summary_only:
        if user_name:
            success = generate_summary(user_name, args.model, args.jobs,
                                       incremental=args.incremental, append=args.append)

            if success:
                print("\n" + "=" * 70)
                print("ğŸ‰ å·¥ä½œæµç¨‹å®Œæˆ!")
                print("=" * 70)
                print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
                if csv_path:
                    print(f"  - CSV: {csv_path}")
                print(f"  - å­—å¹•: {SUBTITLE_OUTPUT / user_name}")
                print(f"  - AIæ‘˜è¦: {SUBTITLE_OUTPUT / f'{user_name}_AIæ€»ç»“.md'}")
            else:
                print("\nâš ï¸ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥")
                return 1
        else:
            print("\nâŒ æ— æ³•ç¡®å®šç”¨æˆ·åï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦")
            return 1
    else:
        print("\n" + "=" * 70)
        print("âœ… å·¥ä½œæµç¨‹å®Œæˆ (è·³è¿‡AIæ‘˜è¦)")
        print("=" * 70)

    print(f"\nâ° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
