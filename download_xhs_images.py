#!/usr/bin/env python3
"""
å°çº¢ä¹¦å›¾ç‰‡ä¸‹è½½å™¨ - åªä¸‹è½½ç¬”è®°çš„å®é™…å†…å®¹å›¾ç‰‡
éœ€è¦æä¾›å®Œæ•´çš„å°çº¢ä¹¦é“¾æ¥ï¼ˆå¸¦xsec_tokenï¼‰
ç”¨æ³•: python download_xhs_images.py "å°çº¢ä¹¦å®Œæ•´é“¾æ¥"
"""

import os
import sys
import re
import json
import time
import requests
from pathlib import Path
from urllib.parse import urlparse, parse_qs

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def extract_xhs_images(url):
    """ä»å°çº¢ä¹¦é“¾æ¥æå–ç¬”è®°çš„å®é™…å›¾ç‰‡URL"""

    # é‡è¦çš„ï¼šå¿…é¡»ä½¿ç”¨å®Œæ•´çš„ URLï¼ˆåŒ…å« xsec_tokenï¼‰
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'same-origin',
    }

    print(f"ğŸ“¡ è¯·æ±‚é¡µé¢...")
    print(f"   URL: {url[:80]}...")

    response = requests.get(url, headers=headers, timeout=30, allow_redirects=True)

    print(f"   çŠ¶æ€ç : {response.status_code}")
    print(f"   æœ€ç»ˆURL: {response.url[:80]}...")

    if response.status_code != 200:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
        return None, []

    # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°404
    if '/404?' in response.url or 'ä½ è®¿é—®çš„é¡µé¢ä¸è§äº†' in response.text:
        print(f"âŒ é¡µé¢æ— æ³•è®¿é—®ï¼ˆåçˆ¬è™«ä¿æŠ¤ï¼‰")
        print(f"   åŸå› ï¼š")
        print(f"   1. é“¾æ¥ç¼ºå°‘ xsec_token å‚æ•°")
        print(f"   2. é“¾æ¥å·²è¿‡æœŸæˆ–å¤±æ•ˆ")
        print(f"   3. éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹")
        return None, []

    html = response.text
    print(f"âœ… é¡µé¢è·å–æˆåŠŸ (é•¿åº¦: {len(html)})")

    # æå–æ ‡é¢˜
    title = "å°çº¢ä¹¦å›¾ç‰‡"
    title_match = re.search(r'<title[^>]*>(.+?)</title>', html)
    if title_match:
        title = title_match.group(1).replace(' - å°çº¢ä¹¦', '').strip()
    print(f"ğŸ“ æ ‡é¢˜: {title[:50]}...")

    print(f"\nğŸ” æ­£åœ¨æå–ç¬”è®°å›¾ç‰‡...")

    # æŸ¥æ‰¾ __INITIAL_STATE__ JSON æ•°æ®
    start_idx = html.find('window.__INITIAL_STATE__=')
    if start_idx == -1:
        print(f"âŒ æœªæ‰¾åˆ° __INITIAL_STATE__")
        return title, []

    start_idx += len('window.__INITIAL_STATE__=')
    end_idx = html.find('</script>', start_idx)
    json_str = html[start_idx:end_idx]

    # å°è¯•è§£æ JSON
    data = None
    try:
        data = json.loads(json_str)
        print(f"âœ… JSONè§£ææˆåŠŸ")
    except json.JSONDecodeError as e:
        print(f"âš ï¸  JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™æœç´¢...")

    image_urls = []

    # æ–¹æ³•1: ä»è§£æå¥½çš„ JSON ä¸­æå–
    if data:
        try:
            # è·¯å¾„: note.noteDetail.imageList
            note = data.get('note', {})
            note_detail = note.get('noteDetail', {})
            image_list = note_detail.get('imageList', [])

            if image_list:
                print(f"âœ… ä» note.noteDetail.imageList æ‰¾åˆ° {len(image_list)} å¼ å›¾ç‰‡")
                for img_obj in image_list:
                    if isinstance(img_obj, dict):
                        # å°è¯•å¤šä¸ªå­—æ®µ
                        url = (img_obj.get('urlDefault') or
                               img_obj.get('url_default') or
                               img_obj.get('url') or
                               img_obj.get('infoList', [{}])[0].get('url') if isinstance(img_obj.get('infoList'), list) else None)
                        if url:
                            image_urls.append(url)
        except Exception as e:
            print(f"âš ï¸  æ–¹æ³•1å¤±è´¥: {e}")

    # æ–¹æ³•2: ç›´æ¥åœ¨ JSON å­—ç¬¦ä¸²ä¸­æœç´¢ imageList
    if not image_urls:
        print(f"ğŸ” å°è¯•ç›´æ¥æœç´¢ imageList...")

        # æ‰¾åˆ° imageList: [...] éƒ¨åˆ† - ä½¿ç”¨è®¡æ•°å™¨åŒ¹é…å®Œæ•´çš„æ•°ç»„
        start = json_str.find('"imageList"')
        if start >= 0:
            # æ‰¾åˆ° [
            bracket_start = json_str.find('[', start)
            if bracket_start >= 0:
                # æ‰‹åŠ¨åŒ¹é…å¯¹åº”çš„ ]
                depth = 0
                i = bracket_start
                while i < len(json_str):
                    if json_str[i] == '[':
                        depth += 1
                    elif json_str[i] == ']':
                        depth -= 1
                        if depth == 0:
                            bracket_end = i
                            break
                    i += 1

                list_content = json_str[bracket_start+1:bracket_end]
                print(f"âœ… æ‰¾åˆ° imageListï¼Œå†…å®¹é•¿åº¦: {len(list_content)}")

                # åªæå– urlDefaultï¼ˆé»˜è®¤/åŸå›¾ï¼‰ï¼Œè·³è¿‡ urlPre å’Œ infoList
                # æ¯ä¸ª image å¯¹è±¡åªå–ä¸€ä¸ª urlDefault
                url_pattern = r'"urlDefault":"([^"]+)"'
                for match in re.finditer(url_pattern, list_content):
                    url = match.group(1)
                    if url:
                        image_urls.append(url)

                if image_urls:
                    print(f"âœ… æå–åˆ° {len(image_urls)} å¼ å›¾ç‰‡")

    # æ–¹æ³•3: ä»æ•´ä¸ª HTML ä¸­æœç´¢ sns-webpic å›¾ç‰‡URLï¼ˆå¤‡ç”¨ï¼‰
    if not image_urls:
        print(f"ğŸ” å°è¯•ä»HTMLç›´æ¥æå–...")
        # æŸ¥æ‰¾æ‰€æœ‰ sns-webpic é“¾æ¥
        all_urls = re.findall(r'(https://sns-webpic[^\"\s\'<>]+)', html)
        # å»é‡
        unique_urls = list(set(all_urls))
        if unique_urls:
            print(f"âœ… æ‰¾åˆ° {len(unique_urls)} ä¸ª sns-webpic URL")
            image_urls = unique_urls[:10]  # é™åˆ¶æ•°é‡

    # å»é‡å¹¶æ¸…ç†
    seen = set()
    unique_urls = []
    for url in image_urls:
        # æ¸…ç† URL
        url = url.split('?')[0]
        # è§£ç  Unicode è½¬ä¹‰ (å¦‚ \u002F -> /)
        try:
            url = url.encode('utf-8').decode('unicode_escape')
        except:
            pass
        # å†æ¬¡æ¸…ç†å¯èƒ½å¼•å…¥çš„é—®é¢˜
        url = url.replace(r'\/', '/')
        # ç¡®ä¿ https åè®®
        if url.startswith('http://'):
            url = 'https://' + url[7:]
        elif not url.startswith('https://'):
            continue
        if url not in seen and 'xhscdn' in url:
            seen.add(url)
            unique_urls.append(url)

    # æ˜¾ç¤ºæ‰¾åˆ°çš„URLç”¨äºè°ƒè¯•
    print(f"ğŸ“‹ å›¾ç‰‡URLåˆ—è¡¨:")
    for i, u in enumerate(unique_urls, 1):
        print(f"   {i}. {u[:80]}...")

    return title, unique_urls


def download_images(url, output_dir="xhs_images"):
    """ä¸‹è½½æ‰€æœ‰å›¾ç‰‡åˆ°æŒ‡å®šç›®å½•"""

    result = extract_xhs_images(url)

    if not result:
        print(f"\nâŒ æå–å¤±è´¥")
        return False

    title, image_urls = result

    if not image_urls:
        print(f"\nâŒ æœªæ‰¾åˆ°å›¾ç‰‡")
        return False

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # æ¸…ç†æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å¤¹å
    safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:50]

    print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½ {len(image_urls)} å¼ å›¾ç‰‡...")
    print(f"{'='*60}")

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
    }

    success_count = 0
    failed_count = 0

    for i, img_url in enumerate(image_urls, 1):
        try:
            print(f"[{i}/{len(image_urls)}] ", end='', flush=True)

            img_response = requests.get(img_url, headers=headers, timeout=30)

            if img_response.status_code == 200:
                # ç¡®å®šæ–‡ä»¶æ‰©å±•å
                content_type = img_response.headers.get('Content-Type', '')
                if 'png' in content_type or img_url.endswith('.png'):
                    ext = '.png'
                elif 'webp' in content_type or img_url.endswith('.webp'):
                    ext = '.webp'
                else:
                    ext = '.jpg'

                filename = f"{safe_title}_{i:02d}{ext}"
                filepath = output_path / filename

                with open(filepath, 'wb') as f:
                    f.write(img_response.content)

                size = len(img_response.content) / 1024
                print(f"âœ… {size:.1f}KB")
                success_count += 1
            else:
                print(f"âŒ HTTP {img_response.status_code}")
                failed_count += 1

        except Exception as e:
            print(f"âŒ {str(e)[:30]}")
            failed_count += 1

        time.sleep(0.3)

    print(f"{'='*60}")
    print(f"\nğŸ‰ ä¸‹è½½å®Œæˆ!")
    print(f"   æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count}")
    print(f"   ä¿å­˜ä½ç½®: {output_path.absolute()}")

    return success_count > 0


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python download_xhs_images.py \"å°çº¢ä¹¦å®Œæ•´é“¾æ¥\"")
        print("\næ³¨æ„ï¼šå¿…é¡»ä½¿ç”¨å®Œæ•´çš„é“¾æ¥ï¼ˆåŒ…å« xsec_token å‚æ•°ï¼‰")
        print("ä»å°çº¢ä¹¦åˆ†äº«æˆ–å¤åˆ¶é“¾æ¥è·å–å®Œæ•´URL")
        sys.exit(1)

    url = sys.argv[1]
    download_images(url)
