#!/usr/bin/env python3
"""
æµ‹è¯•å°çº¢ä¹¦å•ç¬”è®°å›¾æ–‡æå–åŠŸèƒ½

ç›´æ¥æµ‹è¯•ç¬”è®°é“¾æ¥çš„å›¾ç‰‡æå–
"""

import os
import sys
import re
import json
import requests
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def extract_xhs_images_from_note(note_url: str) -> dict:
    """
    ä»å°çº¢ä¹¦ç¬”è®°é“¾æ¥æå–å›¾ç‰‡å’Œæ–‡å­—

    Returns:
        {
            'title': 'æ ‡é¢˜',
            'text': 'æ–‡å­—å†…å®¹',
            'images': [
                {'index': 1, 'url': 'å›¾ç‰‡URL', 'size': 'æ–‡ä»¶å¤§å°'},
                ...
            ],
            'note_id': 'ç¬”è®°ID'
        }
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    }

    print(f"ğŸ“¡ è¯·æ±‚ç¬”è®°é¡µé¢...")
    print(f"   URL: {note_url[:80]}...")

    try:
        response = requests.get(note_url, headers=headers, timeout=30, allow_redirects=True)
        print(f"   çŠ¶æ€ç : {response.status_code}")

        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return None

        html = response.text
        print(f"âœ… é¡µé¢è·å–æˆåŠŸ (é•¿åº¦: {len(html)})")

    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

    # æå–ç¬”è®°ID
    note_id = ""
    note_id_match = re.search(r'/explore/([a-f0-9]+)', note_url)
    if note_id_match:
        note_id = note_id_match.group(1)
    print(f"ğŸ†” ç¬”è®°ID: {note_id}")

    # æå–æ ‡é¢˜
    title = "å°çº¢ä¹¦ç¬”è®°"
    title_match = re.search(r'<title[^>]*>(.+?)</title>', html)
    if title_match:
        title = title_match.group(1).replace(' - å°çº¢ä¹¦', '').strip()
    print(f"ğŸ“ æ ‡é¢˜: {title}")

    # æå–æ–‡å­—å†…å®¹
    text_content = ""

    # æ–¹æ³•1: ä» desc å­—æ®µæå–
    desc_patterns = [
        r'"desc":"([^"]+)"',
        r'"desc":\s*"([^"]+)"',
    ]

    for pattern in desc_patterns:
        desc_match = re.search(pattern, html)
        if desc_match:
            try:
                text_content = desc_match.group(1).encode('utf-8').decode('unicode_escape')
                break
            except:
                text_content = desc_match.group(1)

    print(f"ğŸ“„ æ–‡å­—å†…å®¹: {text_content[:100] if text_content else '(æ— )'}...")

    # æå–å›¾ç‰‡
    print(f"\nğŸ” æ­£åœ¨æå–å›¾ç‰‡...")

    image_list = []

    # æ–¹æ³•1: ä» __INITIAL_STATE__ æå–
    start_idx = html.find('window.__INITIAL_STATE__=')
    if start_idx >= 0:
        start_idx += len('window.__INITIAL_STATE__=')
        end_idx = html.find('</script>', start_idx)
        json_str = html[start_idx:end_idx]

        # å°è¯•è§£æ
        try:
            # æ¸…ç† JSON
            json_str_clean = json_str.replace('\n', '\\n').replace('\r', '\\r')
            data = json.loads(json_str_clean)

            # æå–å›¾ç‰‡
            try:
                note = data.get('note', {})
                note_detail = note.get('noteDetail', {})
                images = note_detail.get('imageList', [])

                if images:
                    print(f"âœ… ä» imageList æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")
                    for i, img in enumerate(images):
                        url = (img.get('urlDefault') or
                               img.get('url_default') or
                               img.get('url') or
                               img.get('infoList', [{}])[0].get('url')
                               if isinstance(img.get('infoList'), list) else None)
                        if url:
                            image_list.append({'index': i+1, 'url': url})
            except Exception as e:
                print(f"âš ï¸  ä» imageList æå–å¤±è´¥: {e}")

        except json.JSONDecodeError:
            print(f"âš ï¸  JSON è§£æå¤±è´¥")

    # æ–¹æ³•2: ç›´æ¥æœç´¢å›¾ç‰‡ URL
    if not image_list:
        print(f"ğŸ” å°è¯•ç›´æ¥æœç´¢å›¾ç‰‡ URL...")
        # å°çº¢ä¹¦å›¾ç‰‡ URL æ ¼å¼
        patterns = [
            r'"urlDefault":"(https://[^"]+xhscdn[^"]*)"',
            r'"url":"(https://sns-webpic[^"]+)"',
            r'(https://sns-webpic[^"\s\'<>]+)',
        ]

        for pattern in patterns:
            urls = re.findall(pattern, html)
            if urls:
                print(f"âœ… æ‰¾åˆ° {len(urls)} ä¸ªå›¾ç‰‡ URL")
                for i, url in enumerate(urls[:10]):  # æœ€å¤š10å¼ 
                    # æ¸…ç† URL
                    url = url.split('?')[0]
                    try:
                        url = url.encode('utf-8').decode('unicode_escape')
                    except:
                        pass
                    url = url.replace(r'\/', '/')
                    if url.startswith('http://'):
                        url = 'https://' + url[7:]

                    if 'xhscdn' in url or 'sns-webpic' in url:
                        image_list.append({'index': len(image_list)+1, 'url': url})
                break

    # è·å–å›¾ç‰‡å¤§å°
    print(f"\nğŸ“Š è·å–å›¾ç‰‡ä¿¡æ¯...")
    for img in image_list:
        try:
            img_response = requests.head(img['url'], headers=headers, timeout=10)
            if img_response.status_code == 200:
                size = int(img_response.headers.get('Content-Length', 0))
                size_kb = size / 1024
                img['size'] = f"{size_kb:.1f}KB"
            else:
                img['size'] = "Unknown"
        except:
            img['size'] = "Unknown"

    return {
        'note_id': note_id,
        'title': title,
        'text': text_content,
        'images': image_list
    }


def format_result(result: dict) -> str:
    """æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœ"""
    if not result:
        return "âŒ æå–å¤±è´¥"

    lines = []
    lines.append("=" * 100)
    lines.append("ğŸ“‹ å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æå–ç»“æœ".center(100))
    lines.append("=" * 100)
    lines.append("")

    # ç¬”è®°ID
    lines.append(f"ğŸ†” ç¬”è®°ID: {result['note_id']}")
    lines.append("")

    # æ ‡é¢˜
    lines.append(f"ğŸ“ æ ‡é¢˜:")
    lines.append(f"   {result['title']}")
    lines.append("")

    # æ–‡å­—å†…å®¹
    lines.append(f"ğŸ“„ æ–‡å­—å†…å®¹:")
    if result['text']:
        lines.append(f"   {result['text']}")
    else:
        lines.append(f"   (æ— æ–‡å­—å†…å®¹)")
    lines.append("")

    # å›¾ç‰‡åˆ—è¡¨
    lines.append(f"ğŸ–¼ï¸  å›¾ç‰‡åˆ—è¡¨ ({len(result['images'])} å¼ ):")
    lines.append("")

    if result['images']:
        lines.append("â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”")
        lines.append("â”‚ #  â”‚ å›¾ç‰‡URL                                                                 â”‚ å¤§å°   â”‚")
        lines.append("â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

        for img in result['images']:
            url = img['url'][:76] + '...' if len(img['url']) > 76 else img['url']
            size = img.get('size', 'Unknown')
            lines.append(f"â”‚ {img['index']:2} â”‚ {url:<76} â”‚ {size:>6} â”‚")

        lines.append("â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    else:
        lines.append("   (æœªæ‰¾åˆ°å›¾ç‰‡)")

    lines.append("")
    lines.append("=" * 100)

    return "\n".join(lines)


def download_images(result: dict, output_dir: str = "output/test_xhs_images") -> list:
    """ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    downloaded = []

    print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½å›¾ç‰‡...")

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
    }

    for img in result['images']:
        url = img['url']
        index = img['index']
        print(f"   [{index}/{len(result['images'])}] ", end='', flush=True)

        try:
            response = requests.get(url, headers=headers, timeout=30)

            if response.status_code == 200:
                # ç¡®å®šæ‰©å±•å
                content_type = response.headers.get('Content-Type', '')
                if 'png' in content_type or '.png' in url:
                    ext = '.png'
                elif 'webp' in content_type or '.webp' in url:
                    ext = '.webp'
                else:
                    ext = '.jpg'

                # å®‰å…¨æ–‡ä»¶å
                safe_title = re.sub(r'[<>:"/\\|?*]', '_', result['title'])[:30]
                filename = f"{safe_title}_{index:02d}{ext}"
                filepath = output_path / filename

                with open(filepath, 'wb') as f:
                    f.write(response.content)

                size = len(response.content) / 1024
                print(f"âœ… {size:.1f}KB -> {filename}")
                downloaded.append(str(filepath))
            else:
                print(f"âŒ HTTP {response.status_code}")

        except Exception as e:
            print(f"âŒ {str(e)[:30]}")

    return downloaded


def main():
    # æµ‹è¯•ç¬”è®°é“¾æ¥ï¼ˆä½ å¯ä»¥æ›¿æ¢æˆå…¶ä»–é“¾æ¥ï¼‰
    test_url = input("è¯·è¾“å…¥å°çº¢ä¹¦ç¬”è®°é“¾æ¥ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤æµ‹è¯•é“¾æ¥ï¼‰: ").strip()

    if not test_url:
        # é»˜è®¤æµ‹è¯•é“¾æ¥ï¼ˆä½ å¯ä»¥æ›¿æ¢æˆæœ‰æ•ˆçš„ï¼‰
        test_url = "https://www.xiaohongshu.com/explore/65003b71000000001300085c?xsec_source=pc_feed"

    print("\n" + "=" * 100)
    print("ğŸ” å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æå–æµ‹è¯•")
    print("=" * 100)
    print()

    # æå–å›¾ç‰‡
    result = extract_xhs_images_from_note(test_url)

    if result and result['images']:
        # æ˜¾ç¤ºç»“æœ
        print("\n")
        print(format_result(result))

        # è¯¢é—®æ˜¯å¦ä¸‹è½½
        print()
        choice = input("æ˜¯å¦ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼Ÿ(y/n): ").strip().lower()

        if choice == 'y':
            downloaded = download_images(result)
            print(f"\nğŸ’¾ å·²ä¸‹è½½ {len(downloaded)} å¼ å›¾ç‰‡åˆ° output/test_xhs_images/")

        # ä¿å­˜ç»“æœ
        output_dir = Path("output/test_xhs")
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_title = re.sub(r'[<>:"/\\|?*]', '_', result['title'])[:30]
        result_file = output_dir / f"{safe_title}_{timestamp}.txt"

        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(format_result(result))
            f.write(f"\n\n")
            f.write(f"åŸå§‹é“¾æ¥: {test_url}\n")
            f.write(f"æå–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    else:
        print("\nâŒ æœªæ‰¾åˆ°å›¾ç‰‡ï¼Œå¯èƒ½åŸå› :")
        print("   1. é“¾æ¥éœ€è¦ xsec_token å‚æ•°")
        print("   2. ç¬”è®°æ˜¯è§†é¢‘ç±»å‹ï¼ˆä¸æ˜¯å›¾æ–‡ï¼‰")
        print("   3. åçˆ¬è™«ä¿æŠ¤ï¼ˆéœ€è¦ç™»å½•ï¼‰")
        print("\nğŸ’¡ å»ºè®®:")
        print("   - ä»å°çº¢ä¹¦APPåˆ†äº«è·å–å®Œæ•´é“¾æ¥")
        print("   - ç¡®ä¿ç¬”è®°æ˜¯å›¾æ–‡ç±»å‹è€Œéè§†é¢‘")


if __name__ == "__main__":
    main()
