#!/usr/bin/env python3
"""
ä½¿ç”¨ Gemini API è¿›è¡Œå›¾æ–‡å¤šæ¨¡æ€åˆ†æ

åŠŸèƒ½ï¼š
1. æå–å°çº¢ä¹¦å›¾æ–‡ç¬”è®°çš„å›¾ç‰‡å’Œæ–‡å­—
2. ä¸Šä¼ å›¾ç‰‡åˆ° Gemini Files API
3. ä½¿ç”¨ Gemini è¿›è¡Œå›¾æ–‡æ··åˆåˆ†æ

ä½¿ç”¨ç¤ºä¾‹:
    # åˆ†æå•ä¸ªå°çº¢ä¹¦ç¬”è®°
    python multimodal_gemini.py --url "å°çº¢ä¹¦ç¬”è®°é“¾æ¥"

    # æ‰¹é‡åˆ†æï¼ˆä»CSVè¯»å–é“¾æ¥åˆ—è¡¨ï¼‰
    python multimodal_gemini.py --csv notes.csv

    # æŒ‡å®šæ¨¡å¼
    python multimodal_gemini.py --url "..." --mode knowledge

    # ä»æœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¤¹åˆ†æ
    python multimodal_gemini.py --dir "images_folder" --text "ç¬”è®°æè¿°æ–‡å­—"
"""

import os
import sys
import time
import json
import re
import csv
import argparse
import requests
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

try:
    import google.generativeai as genai
    import warnings
    warnings.filterwarnings("ignore", category=FutureWarning)
except ImportError:
    # å°è¯•ä½¿ç”¨æ–°åº“
    try:
        from google import genai
        USE_NEW_API = True
    except ImportError:
        print("âŒ æœªå®‰è£… google-generativeai åº“")
        print("è¯·è¿è¡Œ: pip install google-generativeai")
        sys.exit(1)


# ==================== é…ç½® ====================

GEMINI_MODELS = {
    'flash-lite': 'gemini-2.5-flash-lite',
    'flash': 'gemini-2.5-flash',
    'pro': 'gemini-2.5-pro',
}


# ==================== API é…ç½® ====================

def get_api_key() -> str:
    """
    è·å– Gemini API Key

    ä¼˜å…ˆçº§:
    1. ç¯å¢ƒå˜é‡ GEMINI_API_KEY
    2. config_api.py é…ç½®æ–‡ä»¶
    """
    # 1. å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    api_key = os.environ.get('GEMINI_API_KEY')
    if api_key:
        return api_key

    # 2. å°è¯•ä» config_api.py è·å–
    try:
        sys.path.insert(0, str(Path(__file__).parent.parent))
        from config.config_api import API_CONFIG
        api_key = API_CONFIG.get('gemini', {}).get('api_key')
        if api_key:
            return api_key
    except ImportError:
        pass

    return None


def configure_gemini(api_key: str = None) -> bool:
    """é…ç½® Gemini API"""
    if not api_key:
        api_key = get_api_key()

    if not api_key:
        print("âŒ æœªæ‰¾åˆ° Gemini API Key")
        print("\nè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€é…ç½® API Key:")
        print("1. è®¾ç½®ç¯å¢ƒå˜é‡: export GEMINI_API_KEY='your-key'")
        print("2. åœ¨ config_api.py ä¸­æ·»åŠ :")
        print('   API_CONFIG = {"gemini": {"api_key": "your-key"}}')
        return False

    try:
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        print(f"âŒ Gemini API é…ç½®å¤±è´¥: {e}")
        return False


# ==================== å°çº¢ä¹¦å›¾ç‰‡æå– ====================

def extract_xhs_images(url: str) -> Tuple[str, List[str]]:
    """
    ä»å°çº¢ä¹¦é“¾æ¥æå–ç¬”è®°çš„å›¾ç‰‡URL

    å¤ç”¨ download_xhs_images.py çš„é€»è¾‘

    Returns:
        (æ ‡é¢˜, å›¾ç‰‡URLåˆ—è¡¨)
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    }

    print(f"ğŸ“¡ è¯·æ±‚å°çº¢ä¹¦é¡µé¢...")
    print(f"   URL: {url[:80]}...")

    try:
        response = requests.get(url, headers=headers, timeout=30, allow_redirects=True)
        print(f"   çŠ¶æ€ç : {response.status_code}")

        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return None, []

        if '/404?' in response.url or 'ä½ è®¿é—®çš„é¡µé¢ä¸è§äº†' in response.text:
            print(f"âŒ é¡µé¢æ— æ³•è®¿é—®ï¼ˆåçˆ¬è™«ä¿æŠ¤ï¼‰")
            return None, []

        html = response.text
        print(f"âœ… é¡µé¢è·å–æˆåŠŸ (é•¿åº¦: {len(html)})")

    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None, []

    # æå–æ ‡é¢˜
    title = "å°çº¢ä¹¦ç¬”è®°"
    title_match = re.search(r'<title[^>]*>(.+?)</title>', html)
    if title_match:
        title = title_match.group(1).replace(' - å°çº¢ä¹¦', '').strip()
    print(f"ğŸ“ æ ‡é¢˜: {title[:50]}...")

    # æå–å›¾ç‰‡URL
    print(f"\nğŸ” æ­£åœ¨æå–ç¬”è®°å›¾ç‰‡...")

    start_idx = html.find('window.__INITIAL_STATE__=')
    if start_idx == -1:
        print(f"âŒ æœªæ‰¾åˆ° __INITIAL_STATE__")
        return title, []

    start_idx += len('window.__INITIAL_STATE__=')
    end_idx = html.find('</script>', start_idx)
    json_str = html[start_idx:end_idx]

    data = None
    try:
        data = json.loads(json_str)
        print(f"âœ… JSONè§£ææˆåŠŸ")
    except json.JSONDecodeError:
        print(f"âš ï¸  JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™æœç´¢...")

    image_urls = []

    # æ–¹æ³•1: ä»è§£æå¥½çš„ JSON ä¸­æå–
    if data:
        try:
            note = data.get('note', {})
            note_detail = note.get('noteDetail', {})
            image_list = note_detail.get('imageList', [])

            if image_list:
                print(f"âœ… ä» note.noteDetail.imageList æ‰¾åˆ° {len(image_list)} å¼ å›¾ç‰‡")
                for img_obj in image_list:
                    if isinstance(img_obj, dict):
                        url = (img_obj.get('urlDefault') or
                               img_obj.get('url_default') or
                               img_obj.get('url') or
                               img_obj.get('infoList', [{}])[0].get('url')
                               if isinstance(img_obj.get('infoList'), list) else None)
                        if url:
                            image_urls.append(url)
        except Exception as e:
            print(f"âš ï¸  æ–¹æ³•1å¤±è´¥: {e}")

    # æ–¹æ³•2: ç›´æ¥åœ¨ JSON å­—ç¬¦ä¸²ä¸­æœç´¢
    if not image_urls:
        start = json_str.find('"imageList"')
        if start >= 0:
            bracket_start = json_str.find('[', start)
            if bracket_start >= 0:
                depth = 0
                i = bracket_start
                while i < len(json_str):
                    if json_str[i] == '[':
                        depth += 1
                    elif json_str[i] == ']':
                        depth -= 1
                        if depth == 0:
                            bracket_end = i
                            break
                    i += 1

                list_content = json_str[bracket_start+1:bracket_end]
                url_pattern = r'"urlDefault":"([^"]+)"'
                for match in re.finditer(url_pattern, list_content):
                    url = match.group(1)
                    if url:
                        image_urls.append(url)

    # æ¸…ç†å’Œå»é‡
    seen = set()
    unique_urls = []
    for url in image_urls:
        url = url.split('?')[0]
        try:
            url = url.encode('utf-8').decode('unicode_escape')
        except:
            pass
        url = url.replace(r'\/', '/')
        if url.startswith('http://'):
            url = 'https://' + url[7:]
        elif not url.startswith('https://'):
            continue
        if url not in seen and 'xhscdn' in url:
            seen.add(url)
            unique_urls.append(url)

    print(f"ğŸ“‹ æ‰¾åˆ° {len(unique_urls)} å¼ å›¾ç‰‡")

    return title, unique_urls


def download_images(image_urls: List[str], output_dir: Path) -> List[Path]:
    """
    ä¸‹è½½å›¾ç‰‡åˆ°æŒ‡å®šç›®å½•

    Returns:
        ä¸‹è½½çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
    }

    downloaded_paths = []

    print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½ {len(image_urls)} å¼ å›¾ç‰‡...")
    print(f"{'='*60}")

    for i, img_url in enumerate(image_urls, 1):
        try:
            print(f"[{i}/{len(image_urls)}] ", end='', flush=True)

            img_response = requests.get(img_url, headers=headers, timeout=30)

            if img_response.status_code == 200:
                # ç¡®å®šæ–‡ä»¶æ‰©å±•å
                content_type = img_response.headers.get('Content-Type', '')
                if 'png' in content_type or img_url.endswith('.png'):
                    ext = '.png'
                elif 'webp' in content_type or img_url.endswith('.webp'):
                    ext = '.webp'
                else:
                    ext = '.jpg'

                filename = f"image_{i:02d}{ext}"
                filepath = output_dir / filename

                with open(filepath, 'wb') as f:
                    f.write(img_response.content)

                size = len(img_response.content) / 1024
                print(f"âœ… {size:.1f}KB")
                downloaded_paths.append(filepath)
            else:
                print(f"âŒ HTTP {img_response.status_code}")

        except Exception as e:
            print(f"âŒ {str(e)[:30]}")

        time.sleep(0.3)

    print(f"{'='*60}")
    print(f"\nğŸ‰ ä¸‹è½½å®Œæˆ! æˆåŠŸ: {len(downloaded_paths)}/{len(image_urls)}")

    return downloaded_paths


# ==================== Gemini å›¾æ–‡åˆ†æ ====================

class MultimodalAnalyzer:
    """å›¾æ–‡å¤šæ¨¡æ€åˆ†æå™¨"""

    def __init__(self, model: str = 'flash-lite', api_key: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            model: æ¨¡å‹ç±»å‹ (flash/flash-lite/pro)
            api_key: Gemini API Key
        """
        self.api_key = api_key or get_api_key()
        self.model_name = GEMINI_MODELS.get(model, GEMINI_MODELS['flash'])
        self.model = model

        if not configure_gemini(self.api_key):
            raise ValueError("æ— æ³•é…ç½® Gemini API")

    def upload_images(self, image_paths: List[Path]) -> List:
        """
        æ‰¹é‡ä¸Šä¼ å›¾ç‰‡åˆ° Gemini Files API

        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨

        Returns:
            ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡åˆ—è¡¨
        """
        uploaded_files = []

        print(f"\nğŸ“¤ ä¸Šä¼ å›¾ç‰‡åˆ° Gemini...")
        print(f"{'='*60}")

        for i, img_path in enumerate(image_paths, 1):
            print(f"[{i}/{len(image_paths)}] {img_path.name}... ", end='', flush=True)

            try:
                img_file = genai.upload_file(
                    path=str(img_path),
                    display_name=img_path.name
                )

                # ç­‰å¾…å¤„ç†å®Œæˆ
                while img_file.state.name == "PROCESSING":
                    time.sleep(1)
                    img_file = genai.get_file(img_file.name)

                if img_file.state.name == "ACTIVE":
                    size_mb = img_path.stat().st_size / (1024 * 1024)
                    print(f"âœ… ({size_mb:.2f}MB)")
                    uploaded_files.append(img_file)
                else:
                    print(f"âŒ çŠ¶æ€: {img_file.state.name}")

            except Exception as e:
                print(f"âŒ {e}")

        print(f"{'='*60}")
        print(f"âœ… æˆåŠŸä¸Šä¼  {len(uploaded_files)}/{len(image_paths)} å¼ å›¾ç‰‡\n")

        return uploaded_files

    def analyze_note(self, text: str, image_files: List,
                     mode: str = 'knowledge', custom_prompt: str = None) -> Tuple[str, dict]:
        """
        å›¾æ–‡æ··åˆåˆ†æ

        Args:
            text: ç¬”è®°æ–‡å­—å†…å®¹
            image_files: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶å¯¹è±¡åˆ—è¡¨
            mode: åˆ†ææ¨¡å¼
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯

        Returns:
            (åˆ†æç»“æœ, tokenä¿¡æ¯)
        """
        prompt = self._get_prompt(mode, custom_prompt, text)

        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model_name}")
        print(f"ğŸ“ åˆ†ææ¨¡å¼: {mode}")
        print(f"{'='*60}")

        try:
            model = genai.GenerativeModel(self.model_name)

            # æ„å»ºè¾“å…¥ï¼šå›¾ç‰‡ + æç¤ºè¯
            contents = image_files + [prompt]

            print(f"ğŸ”„ æ­£åœ¨åˆ†æ...")
            start_time = time.time()

            response = model.generate_content(contents)

            elapsed = time.time() - start_time
            print(f"âœ… åˆ†æå®Œæˆ! ({elapsed:.1f}ç§’)\n")

            # æå– token ä½¿ç”¨ä¿¡æ¯
            token_info = {
                'prompt_tokens': 0,
                'candidates_tokens': 0,
                'total_tokens': 0
            }

            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                token_info['prompt_tokens'] = response.usage_metadata.prompt_token_count or 0
                token_info['candidates_tokens'] = response.usage_metadata.candidates_token_count or 0
                token_info['total_tokens'] = response.usage_metadata.total_token_count or 0

            return response.text, token_info

        except Exception as e:
            error_msg = f"âŒ åˆ†æå¤±è´¥: {e}"
            print(error_msg)
            return error_msg, {}

    def _get_prompt(self, mode: str, custom_prompt: str, text: str) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        if custom_prompt:
            return f"{custom_prompt}\n\n## ç¬”è®°æ–‡å­—å†…å®¹:\n{text}"

        knowledge_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°çº¢ä¹¦å›¾æ–‡ç¬”è®°åˆ†æå¸ˆï¼Œæ“…é•¿å°†å›¾æ–‡å†…å®¹è½¬åŒ–ä¸ºç»“æ„åŒ–çš„çŸ¥è¯†åº“ç¬”è®°ã€‚è¯·åˆ†æä»¥ä¸‹å›¾æ–‡ç¬”è®°ï¼Œè¾“å‡ºç”¨äºæ„å»º"ç¬¬äºŒå¤§è„‘"çš„ç¬”è®°ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä¿æŒæ‰€æœ‰æ ‡é¢˜å’Œç¬¦å·ï¼‰ï¼š

## ğŸ“‹ ç¬”è®°åŸºæœ¬ä¿¡æ¯
- **ç¬”è®°ç±»å‹**: [ç©¿æ­åˆ†äº«/ç¾å¦†æ•™ç¨‹/ç¾é£Ÿæ¢åº—/æ—…è¡Œæ”»ç•¥/çŸ¥è¯†ç§‘æ™®/äº§å“æµ‹è¯„/ç”Ÿæ´»è®°å½•/å…¶ä»–]
- **æ ¸å¿ƒä¸»é¢˜**: [ä¸€å¥è¯æ¦‚æ‹¬]
- **å†…å®¹é£æ ¼**: [å¹²è´§æ•™ç¨‹/ç§è‰æ¨è/æ—¥å¸¸ç”Ÿæ´»/è§‚ç‚¹åˆ†äº«]

## ğŸ“– å›¾æ–‡å†…å®¹æ‘˜è¦ï¼ˆ150-250å­—ï¼‰
[ç»“åˆå›¾ç‰‡å’Œæ–‡å­—ï¼Œç”¨ç²¾ç‚¼çš„è¯­è¨€æ¦‚æ‹¬ç¬”è®°æ ¸å¿ƒå†…å®¹]

## ğŸ¯ æ ¸å¿ƒä¿¡æ¯æå–
### ä¸»é¢˜/äº§å“
- **ä¸»è¦å¯¹è±¡**: [ç¬”è®°ä»‹ç»çš„ä¸»è¦äº§å“/åœ°ç‚¹/è¯é¢˜]
- **å…³é”®ç‰¹ç‚¹**: [åˆ—ä¸¾3-5ä¸ªå…³é”®ç‰¹ç‚¹]

### å¹²è´§è¦ç‚¹
[å¦‚æœç¬”è®°æœ‰å®ç”¨ä¿¡æ¯ï¼Œåˆ—å‡ºè¦ç‚¹]
- è¦ç‚¹1: [è¯¦ç»†è¯´æ˜]
- è¦ç‚¹2: [è¯¦ç»†è¯´æ˜]
- è¦ç‚¹3: [è¯¦ç»†è¯´æ˜]

### æ¨èç†ç”±
[ä½œè€…æ¨èçš„æ ¸å¿ƒç†ç”±]
- ç†ç”±1: [...]
- ç†ç”±2: [...]

## ğŸ“¸ å›¾ç‰‡åˆ†æ
[åˆ†æå›¾ç‰‡å†…å®¹]
- **å›¾ç‰‡æ•°é‡**: {len(text) if hasattr(self, '_image_count') else 'è‹¥å¹²'}å¼ 
- **å›¾ç‰‡é£æ ¼**: [å®æ‹å›¾/è¡—æ‹å›¾/æ‘†æ‹å›¾/å¹³é“ºå›¾/ç»†èŠ‚å›¾/å¯¹æ¯”å›¾]
- **è§†è§‰æ•ˆæœ**: [å›¾ç‰‡çš„æ°›å›´æ„Ÿã€è‰²è°ƒã€æ„å›¾ç­‰]
- **å…³é”®ç»†èŠ‚**: [ä»å›¾ç‰‡ä¸­è§‚å¯Ÿåˆ°çš„ç»†èŠ‚]

## ğŸ’¡ äº®ç‚¹ä¸ä»·å€¼
### ç‹¬ç‰¹ä¹‹å¤„
[è¿™ç¯‡ç¬”è®°ä¸ä¼—ä¸åŒçš„åœ°æ–¹]

### å®ç”¨ä»·å€¼
- **å‚è€ƒæ€§**: [é«˜/ä¸­/ä½] - [è¯´æ˜]
- **å¯æ“ä½œæ€§**: [é«˜/ä¸­/ä½] - [è¯´æ˜]

### æƒ…ç»ªä»·å€¼
- **æ°›å›´æ„Ÿ**: [ç»™äººä»€ä¹ˆæ„Ÿè§‰]
- **å…±é¸£ç‚¹**: [å¯èƒ½å¼•èµ·å…±é¸£çš„åœ°æ–¹]

## ğŸ“ ä½œè€…é£æ ¼åˆ†æ
- **è¡¨è¾¾æ–¹å¼**: [ç®€æ´æ˜äº†/è¯¦ç»†å•°å—¦/å¹½é»˜é£è¶£/æ­£å¼ä¸¥è‚ƒ]
- **å†…å®¹å€¾å‘**: [å®ç”¨å¹²è´§/æƒ…æ„Ÿå…±é¸£/å®¡ç¾å±•ç¤º/çŸ¥è¯†åˆ†äº«]
- **å¯ä¿¡åº¦**: [é«˜/ä¸­/ä½] - [ç†ç”±]

## âš ï¸ æ³¨æ„äº‹é¡¹
[éœ€è¦ç•™æ„çš„ç‚¹ï¼Œå¦‚:
- æ˜¯å¦ä¸ºå¹¿å‘Šæ¨å¹¿
- ä¿¡æ¯æ˜¯å¦æœ‰å¤¸å¤§
- æ˜¯å¦æœ‰è¸©é›·é£é™©
- å®é™…å‚è€ƒæ—¶éœ€è¦æ³¨æ„ä»€ä¹ˆ]

## ğŸ”— ç›¸å…³å»¶ä¼¸
[åŸºäºç¬”è®°å†…å®¹ï¼Œæ¨èå€¼å¾—æ·±å…¥äº†è§£çš„ç›¸å…³è¯é¢˜ã€äº§å“æˆ–æ€è€ƒæ–¹å‘]

---

## ç¬”è®°æ–‡å­—å†…å®¹:

{text}

---

è¯·ç¡®ä¿è¾“å‡ºç»“æ„å®Œæ•´ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰å®è´¨å†…å®¹ã€‚å¦‚æœæŸéƒ¨åˆ†ç¡®å®ä¸é€‚ç”¨ï¼Œè¯·æ ‡æ³¨"[ä¸é€‚ç”¨]"å¹¶è¯´æ˜åŸå› ã€‚"""

        summary_prompt = f"""è¯·ç”¨ä¸­æ–‡è¯¦ç»†æ€»ç»“è¿™ä¸ªå›¾æ–‡ç¬”è®°çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. ç¬”è®°çš„ä¸»é¢˜å’Œç±»å‹
2. ä¸»è¦å±•ç¤ºçš„äº§å“/å†…å®¹/åœºæ™¯
3. å…³é”®ä¿¡æ¯å’Œäº®ç‚¹
4. å›¾ç‰‡çš„è§†è§‰æ•ˆæœ
5. ä»»ä½•å€¼å¾—æ³¨æ„çš„ç»†èŠ‚

## ç¬”è®°æ–‡å­—å†…å®¹:
{text}"""

        prompts = {
            'knowledge': knowledge_prompt,
            'summary': summary_prompt,
        }

        return prompts.get(mode, summary_prompt)

    def delete_files(self, files: List):
        """åˆ é™¤å·²ä¸Šä¼ çš„æ–‡ä»¶"""
        for f in files:
            try:
                genai.delete_file(f.name)
            except:
                pass


# ==================== è¾“å‡ºç®¡ç† ====================

def save_result(title: str, text: str, result: str, mode: str, model: str,
                token_info: dict, image_count: int,
                output_dir: str = "multimodal_analysis") -> Path:
    """ä¿å­˜åˆ†æç»“æœ"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # æ¸…ç†æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å
    safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:50]
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    result_file = output_path / f"{safe_title}_{timestamp}.md"

    with open(result_file, 'w', encoding='utf-8') as f:
        f.write(f"# {title} - å›¾æ–‡åˆ†æ\n\n")
        f.write(f"## ğŸ“Œ å…ƒä¿¡æ¯\n\n")
        f.write(f"| é¡¹ç›® | å†…å®¹ |\n")
        f.write(f"|------|------|\n")
        f.write(f"| **ç¬”è®°æ ‡é¢˜** | {title} |\n")
        f.write(f"| **åˆ†ææ—¶é—´** | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |\n")
        f.write(f"| **ä½¿ç”¨æ¨¡å‹** | {model} |\n")
        f.write(f"| **åˆ†ææ¨¡å¼** | {mode} |\n")
        f.write(f"| **å›¾ç‰‡æ•°é‡** | {image_count} |\n")

        if token_info and token_info.get('total_tokens', 0) > 0:
            f.write(f"| **Token ä½¿ç”¨** | è¾“å…¥: {token_info.get('prompt_tokens', 0):,} | è¾“å‡º: {token_info.get('candidates_tokens', 0):,} | **æ€»è®¡: {token_info.get('total_tokens', 0):,}** |\n")

        f.write(f"\n---\n\n")
        f.write(f"## ğŸ“„ åŸå§‹æ–‡å­—å†…å®¹\n\n")
        f.write(f"{text}\n\n")
        f.write(f"---\n\n")
        f.write(f"## ğŸ¤– AI åˆ†æç»“æœ\n\n")
        f.write(result)

    return result_file


# ==================== ä¸»å¤„ç†æµç¨‹ ====================

def process_xhs_note(url: str, analyzer: MultimodalAnalyzer,
                     mode: str = 'knowledge', output_dir: str = "multimodal_analysis",
                     keep_images: bool = False) -> bool:
    """
    å¤„ç†å•ä¸ªå°çº¢ä¹¦ç¬”è®°

    Args:
        url: å°çº¢ä¹¦ç¬”è®°é“¾æ¥
        analyzer: MultimodalAnalyzer å®ä¾‹
        mode: åˆ†ææ¨¡å¼
        output_dir: è¾“å‡ºç›®å½•
        keep_images: æ˜¯å¦ä¿ç•™ä¸‹è½½çš„å›¾ç‰‡

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    # æå–å›¾ç‰‡URL
    title, image_urls = extract_xhs_images(url)

    if not image_urls:
        print(f"âŒ æœªæ‰¾åˆ°å›¾ç‰‡")
        return False

    # ä¸‹è½½å›¾ç‰‡
    temp_dir = Path(output_dir) / "_temp_images"
    downloaded_paths = download_images(image_urls, temp_dir)

    if not downloaded_paths:
        print(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥")
        return False

    # ä¸Šä¼ å›¾ç‰‡åˆ° Gemini
    try:
        uploaded_files = analyzer.upload_images(downloaded_paths)

        if not uploaded_files:
            print(f"âŒ å›¾ç‰‡ä¸Šä¼ å¤±è´¥")
            return False

        # æ„å»ºæ–‡å­—å†…å®¹ï¼ˆå¦‚æœæœ‰æ ‡é¢˜ï¼Œå¯ä»¥ä½œä¸ºæ–‡å­—çš„ä¸€éƒ¨åˆ†ï¼‰
        text_content = f"ç¬”è®°æ ‡é¢˜: {title}\n\n"

        # åˆ†æå›¾æ–‡
        result, token_info = analyzer.analyze_note(
            text=text_content,
            image_files=uploaded_files,
            mode=mode
        )

        # åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
        analyzer.delete_files(uploaded_files)

        # ä¿å­˜ç»“æœ
        if result and not result.startswith("âŒ"):
            result_file = save_result(
                title=title,
                text=text_content,
                result=result,
                mode=mode,
                model=analyzer.model_name,
                token_info=token_info,
                image_count=len(uploaded_files),
                output_dir=output_dir
            )
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file.name}")

            # æ‰“å° token ä¿¡æ¯
            if token_info and token_info.get('total_tokens', 0) > 0:
                print(f"ğŸ“Š Token ä½¿ç”¨: è¾“å…¥ {token_info.get('prompt_tokens', 0):,} | è¾“å‡º {token_info.get('candidates_tokens', 0):,} | æ€»è®¡ {token_info.get('total_tokens', 0):,}")

            return True
        else:
            print(f"âŒ åˆ†æå¤±è´¥")
            return False

    finally:
        # æ¸…ç†ä¸´æ—¶å›¾ç‰‡
        if not keep_images and temp_dir.exists():
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)


def process_local_images(image_dir: str, text: str, analyzer: MultimodalAnalyzer,
                         mode: str = 'knowledge', output_dir: str = "multimodal_analysis") -> bool:
    """
    å¤„ç†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¤¹

    Args:
        image_dir: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        text: é…å¥—çš„æ–‡å­—å†…å®¹
        analyzer: MultimodalAnalyzer å®ä¾‹
        mode: åˆ†ææ¨¡å¼
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    image_dir = Path(image_dir)

    if not image_dir.is_dir():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {image_dir}")
        return False

    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp']
    image_paths = []
    for ext in image_extensions:
        image_paths.extend(image_dir.glob(f"*{ext}"))
        image_paths.extend(image_dir.glob(f"*{ext.upper()}"))

    image_paths = sorted(image_paths)

    if not image_paths:
        print(f"âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return False

    print(f"ğŸ“ æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

    # ä¸Šä¼ å›¾ç‰‡
    uploaded_files = analyzer.upload_images(image_paths)

    if not uploaded_files:
        print(f"âŒ å›¾ç‰‡ä¸Šä¼ å¤±è´¥")
        return False

    try:
        # åˆ†æå›¾æ–‡
        result, token_info = analyzer.analyze_note(
            text=text or "(æ— æ–‡å­—å†…å®¹)",
            image_files=uploaded_files,
            mode=mode
        )

        # åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
        analyzer.delete_files(uploaded_files)

        # ä¿å­˜ç»“æœ
        if result and not result.startswith("âŒ"):
            title = image_dir.name
            result_file = save_result(
                title=title,
                text=text,
                result=result,
                mode=mode,
                model=analyzer.model_name,
                token_info=token_info,
                image_count=len(uploaded_files),
                output_dir=output_dir
            )
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file.name}")

            if token_info and token_info.get('total_tokens', 0) > 0:
                print(f"ğŸ“Š Token ä½¿ç”¨: è¾“å…¥ {token_info.get('prompt_tokens', 0):,} | è¾“å‡º {token_info.get('candidates_tokens', 0):,} | æ€»è®¡ {token_info.get('total_tokens', 0):,}")

            return True
        else:
            print(f"âŒ åˆ†æå¤±è´¥")
            return False

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return False


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Gemini API è¿›è¡Œå›¾æ–‡å¤šæ¨¡æ€åˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. åˆ†æå•ä¸ªå°çº¢ä¹¦ç¬”è®°:
   python multimodal_gemini.py --url "å°çº¢ä¹¦ç¬”è®°é“¾æ¥"

2. æ‰¹é‡åˆ†æï¼ˆä»CSVè¯»å–ï¼‰:
   python multimodal_gemini.py --csv notes.csv

3. åˆ†ææœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¤¹:
   python multimodal_gemini.py --dir "images_folder" --text "é…å¥—çš„æ–‡å­—æè¿°"

4. æŒ‡å®šæ¨¡å¼:
   python multimodal_gemini.py --url "..." --mode knowledge

5. ä¿ç•™ä¸‹è½½çš„å›¾ç‰‡:
   python multimodal_gemini.py --url "..." --keep-images
        """
    )

    parser.add_argument('--url', help='å°çº¢ä¹¦ç¬”è®°é“¾æ¥')
    parser.add_argument('--csv', help='CSVæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«urlåˆ—ï¼‰')
    parser.add_argument('--dir', help='æœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--text', help='é…å¥—çš„æ–‡å­—å†…å®¹ï¼ˆç”¨äº--diræ¨¡å¼ï¼‰')
    parser.add_argument('-m', '--mode', choices=['knowledge', 'summary'],
                        default='knowledge', help='åˆ†ææ¨¡å¼ï¼ˆé»˜è®¤: knowledgeï¼‰')
    parser.add_argument('--model', choices=['flash', 'flash-lite', 'pro'],
                        default='flash-lite', help='Gemini æ¨¡å‹ï¼ˆé»˜è®¤: flash-liteï¼‰')
    parser.add_argument('-o', '--output', default='multimodal_analysis',
                        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: multimodal_analysisï¼‰')
    parser.add_argument('--keep-images', action='store_true',
                        help='ä¿ç•™ä¸‹è½½çš„å›¾ç‰‡')
    parser.add_argument('--api-key', help='Gemini API Keyï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')

    args = parser.parse_args()

    # åˆå§‹åŒ–åˆ†æå™¨
    try:
        analyzer = MultimodalAnalyzer(model=args.model, api_key=args.api_key)
    except ValueError as e:
        print(f"âŒ {e}")
        return

    print(f"\n{'='*80}")
    print(f"ğŸ–¼ï¸  å›¾æ–‡å¤šæ¨¡æ€åˆ†æå·¥å…·")
    print(f"{'='*80}")

    # å¤„ç†å°çº¢ä¹¦é“¾æ¥
    if args.url:
        print(f"ğŸ”— é“¾æ¥: {args.url[:80]}...")
        success = process_xhs_note(
            url=args.url,
            analyzer=analyzer,
            mode=args.mode,
            output_dir=args.output,
            keep_images=args.keep_images
        )

        if success:
            print(f"\nâœ… å®Œæˆ!")
        else:
            print(f"\nâŒ å¤±è´¥!")

    # å¤„ç†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶å¤¹
    elif args.dir:
        print(f"ğŸ“ å›¾ç‰‡ç›®å½•: {args.dir}")
        print(f"ğŸ“ æ–‡å­—å†…å®¹: {args.text[:100] if args.text else '(æ— )'}...")
        success = process_local_images(
            image_dir=args.dir,
            text=args.text or "",
            analyzer=analyzer,
            mode=args.mode,
            output_dir=args.output
        )

        if success:
            print(f"\nâœ… å®Œæˆ!")
        else:
            print(f"\nâŒ å¤±è´¥!")

    # æ‰¹é‡å¤„ç†CSV
    elif args.csv:
        csv_path = Path(args.csv)
        if not csv_path.exists():
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv}")
            return

        print(f"ğŸ“‹ CSVæ–‡ä»¶: {args.csv}")

        with open(csv_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            rows = list(reader)

        print(f"ğŸ“Š å¾…å¤„ç†: {len(rows)} æ¡è®°å½•\n")

        success_count = 0
        fail_count = 0

        for i, row in enumerate(rows, 1):
            url = row.get('url') or row.get('é“¾æ¥') or row.get('URL', '')
            if not url:
                continue

            print(f"\n{'='*80}")
            print(f"[{i}/{len(rows)}] å¤„ç†: {url[:60]}...")
            print(f"{'='*80}")

            if process_xhs_note(url, analyzer, args.mode, args.output, args.keep_images):
                success_count += 1
            else:
                fail_count += 1

        print(f"\n{'='*80}")
        print(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ")
        print(f"{'='*80}")
        print(f"æ€»è®¡: {len(rows)} | æˆåŠŸ: {success_count} | å¤±è´¥: {fail_count}")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
