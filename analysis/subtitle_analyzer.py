#!/usr/bin/env python3
"""
ç®€åŒ–çš„å­—å¹•åˆ†æå·¥å…·
åŠŸèƒ½ï¼š
1. è¯»å–å­—å¹•æ–‡ä»¶
2. ç”Ÿæˆä¹¦é¢æ–‡ç¨¿
3. æå–è®ºç‚¹è®ºæ®ï¼ˆéæ–°é—»ç±»ï¼‰æˆ–æ–°é—»è¦ç‚¹ï¼ˆæ–°é—»ç±»ï¼‰
"""

import os
import sys
import re
import argparse
from pathlib import Path
from typing import List, Dict


# ä¼˜å…ˆä½¿ç”¨æ–° SDK
try:
    from google import genai
    USE_NEW_SDK = True
except ImportError:
    try:
        import google.generativeai as genai
        USE_NEW_SDK = False
    except ImportError:
        print("æœªå®‰è£… google-genai æˆ– google-generativeai åº“")
        print("è¯·è¿è¡Œ: pip install google-genai")
        sys.exit(1)


def get_api_key() -> str:
    """è·å– Gemini API Key (ä¼˜å…ˆçº§: é…ç½®æ–‡ä»¶ > ç¯å¢ƒå˜é‡)"""
    # 1. ä¼˜å…ˆä»é…ç½®æ–‡ä»¶è¯»å–
    try:
        # è·å–é¡¹ç›®æ ¹ç›®å½• (analysis/ çš„çˆ¶ç›®å½•)
        project_root = Path(__file__).parent.parent
        config_path = project_root / 'config'
        sys.path.insert(0, str(config_path))
        from config_api import API_CONFIG
        api_key = API_CONFIG.get('gemini', {}).get('api_key')
        if api_key:
            return api_key
    except (ImportError, FileNotFoundError):
        pass

    # 2. å…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
    api_key = os.environ.get('GEMINI_API_KEY')
    if api_key:
        return api_key

    return None


class GeminiClient:
    """Gemini API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ–°æ—§ SDKï¼‰"""

    def __init__(self, model: str = 'flash-lite', api_key: str = None):
        self.api_key = api_key or get_api_key()
        self.model_name = {
            'flash-lite': 'gemini-2.5-flash-lite',
            'flash': 'gemini-2.5-flash',
            'pro': 'gemini-2.5-pro',
        }.get(model, 'gemini-2.5-flash-lite')

        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° Gemini API Key")

        if self.use_new_sdk:
            # æ–° SDK
            self.client = genai.Client(api_key=self.api_key)
        else:
            # æ—§ SDK
            import google.generativeai as genai_old
            genai_old.configure(api_key=self.api_key)

    @property
    def use_new_sdk(self):
        return USE_NEW_SDK

    def generate_content(self, prompt: str) -> Dict:
        """
        ç”Ÿæˆå†…å®¹

        Returns:
            {'text': 'ç”Ÿæˆå†…å®¹', 'tokens': int, 'input_tokens': int, 'output_tokens': int,
             'success': bool, 'error': str}
        """
        try:
            if self.use_new_sdk:
                # æ–° SDK
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=prompt
                )
                text = response.text
                # æ–° SDK token ä¿¡æ¯
                input_tokens = 0
                output_tokens = 0
                total_tokens = 0
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    metadata = response.usage_metadata
                    input_tokens = getattr(metadata, 'prompt_token_count', 0) or 0
                    output_tokens = getattr(metadata, 'candidates_token_count', 0) or 0
                    total_tokens = getattr(metadata, 'total_token_count', 0) or 0
            else:
                # æ—§ SDK
                import google.generativeai as genai_old
                model = genai_old.GenerativeModel(self.model_name)
                response = model.generate_content(prompt)
                text = response.text
                input_tokens = 0
                output_tokens = 0
                total_tokens = 0
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    metadata = response.usage_metadata
                    input_tokens = getattr(metadata, 'prompt_token_count', 0) or 0
                    output_tokens = getattr(metadata, 'candidates_token_count', 0) or 0
                    total_tokens = getattr(metadata, 'total_token_count', 0) or 0

            return {
                'text': text.strip() if text else '',
                'tokens': total_tokens,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'success': True
            }

        except Exception as e:
            return {
                'text': '',
                'tokens': 0,
                'input_tokens': 0,
                'output_tokens': 0,
                'success': False,
                'error': str(e)
            }


def parse_srt(srt_path: Path) -> List[Dict]:
    """
    è§£æ SRT æ–‡ä»¶ï¼Œè¿”å›å­—å¹•æ¡ç›®åˆ—è¡¨

    Returns:
        [
            {'index': 1, 'start': '00:00:01,000', 'end': '00:00:04,000', 'text': 'å­—å¹•å†…å®¹'},
            ...
        ]
    """
    entries = []

    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # SRT æ ¼å¼è§£æ
    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?=\n\n|\n\d+\n|$)'
    matches = re.findall(pattern, content, re.DOTALL)

    for match in matches:
        index, start, end, text = match
        entries.append({
            'index': int(index),
            'start': start,
            'end': end,
            'text': text.strip().replace('\n', ' ')
        })

    return entries


def srt_to_text(srt_path: Path, max_length: int = 15000) -> str:
    """
    å°† SRT è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œæ§åˆ¶é•¿åº¦é¿å…è¶…é™

    Args:
        srt_path: SRT æ–‡ä»¶è·¯å¾„
        max_length: æœ€å¤§æ–‡æœ¬é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰

    Returns:
        å­—å¹•æ–‡æœ¬å†…å®¹
    """
    entries = parse_srt(srt_path)

    # åˆå¹¶æ‰€æœ‰å­—å¹•æ–‡æœ¬
    full_text = ' '.join([e['text'] for e in entries])

    # å¦‚æœè¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œæˆªæ–­å¹¶ä¿ç•™å‰80%
    if len(full_text) > max_length:
        full_text = full_text[:int(max_length * 0.8)] + '\n\n[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­...]'

    return full_text


def detect_video_style(text: str, title: str = "") -> str:
    """
    æ£€æµ‹è§†é¢‘é£æ ¼ç±»å‹

    Args:
        text: å­—å¹•æ–‡æœ¬
        title: è§†é¢‘æ ‡é¢˜

    Returns:
        è§†é¢‘é£æ ¼ç±»å‹ ('news' æˆ– 'non_news')
    """
    # æ–°é—»ç±»å…³é”®è¯
    news_keywords = ['æ–°é—»', 'æŠ¥é“', 'äº‹ä»¶', 'æ—¶äº‹', 'çƒ­ç‚¹', 'çªå‘', 'æœ€æ–°', 'æ¶ˆæ¯', 'é€šæŠ¥']

    text_lower = text.lower()
    title_lower = title.lower() if title else ''

    # æ£€æŸ¥å…³é”®è¯
    for keyword in news_keywords:
        if keyword in text_lower or keyword in title_lower:
            return 'news'

    return 'non_news'


def generate_summary(text: str, title: str = "", model: str = 'flash-lite') -> Dict:
    """
    ç”Ÿæˆè§†é¢‘æ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºå…¼å®¹æ—§ä»£ç ï¼‰

    Args:
        text: å­—å¹•æ–‡æœ¬æˆ–åŸå§‹SRTå†…å®¹
        title: è§†é¢‘æ ‡é¢˜
        model: Gemini æ¨¡å‹

    Returns:
        {'summary': 'æ‘˜è¦å†…å®¹', 'tokens': int, 'input_tokens': int, 'output_tokens': int, 'success': bool}
    """
    client = GeminiClient(model=model)

    # æ£€æµ‹é£æ ¼
    video_style = detect_video_style(text, title)

    # æ£€æµ‹æ˜¯å¦ä¸ºå¯¹è¯å¼
    is_dialogue = ('è¯´' in text and 'é—®' in text) or ('å›ç­”' in text) or ('é‡‡è®¿' in title)

    # åˆ¤æ–­æ˜¯å¦ä¸º SRT æ ¼å¼ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    is_srt = '-->' in text

    # å¦‚æœæ˜¯ SRT æ ¼å¼ï¼Œå…ˆè§£ææˆçº¯æ–‡æœ¬
    if is_srt:
        # ç®€å•å»é™¤æ—¶é—´æˆ³å’Œåºå·
        lines = text.split('\n')
        clean_lines = []
        for line in lines:
            # è·³è¿‡æ—¶é—´æˆ³è¡Œå’Œåºå·è¡Œ
            if '-->' in line or line.strip().isdigit():
                continue
            # è·³è¿‡ç©ºè¡Œ
            if not line.strip():
                continue
            clean_lines.append(line.strip())
        text = ' '.join(clean_lines)

    # ç”Ÿæˆåˆ†ææç¤ºè¯
    if video_style == 'news':
        prompt = f"""è¯·åˆ†æä»¥ä¸‹è§†é¢‘å†…å®¹ï¼ˆæ–°é—»ç±»ï¼‰ï¼Œç”Ÿæˆç®€æ´çš„æ‘˜è¦ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{title if title else "æ— æ ‡é¢˜"}

å­—å¹•å†…å®¹ï¼š
{text[:10000]}

ã€é‡è¦è¾“å‡ºè¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
2. ä¸è¦è¾“å‡ºä»»ä½•å¼€åœºç™½ã€ç»“æŸè¯­æˆ–è§£é‡Šæ€§æ–‡å­—
3. ç›´æ¥è¾“å‡ºmarkdownæ ¼å¼çš„å†…å®¹
4. æ–°é—»è¦ç‚¹å¿…é¡»æŒ‰ç…§å›ºå®šæ ¼å¼åˆ—å‡º

è¾“å‡ºæ ¼å¼ï¼š

# è§†é¢‘æ‘˜è¦

## ğŸ“‹ æ ¸å¿ƒå†…å®¹
[ç”¨100-200å­—æ¦‚æ‹¬æ–°é—»çš„æ ¸å¿ƒäº‹ä»¶]

## ğŸ“° ä¸»è¦æ–°é—»è¦ç‚¹
1. **äº‹ä»¶**: [äº‹ä»¶åç§°] - **å…³é”®ä¿¡æ¯**: [ç®€è¦è¯´æ˜]
2. **äº‹ä»¶**: [äº‹ä»¶åç§°] - **å…³é”®ä¿¡æ¯**: [ç®€è¦è¯´æ˜]

---
ï¼ˆæ ¹æ®å®é™…å†…å®¹åˆ—å‡ºæ‰€æœ‰è¦ç‚¹ï¼Œæ¯ç‚¹ä¸€è¡Œï¼‰"""
    else:
        prompt = f"""è¯·åˆ†æä»¥ä¸‹è§†é¢‘å†…å®¹ï¼Œç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{title if title else "æ— æ ‡é¢˜"}
{'å†…å®¹ç±»å‹: å¯¹è¯å¼' if is_dialogue else 'å†…å®¹ç±»å‹: å™è¿°å¼'}

å­—å¹•å†…å®¹ï¼š
{text[:10000]}

ã€é‡è¦è¾“å‡ºè¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
2. ä¸è¦è¾“å‡ºä»»ä½•å¼€åœºç™½ã€ç»“æŸè¯­æˆ–è§£é‡Šæ€§æ–‡å­—
3. ç›´æ¥è¾“å‡ºmarkdownæ ¼å¼çš„å†…å®¹
4. è§‚ç‚¹å¿…é¡»æŒ‰ç…§å›ºå®šæ ¼å¼åˆ—å‡º

è¾“å‡ºæ ¼å¼ï¼š

# è§†é¢‘æ‘˜è¦

## ğŸ“– æ ¸å¿ƒä¸»é¢˜
[ä¸€å¥è¯æ¦‚æ‹¬è§†é¢‘çš„æ ¸å¿ƒå†…å®¹]

## ğŸ¯ ä¸»è¦è§‚ç‚¹
1. **è§‚ç‚¹**: [æ ¸å¿ƒè§‚ç‚¹]
   - **è®ºæ®**: [æ”¯æŒè®ºæ®]
2. **è§‚ç‚¹**: [æ ¸å¿ƒè§‚ç‚¹]
   - **è®ºæ®**: [æ”¯æŒè®ºæ®]

---
ï¼ˆæ ¹æ®å®é™…å†…å®¹åˆ—å‡ºæ‰€æœ‰è§‚ç‚¹ï¼Œæ¯ç‚¹ä¸€è¡Œï¼‰

## ğŸ’ é‡‘å¥
- [ç²¾å½©å¥å­1]
- [ç²¾å½©å¥å­2]
- [ç²¾å½©å¥å­3]"""

    result = client.generate_content(prompt)

    if result['success']:
        return {
            'summary': result['text'],
            'tokens': result['tokens'],
            'input_tokens': result['input_tokens'],
            'output_tokens': result['output_tokens'],
            'success': True
        }
    else:
        return {
            'summary': f"ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
            'tokens': 0,
            'input_tokens': 0,
            'output_tokens': 0,
            'success': False,
            'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
        }


# ä¸ºäº†å…¼å®¹æ—§ä»£ç ï¼Œåˆ›å»ºä¸€ä¸ª GeminiSummarizer ç±»
class GeminiSummarizer:
    """
    å…¼å®¹ç±»ï¼Œç”¨äºä¿æŒä¸æ—§ä»£ç çš„å…¼å®¹æ€§
    """
    def __init__(self, model: str = 'flash-lite'):
        self.model = model
        self.client = GeminiClient(model=model)

    def generate_summary(self, text: str, title: str = "") -> Dict:
        """è°ƒç”¨å…¨å±€ generate_summary å‡½æ•°"""
        return generate_summary(text, title, self.model)


def generate_written_script(text: str, title: str = "", is_dialogue: bool = False) -> str:
    """
    ç”Ÿæˆä¹¦é¢æ–‡ç¨¿

    Args:
        text: å­—å¹•æ–‡æœ¬
        title: è§†é¢‘æ ‡é¢˜
        is_dialogue: æ˜¯å¦æ˜¯å¯¹è¯å¼

    Returns:
        ä¹¦é¢æ–‡ç¨¿
    """
    if is_dialogue:
        # å¯¹è¯å¼ï¼šæå–äººç‰©å¯¹è¯
        prompt = f"""è¯·å°†ä»¥ä¸‹å­—å¹•å†…å®¹æ•´ç†æˆç»“æ„åŒ–çš„å¯¹è¯è®°å½•ï¼Œæå–äººç‰©å¹¶æ ‡è®°å¯¹è¯å†…å®¹ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{title if title else "æ— æ ‡é¢˜"}

å­—å¹•å†…å®¹ï¼š
{text}

ã€é‡è¦è¾“å‡ºè¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
2. ä¸è¦è¾“å‡ºå¼€åœºç™½ã€ç»“æŸè¯­æˆ–è§£é‡Šæ€§æ–‡å­—
3. è¯†åˆ«å¹¶æå–ä¸åŒäººç‰©çš„å¯¹è¯
4. ä¿æŒå¯¹è¯çš„å®Œæ•´æ€§
5. å»é™¤é‡å¤çš„å¯¹è¯
6. ä½¿ç”¨ç®€æ´çš„è¯­è¨€è¡¨è¾¾

è¾“å‡ºæ ¼å¼ï¼š

## å¯¹è¯è®°å½•

### äººç‰©A
[å¯¹è¯å†…å®¹1]

[å¯¹è¯å†…å®¹2]

### äººç‰©B
[å¯¹è¯å†…å®¹1]

[å¯¹è¯å†…å®¹2]

---
ï¼ˆæ ¹æ®å®é™…å†…å®¹åˆ—å‡ºæ‰€æœ‰äººç‰©å¯¹è¯ï¼‰"""
    else:
        # éå¯¹è¯å¼ï¼šç”Ÿæˆæ ‡å‡†çš„ä¹¦é¢æ–‡ç¨¿
        prompt = f"""è¯·å°†ä»¥ä¸‹å­—å¹•å†…å®¹æ•´ç†æˆç²¾ç‚¼çš„ä¹¦é¢è¡¨è¾¾æ–‡ç¨¿ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{title if title else "æ— æ ‡é¢˜"}

å­—å¹•å†…å®¹ï¼š
{text}

ã€é‡è¦è¾“å‡ºè¦æ±‚ã€‘
1. å»é™¤æ‰€æœ‰å£è¯­åŒ–å†—ä½™ï¼ˆå¦‚"é‚£ä¸ª"ã€"å°±æ˜¯"ã€"ç„¶å"ç­‰ï¼‰
2. ä½¿ç”¨æ­£å¼ã€ç»“æ„åŒ–çš„ä¹¦é¢è¯­è¨€
3. ä¿ç•™æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘é“¾æ¡
4. é€‚åˆä½œä¸ºæ¨¡å‹è®­ç»ƒçš„è¯­è¨€ææ–™
5. å­—æ•°æ§åˆ¶åœ¨åŸæ–‡çš„30%-50%
6. ä¿æŒå†…å®¹çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
7. æŒ‰ç…§æ®µè½ç»„ç»‡å†…å®¹ï¼Œä½¿ç”¨é€‚å½“çš„è¿æ¥è¯
8. ä¸è¦æ·»åŠ ä»»ä½•å¼€åœºç™½æˆ–ç»“æŸè¯­ï¼Œç›´æ¥è¾“å‡ºæ–‡ç¨¿å†…å®¹

è¯·ç›´æ¥è¾“å‡ºä¹¦é¢æ–‡ç¨¿ï¼š"""

    return prompt


def generate_analysis(prompt: str, client: GeminiClient) -> Dict:
    """
    ä½¿ç”¨ Gemini è¿›è¡Œåˆ†æ

    Args:
        prompt: åˆ†ææç¤ºè¯
        client: Gemini å®¢æˆ·ç«¯

    Returns:
        åˆ†æç»“æœ
    """
    result = client.generate_content(prompt)

    if result['success']:
        return {
            'content': result['text'],
            'tokens': result['tokens'],
            'input_tokens': result['input_tokens'],
            'output_tokens': result['output_tokens'],
            'success': True
        }
    else:
        return {
            'content': f"åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
            'tokens': 0,
            'input_tokens': 0,
            'output_tokens': 0,
            'success': False,
            'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
        }


def analyze_subtitle_file(srt_file: Path, output_dir: Path, model: str = 'flash-lite') -> Dict:
    """
    åˆ†æå•ä¸ªå­—å¹•æ–‡ä»¶

    Args:
        srt_file: SRT æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        åˆ†æç»“æœ
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)

    # æå–æ ‡é¢˜
    title = srt_file.stem

    # æ£€æµ‹è§†é¢‘é£æ ¼
    srt_text = srt_to_text(srt_file)
    video_style = detect_video_style(srt_text, title)
    print(f"ğŸ“„ æ–‡ä»¶: {title}")
    print(f"ğŸ­ é£æ ¼: {'æ–°é—»ç±»' if video_style == 'news' else 'éæ–°é—»ç±»'}")

    # åˆ¤æ–­æ˜¯å¦ä¸ºå¯¹è¯å¼
    is_dialogue = ('è¯´' in srt_text and 'é—®' in srt_text) or ('å›ç­”' in srt_text) or ('é‡‡è®¿' in title)

    # åˆ›å»º Gemini å®¢æˆ·ç«¯
    client = GeminiClient(model=model)

    # ç”Ÿæˆä¹¦é¢æ–‡ç¨¿
    print(f"ğŸ“ ç”Ÿæˆä¹¦é¢æ–‡ç¨¿...")
    written_script_prompt = generate_written_script(srt_text, title, is_dialogue)
    written_script_result = generate_analysis(written_script_prompt, client)

    if not written_script_result['success']:
        return {
            'title': title,
            'srt_file': srt_file.name,
            'error': written_script_result.get('error', 'ä¹¦é¢æ–‡ç¨¿ç”Ÿæˆå¤±è´¥'),
            'style': video_style,
            'dialogue': is_dialogue
        }

    # ç”Ÿæˆåˆ†æå†…å®¹
    if video_style == 'news':
        # æ–°é—»ç±»ï¼šæå–æ–°é—»è¦ç‚¹
        analysis_prompt = f"""è¯·åˆ†æä»¥ä¸‹ä¹¦é¢æ–‡ç¨¿ï¼Œæå–æ‰€æœ‰æ–°é—»è¦ç‚¹ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{title}

ä¹¦é¢æ–‡ç¨¿ï¼š
{written_script_result['content']}

ã€é‡è¦è¾“å‡ºè¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
2. ä¸è¦è¾“å‡ºå¼€åœºç™½ã€ç»“æŸè¯­æˆ–è§£é‡Šæ€§æ–‡å­—
3. åˆ—å‡ºæ‰€æœ‰è¯†åˆ«åˆ°çš„æ–°é—»è¦ç‚¹ï¼Œè¦ç‚¹ä¹‹é—´ä¸è¦é‡å¤
4. æ¯ä¸ªè¦ç‚¹åŒ…å«6ä¸ªè¦ç´ ï¼Œæå–å®Œæ•´ä¿¡æ¯ä¸è¦é—æ¼
5. ä½¿ç”¨markdownæ ¼å¼è¾“å‡º

è¾“å‡ºæ ¼å¼ï¼š

## æ–°é—»è¦ç‚¹

### è¦ç‚¹ 1
- **äº‹ä»¶**: [äº‹ä»¶åç§°]
- **æ—¶é—´**: [å‘ç”Ÿæ—¶é—´]
- **åœ°ç‚¹**: [äº‹ä»¶åœ°ç‚¹]
- **æ¶‰åŠäººç‰©/æœºæ„**: [ç›¸å…³æ–¹]
- **å…³é”®ä¿¡æ¯**: [æœ€é‡è¦çš„ä¿¡æ¯]
- **å½±å“/ç»“æœ**: [äº§ç”Ÿçš„å½±å“æˆ–ç»“æœ]

### è¦ç‚¹ 2
- **äº‹ä»¶**: [äº‹ä»¶åç§°]
- **æ—¶é—´**: [å‘ç”Ÿæ—¶é—´]
- **åœ°ç‚¹**: [äº‹ä»¶åœ°ç‚¹]
- **æ¶‰åŠäººç‰©/æœºæ„**: [ç›¸å…³æ–¹]
- **å…³é”®ä¿¡æ¯**: [æœ€é‡è¦çš„ä¿¡æ¯]
- **å½±å“/ç»“æœ**: [äº§ç”Ÿçš„å½±å“æˆ–ç»“æœ]

---
ï¼ˆæ ¹æ®å®é™…å†…å®¹åˆ—å‡ºæ‰€æœ‰æ–°é—»è¦ç‚¹ï¼Œæ¯ç‚¹ä¸€ä¸ªäºŒçº§æ ‡é¢˜ï¼‰"""
    else:
        # éæ–°é—»ç±»ï¼šæå–è®ºç‚¹è®ºæ®
        analysis_prompt = f"""è¯·åˆ†æä»¥ä¸‹ä¹¦é¢æ–‡ç¨¿ï¼Œæå–æ‰€æœ‰è®ºç‚¹å’Œè®ºæ®ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{title}

ä¹¦é¢æ–‡ç¨¿ï¼š
{written_script_result['content']}

ã€é‡è¦è¾“å‡ºè¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
2. ä¸è¦è¾“å‡ºå¼€åœºç™½ã€ç»“æŸè¯­æˆ–è§£é‡Šæ€§æ–‡å­—
3. åˆ—å‡ºæ‰€æœ‰è¯†åˆ«åˆ°çš„è®ºç‚¹ï¼Œæ¯ä¸ªè®ºç‚¹è‡³å°‘åˆ—å‡ºä¸€ä¸ªè®ºæ®
4. è®ºæ®ä¹‹é—´ä¸è¦é‡å¤
5. å¯¹è®ºæ®çš„å¯ä¿¡åº¦è¿›è¡Œè¯„ä¼°
6. ä½¿ç”¨markdownæ ¼å¼è¾“å‡º

è¾“å‡ºæ ¼å¼ï¼š

## è®ºç‚¹ä¸è®ºæ®

### è®ºç‚¹ 1
- **è®ºç‚¹**: [æ ¸å¿ƒè§‚ç‚¹]
- **è®ºæ®1**: [æ”¯æŒè®ºæ®1]
- **è®ºæ®2**: [æ”¯æŒè®ºæ®2]
- **è®ºæ®3**: [æ”¯æŒè®ºæ®3ï¼ˆå¦‚æœ‰ï¼‰]
- **å¯ä¿¡åº¦**: [é«˜/ä¸­/ä½]

### è®ºç‚¹ 2
- **è®ºç‚¹**: [æ ¸å¿ƒè§‚ç‚¹]
- **è®ºæ®1**: [æ”¯æŒè®ºæ®1]
- **è®ºæ®2**: [æ”¯æŒè®ºæ®2]
- **è®ºæ®3**: [æ”¯æŒè®ºæ®3ï¼ˆå¦‚æœ‰ï¼‰]
- **å¯ä¿¡åº¦**: [é«˜/ä¸­/ä½]

---
ï¼ˆæ ¹æ®å®é™…å†…å®¹åˆ—å‡ºæ‰€æœ‰è®ºç‚¹ï¼Œæ¯ç‚¹ä¸€ä¸ªäºŒçº§æ ‡é¢˜ï¼‰"""

    analysis_result = generate_analysis(analysis_prompt, client)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_file = output_dir / f"{title}_åˆ†æç»“æœ.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# {title} å­—å¹•åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**è§†é¢‘é£æ ¼**: {'æ–°é—»ç±»' if video_style == 'news' else 'éæ–°é—»ç±»'}\n")
        f.write(f"**å¯¹è¯å¼**: {'æ˜¯' if is_dialogue else 'å¦'}\n")
        f.write(f"**ä½¿ç”¨æ¨¡å‹**: {model}\n")
        f.write(f"**Tokenç»Ÿè®¡**: è¾“å…¥ {written_script_result['input_tokens']:,} | è¾“å‡º {written_script_result['output_tokens']:,} | æ€»è®¡ {written_script_result['tokens']:,}\n\n")
        f.write("---\n\n")

        # ä¹¦é¢æ–‡ç¨¿
        f.write("## ğŸ“ ä¹¦é¢æ–‡ç¨¿\n\n")
        f.write(written_script_result['content'])
        f.write("\n\n")

        # åˆ†æç»“æœ
        f.write("## ğŸ“Š åˆ†æç»“æœ\n\n")
        if analysis_result['success']:
            f.write(analysis_result['content'])
            f.write(f"\n\n**Tokenç»Ÿè®¡**: è¾“å…¥ {analysis_result['input_tokens']:,} | è¾“å‡º {analysis_result['output_tokens']:,} | æ€»è®¡ {analysis_result['tokens']:,}")
        else:
            f.write(f"âŒ åˆ†æå¤±è´¥: {analysis_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        f.write("\n\n---\n\n")
        f.write(f"**æºæ–‡ä»¶**: {srt_file.name}\n")

    print(f"  âœ… åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"  ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥ {written_script_result['input_tokens']:,} + {analysis_result['input_tokens']:,} = {written_script_result['input_tokens'] + analysis_result['input_tokens']:,}")
    print(f"  ğŸ“ Tokenè¾“å‡º: è¾“å‡º {written_script_result['output_tokens']:,} + {analysis_result['output_tokens']:,} = {written_script_result['output_tokens'] + analysis_result['output_tokens']:,}")

    return {
        'title': title,
        'srt_file': srt_file.name,
        'output_file': str(output_file),
        'style': video_style,
        'dialogue': is_dialogue,
        'success': True,
        'tokens': written_script_result['tokens'] + analysis_result['tokens']
    }


def main():
    parser = argparse.ArgumentParser(
        description="ç®€åŒ–çš„å­—å¹•åˆ†æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
    # åˆ†æå•ä¸ªå­—å¹•æ–‡ä»¶
    python subtitle_analyzer.py -i video.srt -o output/

    # åˆ†ææ•´ä¸ªæ–‡ä»¶å¤¹
    python subtitle_analyzer.py -d /path/to/subtitles -o output/

    # æŒ‡å®šæ¨¡å‹
    python subtitle_analyzer.py -i video.srt -o output/ -m flash
        """
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('-i', '--input', help='è¾“å…¥ SRT æ–‡ä»¶è·¯å¾„')
    group.add_argument('-d', '--directory', help='è¾“å…¥å­—å¹•æ–‡ä»¶å¤¹è·¯å¾„')

    parser.add_argument('-o', '--output', required=True, help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('-m', '--model', choices=['flash', 'flash-lite', 'pro'],
                        default='flash-lite', help='Gemini æ¨¡å‹ï¼ˆé»˜è®¤: flash-liteï¼‰')

    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)

    if args.input:
        # åˆ†æå•ä¸ªæ–‡ä»¶
        srt_file = Path(args.input)
        if not srt_file.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {srt_file}")
            return

        if not srt_file.suffix.lower() == '.srt':
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {srt_file.suffix}ï¼Œè¯·ä½¿ç”¨ .srt æ–‡ä»¶")
            return

        result = analyze_subtitle_file(srt_file, output_dir, args.model)

        print(f"\n{'='*60}")
        print(f"ğŸ“Š åˆ†æå®Œæˆ!")
        print(f"  æ–‡ä»¶: {result['title']}")
        print(f"  çŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        if result['success']:
            print(f"  è¾“å‡º: {result['output_file']}")
            print(f"  Token: {result['tokens']:,}")
        else:
            print(f"  é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    elif args.directory:
        # åˆ†ææ•´ä¸ªæ–‡ä»¶å¤¹
        subtitle_dir = Path(args.directory)
        if not subtitle_dir.exists():
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {subtitle_dir}")
            return

        # æŸ¥æ‰¾æ‰€æœ‰ SRT æ–‡ä»¶
        srt_files = list(subtitle_dir.glob("*.srt"))

        if not srt_files:
            print(f"âŒ æœªæ‰¾åˆ° SRT æ–‡ä»¶")
            return

        print(f"ğŸ“ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")

        # ç»Ÿè®¡
        success_count = 0
        fail_count = 0
        total_tokens = 0

        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for srt_file in srt_files:
            print(f"\n{'='*60}")
            result = analyze_subtitle_file(srt_file, output_dir, args.model)

            if result['success']:
                success_count += 1
                total_tokens += result['tokens']
            else:
                fail_count += 1

        # æœ€ç»ˆç»Ÿè®¡
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ‰€æœ‰æ–‡ä»¶åˆ†æå®Œæˆ!")
        print(f"  æ€»è®¡: {len(srt_files)}")
        print(f"  æˆåŠŸ: {success_count}")
        print(f"  å¤±è´¥: {fail_count}")
        if success_count > 0:
            print(f"  æ€»Token: {total_tokens:,}")
            print(f"  å¹³å‡Token: {total_tokens//success_count:,}")


if __name__ == "__main__":
    main()