#!/usr/bin/env python3
"""
Â∞èÁ∫¢‰π¶AIÊïôÊéàÁõëÊéßÁ≥ªÁªü - MediaCrawlerÈõÜÊàêÁâà

Ëøô‰∏™ËÑöÊú¨ÂèØ‰ª•Áõ¥Êé•ÂàÜÊûê MediaCrawler Áà¨ÂèñÁöÑÂ∞èÁ∫¢‰π¶Êï∞ÊçÆÔºå
Ëá™Âä®ËØÜÂà´ÁúüÂÆûÊïôÊéàË¥¶Âè∑Âíå‰∏≠‰ªãÂÅá‰ø°ÊÅØ„ÄÇ

‰ΩøÁî®ÊñπÊ≥ï:
    # 1. ÂÖàÁî® MediaCrawler Áà¨ÂèñÊï∞ÊçÆ
    cd MediaCrawler
    python main.py

    # 2. ÂàÜÊûêÁà¨ÂèñÁöÑÊï∞ÊçÆ
    python xhs_professor_monitor_integration.py --analyze-data

    # 3. ÁõëÊéßÊåáÂÆöÁî®Êà∑
    python xhs_professor_monitor_integration.py --add-user "Áî®Êà∑‰∏ªÈ°µURL"

    # 4. Êü•ÁúãÊä•Âëä
    python xhs_professor_monitor_integration.py --report
"""

import os
import sys
import json
import csv
import re
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field
from collections import Counter
import sqlite3

# WindowsÁºñÁ†Å‰øÆÂ§ç
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ==================== ÈÖçÁΩÆ ====================

# ‰∏≠‰ªãÊ£ÄÊµãËßÑÂàô
AGENCY_RULES = {
    'name_patterns': {
        'suspicious': [
            r'\d{4,}$',           # ‰ª•4‰Ωç‰ª•‰∏äÊï∞Â≠óÁªìÂ∞æ
            r'(wx|v|ÂæÆ‰ø°|vx|Âä†ÂæÆ)', # Âê´ÂæÆ‰ø°Áõ∏ÂÖ≥
            r'(ÁïôÂ≠¶|Áî≥ËØ∑|‰∏≠‰ªã|Êú∫ÊûÑ|‰øùÂΩïÂèñ|ÂÜÖÊé®)',  # Âê´‰∏≠‰ªãËØç
        ],
        'safe': [
            r'^[\u4e00-\u9fa5]{2,4}$',  # Á∫Ø‰∏≠Êñá2-4Â≠óÔºàÂèØËÉΩÊòØÁúüÂêçÔºâ
            r'[ÊïôÊéà|Prof|Dr\.|ÂçöÂ£´|PI]',  # Âê´Â≠¶ÊúØÂ§¥Ë°î
        ]
    },
    'bio_signals': {
        'agency': [
            'dd', 'Êª¥Êª¥', 'ÁßÅ‰ø°', 'Âä†v', 'Âä†ÂæÆ', 'vx', 'ÂæÆ‰ø°',
            'ÁïôÂ≠¶', 'Áî≥ËØ∑', '‰∏≠‰ªã', 'Êú∫ÊûÑ', '‰øùoffer', 'ÂÜÖÊé®',
            'ÂêçÈ¢ùÊúâÈôê', 'ÊúÄÂêé', 'ÊäìÁ¥ß', 'Âç≥Â∞ÜÊà™Ê≠¢',
        ],
        'professor': [
            'ÊïôÊéà', 'ÂâØÊïôÊéà', 'Âä©ÁêÜÊïôÊéà', 'PI', 'ÂÆûÈ™åÂÆ§', 'Lab',
            'University', 'Â§ßÂ≠¶', 'Â≠¶Èô¢', 'Á†îÁ©∂ÊâÄ', 'ÂçöÂØº',
        ]
    },
    'content_signals': {
        'agency_high': [
            'dd', 'Êª¥Êª¥', 'Êª¥Êª¥Êàë', 'ÁßÅ‰ø°‰∫ÜËß£', 'Âä†vÂí®ËØ¢',
            '‰øùÂΩïÂèñ', '‰øùoffer', '‰ª£Áî≥ËØ∑',
        ],
        'agency_medium': [
            'ÂÜÖÊé®', 'Êé®Ëçê', 'ÂêçÈ¢ùÊúâÈôê', 'fundingÂÖÖË∂≥', '‰∫∫Âæànice',
            'Êãõ‰∫∫', 'ÊãõÁîü', 'ÊãõÊî∂', 'ÊúâÂÅø', '‰ªòË¥π',
        ],
        'professor_high': [
            'ËÆ∫Êñá', 'paper', 'research', 'È°∂‰ºö', 'ÊúüÂàä',
            'CVPR', 'ICCV', 'NeurIPS', 'ICML', 'AAAI',
            'ÊäïÁ®ø', 'ÂèëË°®', 'Êé•Êî∂', 'ÂÆûÈ™åÂÆ§', 'ËØæÈ¢òÁªÑ',
        ]
    }
}

# ==================== Êï∞ÊçÆÁªìÊûÑ ====================

@dataclass
class AccountAnalysis:
    """Ë¥¶Âè∑ÂàÜÊûêÁªìÊûú"""
    user_id: str
    name: str
    description: str = ""
    followers_count: int = 0
    posts_count: int = 0

    # ËØÑÂàÜ
    credibility_score: float = 50.0  # 0-100
    agency_score: float = 0.0        # 0-100ÔºåË∂äÈ´òË∂äÂÉè‰∏≠‰ªã
    professor_score: float = 0.0     # 0-100ÔºåË∂äÈ´òË∂äÂÉèÊïôÊéà

    # Âà§Êñ≠
    is_professor: bool = False
    is_agency: bool = False
    confidence: str = "low"  # low, medium, high

    # ËØ¶ÊÉÖ
    reasons: List[str] = field(default_factory=list)
    suspicious_signals: List[str] = field(default_factory=list)
    professor_signals: List[str] = field(default_factory=list)


# ==================== ÂàÜÊûêÂô® ====================

class XHSAccountAnalyzer:
    """Â∞èÁ∫¢‰π¶Ë¥¶Âè∑ÂàÜÊûêÂô®"""

    def __init__(self):
        self.rules = AGENCY_RULES

    def analyze_from_mc_data(self, data_dir: str = None) -> Dict:
        """ÂàÜÊûê MediaCrawler Áà¨ÂèñÁöÑÊï∞ÊçÆ"""
        if data_dir is None:
            # ‰ªé platforms/xiaohongshu/ ÂõûÂà∞Áà∂ÁõÆÂΩïÁöÑ MediaCrawler/data/xhs
            data_dir = str(Path(__file__).parent.parent.parent / "MediaCrawler" / "data" / "xhs")
        data_path = Path(data_dir)

        if not data_path.exists():
            return {'accounts': [], 'posts': [], 'errors': ['Êï∞ÊçÆÁõÆÂΩï‰∏çÂ≠òÂú®']}

        accounts = {}
        posts = []

        # ÈÅçÂéÜJSONÊñá‰ª∂
        for json_file in data_path.rglob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # Â§ÑÁêÜ‰∏çÂêåÁöÑÊï∞ÊçÆÊ†ºÂºè
                items = data if isinstance(data, list) else [data]

                for item in items:
                    # ÊèêÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ
                    post = self._extract_post(item)
                    if post:
                        posts.append(post)

                        # ËÅöÂêàË¥¶Âè∑‰ø°ÊÅØ
                        user_id = post.get('user_id', '')
                        if user_id and user_id not in accounts:
                            accounts[user_id] = {
                                'user_id': user_id,
                                'name': post.get('author', ''),
                                'description': post.get('user_desc', ''),
                                'posts': []
                            }
                        if user_id in accounts:
                            accounts[user_id]['posts'].append(post)

            except Exception as e:
                pass

        # ÂàÜÊûêÊØè‰∏™Ë¥¶Âè∑
        analyzed_accounts = []
        for user_id, account_data in accounts.items():
            analysis = self.analyze_account(
                user_id=user_id,
                name=account_data['name'],
                description=account_data['description'],
                posts=account_data['posts']
            )
            analyzed_accounts.append(analysis)

        return {
            'accounts': analyzed_accounts,
            'posts': posts,
            'total': len(analyzed_accounts)
        }

    def _extract_post(self, item: Dict) -> Optional[Dict]:
        """‰ªé MediaCrawler Êï∞ÊçÆ‰∏≠ÊèêÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ"""
        # MediaCrawler ÂèØËÉΩÁöÑÂ≠óÊÆµÂêç
        title = (
            item.get('title') or item.get('note_title') or
            item.get('share_note_title') or ''
        )
        desc = (
            item.get('desc') or item.get('note_desc') or
            item.get('share_note_desc') or item.get('text') or ''
        )

        if not title and not desc:
            return None

        return {
            'post_id': item.get('note_id') or item.get('id') or '',
            'user_id': item.get('user_id') or '',
            'author': item.get('nickname') or item.get('author_name') or '',
            'user_desc': item.get('user_desc') or item.get('user_sign') or '',
            'title': title,
            'desc': desc,
            'likes': item.get('liked_count') or item.get('like_count') or 0,
            'comments': item.get('comment_count') or item.get('comments') or 0,
        }

    def analyze_account(self, user_id: str, name: str, description: str = "",
                       posts: List[Dict] = None) -> AccountAnalysis:
        """ÂàÜÊûêÂçï‰∏™Ë¥¶Âè∑"""
        analysis = AccountAnalysis(
            user_id=user_id,
            name=name,
            description=description,
            posts_count=len(posts) if posts else 0
        )

        if not posts:
            posts = []

        # 1. ÂàÜÊûêÂêçÂ≠ó
        name_score, name_reasons = self._analyze_name(name)
        analysis.agency_score += name_score['agency']
        analysis.professor_score += name_score['professor']
        analysis.reasons.extend(name_reasons)

        # 2. ÂàÜÊûêÁÆÄ‰ªã
        bio_score, bio_reasons, bio_suspicious = self._analyze_bio(description)
        analysis.agency_score += bio_score['agency']
        analysis.professor_score += bio_score['professor']
        analysis.reasons.extend(bio_reasons)
        analysis.suspicious_signals.extend(bio_suspicious)

        # 3. ÂàÜÊûêÂèëÂ∏ñÂÜÖÂÆπ
        post_score, post_reasons, post_suspicious = self._analyze_posts(posts)
        analysis.agency_score += post_score['agency']
        analysis.professor_score += post_score['professor']
        analysis.reasons.extend(post_reasons)
        analysis.suspicious_signals.extend(post_suspicious)

        # 4. ËÆ°ÁÆóÁªºÂêàÂèØ‰ø°Â∫¶
        # Âü∫Á°ÄÂàÜ50ÔºåÊïôÊéàÂä†ÂàÜÔºå‰∏≠‰ªãÊâ£ÂàÜ
        analysis.credibility_score = 50 + analysis.professor_score - analysis.agency_score
        analysis.credibility_score = max(0, min(100, analysis.credibility_score))

        # 5. Âà§Êñ≠Á±ªÂûã
        if analysis.professor_score >= 30 and analysis.agency_score <= 20:
            analysis.is_professor = True
            analysis.confidence = "high" if analysis.credibility_score >= 70 else "medium"

        if analysis.agency_score >= 40:
            analysis.is_agency = True
            analysis.credibility_score = max(0, analysis.credibility_score - 30)

        # È´òÂ∫¶ÂèØÁñëÔºöÂèë‰∫ÜÂ§ö‰∏™‰∏çÂêåËÄÅÂ∏àÁöÑÊãõÁîü‰ø°ÊÅØ
        mentioned_professors = self._extract_mentioned_professors(posts)
        if len(mentioned_professors) >= 3:
            analysis.is_agency = True
            analysis.suspicious_signals.append(f"ÊèêÂèä{len(mentioned_professors)}‰Ωç‰∏çÂêåÁöÑËÄÅÂ∏à")

        return analysis

    def _analyze_name(self, name: str) -> Tuple[Dict, List[str]]:
        """ÂàÜÊûêË¥¶Âè∑Âêç"""
        scores = {'agency': 0, 'professor': 0}
        reasons = []

        # ÂèØÁñëÊ®°Âºè
        for pattern in self.rules['name_patterns']['suspicious']:
            if re.search(pattern, name, re.I):
                scores['agency'] += 20
                reasons.append(f"ÂêçÂ≠óÂê´ÂèØÁñëÊ®°Âºè: {pattern}")

        # ÂÆâÂÖ®Ê®°Âºè
        for pattern in self.rules['name_patterns']['safe']:
            if re.search(pattern, name, re.I):
                scores['professor'] += 15
                reasons.append(f"ÂêçÂ≠óÂê´Â≠¶ÊúØÁâπÂæÅ: {pattern}")

        return scores, reasons

    def _analyze_bio(self, bio: str) -> Tuple[Dict, List[str], List[str]]:
        """ÂàÜÊûêÁÆÄ‰ªã"""
        scores = {'agency': 0, 'professor': 0}
        reasons = []
        suspicious = []

        if not bio:
            return scores, reasons, suspicious

        bio_lower = bio.lower()

        # ‰∏≠‰ªã‰ø°Âè∑
        for signal in self.rules['bio_signals']['agency']:
            if signal in bio_lower:
                scores['agency'] += 10
                suspicious.append(f"ÁÆÄ‰ªãÂê´‰∏≠‰ªãËØç: {signal}")

        # ÊïôÊéà‰ø°Âè∑
        for signal in self.rules['bio_signals']['professor']:
            if signal in bio:
                scores['professor'] += 15
                reasons.append(f"ÁÆÄ‰ªãÂê´Â≠¶ÊúØË∫´‰ªΩ: {signal}")

        return scores, reasons, suspicious

    def _analyze_posts(self, posts: List[Dict]) -> Tuple[Dict, List[str], List[str]]:
        """ÂàÜÊûêÂèëÂ∏ñÂÜÖÂÆπ"""
        scores = {'agency': 0, 'professor': 0}
        reasons = []
        suspicious = []

        if not posts:
            return scores, reasons, suspicious

        for post in posts:
            content = (post.get('title', '') + ' ' + post.get('desc', '')).lower()

            # È´òÊùÉÈáç‰∏≠‰ªã‰ø°Âè∑
            for signal in self.rules['content_signals']['agency_high']:
                if signal in content:
                    scores['agency'] += 15
                    suspicious.append(f"ÂÜÖÂÆπÂê´‰∏≠‰ªãËØç: {signal}")
                    break

            # ‰∏≠Á≠âÊùÉÈáç‰∏≠‰ªã‰ø°Âè∑
            for signal in self.rules['content_signals']['agency_medium']:
                if signal in content:
                    scores['agency'] += 5
                    break

            # ÊïôÊéà‰ø°Âè∑
            for signal in self.rules['content_signals']['professor_high']:
                if signal.lower() in content:
                    scores['professor'] += 10
                    reasons.append(f"ÂÜÖÂÆπÂê´Â≠¶ÊúØËØç: {signal}")
                    break

        return scores, reasons, suspicious

    def _extract_mentioned_professors(self, posts: List[Dict]) -> List[str]:
        """ÊèêÂèñÂ∏ñÂ≠ê‰∏≠ÊèêÂèäÁöÑÊïôÊéàÂêçÂ≠ó"""
        mentioned = set()

        for post in posts:
            content = post.get('title', '') + ' ' + post.get('desc', '')
            # ÂåπÈÖç "XXÊïôÊéà"„ÄÅ"XXËÄÅÂ∏à"„ÄÅ"XXÂØºÂ∏à"
            matches = re.findall(r'([\u4e00-\u9fa5]{2,4})(?:ÊïôÊéà|ËÄÅÂ∏à|ÂØºÂ∏à)', content)
            mentioned.update(matches)

        return list(mentioned)


# ==================== Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜ ====================

class MonitorDatabase:
    """ÁõëÊéßÊï∞ÊçÆÂ∫ì"""

    def __init__(self, db_path: str = "data/professor_monitor.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(str(self.db_path), check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self._init_tables()

    def _init_tables(self):
        """ÂàùÂßãÂåñË°®"""
        cursor = self.conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS accounts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT UNIQUE,
                name TEXT,
                description TEXT,
                credibility_score REAL DEFAULT 50,
                agency_score REAL DEFAULT 0,
                professor_score REAL DEFAULT 0,
                is_professor INTEGER DEFAULT 0,
                is_agency INTEGER DEFAULT 0,
                confidence TEXT DEFAULT 'low',
                reasons TEXT,
                suspicious_signals TEXT,
                posts_count INTEGER DEFAULT 0,
                last_checked TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id TEXT UNIQUE,
                user_id TEXT,
                title TEXT,
                description TEXT,
                likes INTEGER DEFAULT 0,
                is_recruitment INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES accounts(user_id)
            )
        """)

        self.conn.commit()

    def save_account(self, analysis: AccountAnalysis):
        """‰øùÂ≠òË¥¶Âè∑ÂàÜÊûê"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO accounts
            (user_id, name, description, credibility_score, agency_score, professor_score,
             is_professor, is_agency, confidence, reasons, suspicious_signals, posts_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            analysis.user_id, analysis.name, analysis.description,
            analysis.credibility_score, analysis.agency_score, analysis.professor_score,
            int(analysis.is_professor), int(analysis.is_agency), analysis.confidence,
            json.dumps(analysis.reasons, ensure_ascii=False),
            json.dumps(analysis.suspicious_signals, ensure_ascii=False),
            analysis.posts_count
        ))
        self.conn.commit()

    def get_accounts(self, filter_type: str = None) -> List[Dict]:
        """Ëé∑ÂèñË¥¶Âè∑ÂàóË°®"""
        cursor = self.conn.cursor()

        if filter_type == 'professor':
            cursor.execute("SELECT * FROM accounts WHERE is_professor = 1 ORDER BY credibility_score DESC")
        elif filter_type == 'agency':
            cursor.execute("SELECT * FROM accounts WHERE is_agency = 1 ORDER BY credibility_score ASC")
        elif filter_type == 'suspicious':
            cursor.execute("SELECT * FROM accounts WHERE credibility_score < 50 ORDER BY credibility_score ASC")
        else:
            cursor.execute("SELECT * FROM accounts ORDER BY credibility_score DESC")

        return [dict(row) for row in cursor.fetchall()]

    def close(self):
        """ÂÖ≥Èó≠Êï∞ÊçÆÂ∫ì"""
        self.conn.close()


# ==================== Êä•ÂëäÁîüÊàê ====================

class ReportGenerator:
    """Êä•ÂëäÁîüÊàêÂô®"""

    @staticmethod
    def generate_report(analyses: List[AccountAnalysis], output_path: str = "professor_monitor_report.md"):
        """ÁîüÊàêÂàÜÊûêÊä•Âëä"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# Â∞èÁ∫¢‰π¶ÊïôÊéàË¥¶Âè∑ÁõëÊéßÊä•Âëä\n\n")
            f.write(f"ÁîüÊàêÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")

            # ÁªüËÆ°
            professors = [a for a in analyses if a.is_professor]
            agencies = [a for a in analyses if a.is_agency]
            suspicious = [a for a in analyses if a.credibility_score < 50 and not a.is_agency]

            f.write("## üìä ÁªüËÆ°Ê¶ÇËßà\n\n")
            f.write(f"- ÊÄªÂàÜÊûêË¥¶Âè∑: {len(analyses)}\n")
            f.write(f"- ‚úÖ Áñë‰ººÁúüÂÆûÊïôÊéà: {len(professors)}\n")
            f.write(f"- ‚ö†Ô∏è Áñë‰ºº‰∏≠‰ªãË¥¶Âè∑: {len(agencies)}\n")
            f.write(f"- ‚ùì ÂèØÁñëË¥¶Âè∑: {len(suspicious)}\n\n")

            # ÁúüÂÆûÊïôÊéàÂàóË°®
            if professors:
                f.write("## ‚úÖ Áñë‰ººÁúüÂÆûÊïôÊéàË¥¶Âè∑\n\n")
                for a in sorted(professors, key=lambda x: x.credibility_score, reverse=True):
                    f.write(f"### {a.name} (ÂèØ‰ø°Â∫¶: {a.credibility_score:.0f}/100)\n\n")
                    f.write(f"- **Áî®Êà∑ID**: {a.user_id}\n")
                    f.write(f"- **ÁΩÆ‰ø°Â∫¶**: {a.confidence}\n")
                    if a.description:
                        f.write(f"- **ÁÆÄ‰ªã**: {a.description[:100]}...\n")
                    if a.reasons:
                        f.write(f"- **Âà§Êñ≠‰æùÊçÆ**: {', '.join(a.reasons[:3])}\n")
                    f.write(f"- **ÂèëÂ∏ñÊï∞**: {a.posts_count}\n\n")

            # ‰∏≠‰ªãÂàóË°®
            if agencies:
                f.write("## ‚ö†Ô∏è Áñë‰ºº‰∏≠‰ªãË¥¶Âè∑\n\n")
                for a in sorted(agencies, key=lambda x: a.credibility_score):
                    f.write(f"### {a.name} (ÂèØ‰ø°Â∫¶: {a.credibility_score:.0f}/100)\n\n")
                    f.write(f"- **Áî®Êà∑ID**: {a.user_id}\n")
                    if a.suspicious_signals:
                        f.write(f"- **ÂèØÁñë‰ø°Âè∑**: {', '.join(a.suspicious_signals[:5])}\n")
                    f.write(f"- **ÂèëÂ∏ñÊï∞**: {a.posts_count}\n\n")

            # ÂèØÁñëË¥¶Âè∑
            if suspicious:
                f.write("## ‚ùì ÈúÄË¶ÅËøõ‰∏ÄÊ≠•Á°ÆËÆ§ÁöÑË¥¶Âè∑\n\n")
                for a in sorted(suspicious, key=lambda x: x.credibility_score)[:10]:
                    f.write(f"- {a.name} (ÂèØ‰ø°Â∫¶: {a.credibility_score:.0f}/100)\n")

        print(f"üìÑ Êä•ÂëäÂ∑≤‰øùÂ≠ò: {output_path}")


# ==================== ‰∏ªÁ®ãÂ∫è ====================

def main():
    parser = argparse.ArgumentParser(
        description="Â∞èÁ∫¢‰π¶AIÊïôÊéàÁõëÊéßÁ≥ªÁªü - MediaCrawlerÈõÜÊàêÁâà",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--analyze-data', action='store_true',
                       help='ÂàÜÊûê MediaCrawler Áà¨ÂèñÁöÑÊï∞ÊçÆ')
    parser.add_argument('--data-dir', default='MediaCrawler/data/xhs',
                       help='MediaCrawler Êï∞ÊçÆÁõÆÂΩï')

    parser.add_argument('--add-user', metavar='USER_ID',
                       help='Ê∑ªÂä†ÁõëÊéßÁî®Êà∑')
    parser.add_argument('--name', metavar='NAME',
                       help='Áî®Êà∑ÂêçÁß∞')
    parser.add_argument('--bio', metavar='BIO',
                       help='Áî®Êà∑ÁÆÄ‰ªã')

    parser.add_argument('--report', action='store_true',
                       help='ÁîüÊàêÂàÜÊûêÊä•Âëä')

    parser.add_argument('--list', nargs='?', const='all',
                       choices=['all', 'professor', 'agency', 'suspicious'],
                       help='ÂàóÂá∫Â∑≤ÂàÜÊûêÁöÑË¥¶Âè∑')

    parser.add_argument('--output', default='professor_monitor_report.md',
                       help='Êä•ÂëäËæìÂá∫Êñá‰ª∂')

    args = parser.parse_args()

    analyzer = XHSAccountAnalyzer()
    db = MonitorDatabase()

    # ÂàÜÊûê MediaCrawler Êï∞ÊçÆ
    if args.analyze_data:
        print("\n" + "="*60)
        print("üîç ÂàÜÊûê MediaCrawler Êï∞ÊçÆ")
        print("="*60)

        result = analyzer.analyze_from_mc_data(args.data_dir)

        if not result['accounts']:
            print(f"\n‚ùì Êú™ÊâæÂà∞ÂèØÂàÜÊûêÁöÑÊï∞ÊçÆ")
            print(f"   ËØ∑Á°ÆËÆ§ MediaCrawler Â∑≤Ê≠£Á°ÆÁà¨ÂèñÊï∞ÊçÆÂà∞ {args.data_dir}")
            return

        print(f"\n‚úÖ ÊâæÂà∞ {result['total']} ‰∏™Ë¥¶Âè∑")

        for analysis in result['accounts']:
            db.save_account(analysis)
            status = "‚úÖÊïôÊéà" if analysis.is_professor else ("‚ö†Ô∏è‰∏≠‰ªã" if analysis.is_agency else "‚ùìÊú™Áü•")
            print(f"   [{status}] {analysis.name}: {analysis.credibility_score:.0f}/100")

        # ÁîüÊàêÊä•Âëä
        ReportGenerator.generate_report(result['accounts'], args.output)

        return

    # ÁîüÊàêÊä•Âëä
    if args.report:
        accounts = db.get_accounts()
        analyses = []
        for acc in accounts:
            analysis = AccountAnalysis(
                user_id=acc['user_id'],
                name=acc['name'],
                description=acc['description'],
                credibility_score=acc['credibility_score'],
                agency_score=acc['agency_score'],
                professor_score=acc['professor_score'],
                is_professor=bool(acc['is_professor']),
                is_agency=bool(acc['is_agency']),
                confidence=acc['confidence'],
                posts_count=acc['posts_count']
            )
            if acc['reasons']:
                analysis.reasons = json.loads(acc['reasons'])
            if acc['suspicious_signals']:
                analysis.suspicious_signals = json.loads(acc['suspicious_signals'])
            analyses.append(analysis)

        ReportGenerator.generate_report(analyses, args.output)
        return

    # ÂàóÂá∫Ë¥¶Âè∑
    if args.list:
        filter_type = 'professor' if args.list == 'professor' else args.list
        accounts = db.get_accounts(filter_type)

        print(f"\nüìã Ë¥¶Âè∑ÂàóË°® ({len(accounts)} ‰∏™)\n")

        for acc in accounts:
            status = "‚úÖ" if acc['is_professor'] else ("‚ö†Ô∏è" if acc['is_agency'] else "‚ùì")
            print(f"  {status} {acc['name']}: {acc['credibility_score']:.0f}/100 "
                  f"(ÊïôÊéà:{acc['professor_score']:.0f}, ‰∏≠‰ªã:{acc['agency_score']:.0f})")

        return

    # ÊâãÂä®Ê∑ªÂä†Áî®Êà∑
    if args.add_user:
        analysis = analyzer.analyze_account(
            user_id=args.add_user,
            name=args.name or "Êú™Áü•Áî®Êà∑",
            description=args.bio or ""
        )
        db.save_account(analysis)

        print(f"\nüìä ÂàÜÊûêÁªìÊûú:")
        print(f"   ÂêçÁß∞: {analysis.name}")
        print(f"   ÂèØ‰ø°Â∫¶: {analysis.credibility_score:.0f}/100")
        print(f"   Âà§ÂÆö: {'‚úÖÊïôÊéà' if analysis.is_professor else ('‚ö†Ô∏è‰∏≠‰ªã' if analysis.is_agency else '‚ùìÊú™Áü•')}")
        if analysis.reasons:
            print(f"   ‰æùÊçÆ: {', '.join(analysis.reasons[:3])}")
        return

    # ÊòæÁ§∫Â∏ÆÂä©
    parser.print_help()


if __name__ == "__main__":
    main()
