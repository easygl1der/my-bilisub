#!/usr/bin/env python3
"""
å°çº¢ä¹¦AIæ•™æˆç›‘æ§ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. ç›‘æ§æŒ‡å®šå…³é”®è¯ï¼ˆAIã€æ•™æˆã€æ‹›ç”Ÿç­‰ï¼‰
2. ç”„åˆ«ä¸­ä»‹å‡ä¿¡æ¯
3. è´¦å·å¯ä¿¡åº¦åˆ†æï¼ˆç­›é€‰çœŸæ­£æ•™æˆè´¦å·ï¼‰
4. å®æ—¶é€šçŸ¥

ä¸­ä»‹ç‰¹å¾æ£€æµ‹ï¼š
- æ–‡æ¡ˆé—®é¢˜ï¼šå¤§é‡ä½¿ç”¨"dd"ã€"ç§ä¿¡"ã€"è€å¸ˆ"ç­‰ä¸­ä»‹å¸¸ç”¨è¯
- è´¦å·è¡Œä¸ºï¼šå‘å¸ƒå¤šç§ä¸åŒè€å¸ˆçš„æ‹›ç”Ÿä¿¡æ¯
- ç¼ºä¹ä¸ªäººèº«ä»½ä¿¡æ¯

ä½¿ç”¨æ–¹æ³•:
    python xhs_professor_monitor.py --keywords "AIæ•™æˆ,MLæ‹›ç”Ÿ" --check
    python xhs_professor_monitor.py --analyze-user "ç”¨æˆ·ä¸»é¡µé“¾æ¥"
    python xhs_professor_monitor.py --monitor
"""

import os
import sys
import json
import time
import asyncio
import argparse
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field
from collections import Counter

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ==================== é…ç½® ====================

# ä¸­ä»‹å¸¸ç”¨å…³é”®è¯ï¼ˆç”¨äºæ£€æµ‹ï¼‰
AGENCY_KEYWORDS = {
    'contact': ['dd', 'æ»´æ»´', 'æ»´æ»´æˆ‘', 'ç§ä¿¡', 'ç§èŠ', 'åŠ v', 'åŠ å¾®', 'è”ç³»',
                'vx', 'VX', 'vä¿¡', 'WeChat', 'wx', 'å¾®ä¿¡', 'é¸½é¸½', 'å¤§å“¥'],
    'recruitment': ['æ‹›äºº', 'æ‹›ç”Ÿ', 'æ‹›æ”¶', 'åé¢', 'ä½ç½®', 'å‘ä½', 'æ¨è',
                    'å†…æ¨', 'ä¿å½•å–', 'ä¿offer', 'ä»£ç”³è¯·', 'ä¸­ä»‹', 'æœºæ„'],
    'professor_ref': ['è€å¸ˆ', 'å¤§ç‰›', 'å¤§ä½¬', 'å¯¼å¸ˆ', 'PI', 'æ–¹å‘å¾ˆå¥½',
                      'äººå¾ˆnice', 'æ„¿æ„å¸®å­¦ç”Ÿ', 'fundingå……è¶³'],
    'urgency': ['åé¢æœ‰é™', 'æœ€å', 'æŠ“ç´§', 'å³å°†æˆªæ­¢', 'é©¬ä¸Š', 'ç«‹åˆ»',
                'é”™è¿‡ç­‰ä¸€å¹´', 'æ‰‹æ…¢æ— '],
}

# çœŸå®æ•™æˆçš„æ­£é¢ä¿¡å·
PROFESSOR_INDICATORS = {
    'identity': ['æ•™æˆ', 'å‰¯æ•™æˆ', 'åŠ©ç†æ•™æˆ', 'PI', 'å®éªŒå®¤', 'Lab',
                 'University', 'å¤§å­¦', 'å­¦é™¢', 'ç ”ç©¶æ‰€'],
    'research': ['è®ºæ–‡', 'paper', 'ç ”ç©¶', 'research', 'é¡¹ç›®', 'project',
                 'æŠ•ç¨¿', 'å‘è¡¨', 'é¡¶ä¼š', 'æœŸåˆŠ', 'CVPR', 'ICCV', 'NeurIPS',
                 'ICML', 'AAAI', 'IJCAI', 'ACL', 'EMNLP'],
    'student': ['æ‹›ç”Ÿ', 'æ‹›åš', 'æ‹›ç¡•', 'ç ”ç©¶ç”Ÿ', 'åšå£«ç”Ÿ', 'ç¡•å£«ç”Ÿ',
                'RA', 'ç ”ç©¶åŠ©ç†', 'å®ä¹ ç”Ÿ'],
}

# å¯ç–‘çš„è´¦å·ç‰¹å¾
SUSPICIOUS_PATTERNS = {
    'random_numbers': re.compile(r'.*\d{4,}$'),  # ä»¥4ä½ä»¥ä¸Šæ•°å­—ç»“å°¾
    'weixin_in_name': re.compile(r'(wx|v|å¾®ä¿¡|vx)', re.I),  # åå­—å«å¾®ä¿¡
    'agency_in_name': re.compile(r'(ç•™å­¦|ç”³è¯·|ä¸­ä»‹|æœºæ„|ä¿å½•å–)', re.I),  # åå­—å«ä¸­ä»‹è¯
}

# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class AccountProfile:
    """è´¦å·ç”»åƒ"""
    user_id: str
    name: str
    description: str = ""
    posts_count: int = 0
    followers_count: int = 0
    posts: List[Dict] = field(default_factory=list)

    # åˆ†æç»“æœ
    credibility_score: float = 0.0  # 0-100
    is_professor: bool = False
    is_agency: bool = False
    confidence: str = "low"  # low, medium, high

    # ç‰¹å¾æ ‡è®°
    has_personal_identity: bool = False
    has_research_content: bool = False
    has_multiple_professors: bool = False
    has_contact_info: bool = False
    agency_word_count: int = 0
    professor_word_count: int = 0


@dataclass
class PostAnalysis:
    """å¸–å­åˆ†æç»“æœ"""
    post_id: str
    title: str
    content: str
    author: str

    # åˆ†ç±»
    is_recruitment: bool = False
    is_professor_post: bool = False
    is_agency_post: bool = False
    confidence: float = 0.0

    # å…³é”®æå–
    professor_name: str = ""
    university: str = ""
    research_area: str = ""
    contact_method: str = ""

    # å¯ç–‘æ ‡è®°
    suspicious_signals: List[str] = field(default_factory=list)


# ==================== å¯ä¿¡åº¦åˆ†æå™¨ ====================

class CredibilityAnalyzer:
    """è´¦å·å¯ä¿¡åº¦åˆ†æå™¨"""

    def __init__(self):
        self.agency_keywords = AGENCY_KEYWORDS
        self.professor_indicators = PROFESSOR_INDICATORS
        self.suspicious_patterns = SUSPICIOUS_PATTERNS

    def analyze_account(self, profile: AccountProfile) -> AccountProfile:
        """åˆ†æè´¦å·å¯ä¿¡åº¦"""
        # 1. æ£€æŸ¥è´¦å·å
        name_score = self._analyze_name(profile.name)

        # 2. æ£€æŸ¥ç®€ä»‹
        bio_score, bio_signals = self._analyze_bio(profile.description)

        # 3. æ£€æŸ¥å‘å¸–æ¨¡å¼
        post_score, post_signals = self._analyze_posts(profile.posts)

        # 4. è®¡ç®—ç»¼åˆå¾—åˆ†
        base_score = 50
        profile.credibility_score = min(100, max(0, base_score + name_score + bio_score + post_score))

        # 5. åˆ¤æ–­è´¦å·ç±»å‹
        profile.has_personal_identity = bio_signals.get('has_identity', False)
        profile.has_research_content = post_signals.get('has_research', False)
        profile.has_multiple_professors = post_signals.get('multiple_professors', False)
        profile.has_contact_info = bio_signals.get('has_contact', False)
        profile.agency_word_count = post_signals.get('agency_words', 0)
        profile.professor_word_count = post_signals.get('professor_words', 0)

        # åˆ¤æ–­æ˜¯å¦æ˜¯æ•™æˆ
        if (profile.has_personal_identity and
            profile.has_research_content and
            not profile.has_multiple_professors and
            profile.credibility_score >= 70):
            profile.is_professor = True
            profile.confidence = "high" if profile.credibility_score >= 85 else "medium"

        # åˆ¤æ–­æ˜¯å¦æ˜¯ä¸­ä»‹
        if (profile.has_multiple_professors or
            profile.agency_word_count >= 3 or
            profile.has_contact_info and not profile.has_personal_identity):
            profile.is_agency = True
            profile.credibility_score = max(0, profile.credibility_score - 40)

        return profile

    def _analyze_name(self, name: str) -> int:
        """åˆ†æè´¦å·åï¼Œè¿”å›å¾—åˆ†è°ƒæ•´"""
        score = 0

        # å¯ç–‘æ¨¡å¼
        if self.suspicious_patterns['random_numbers'].match(name):
            score -= 20
        if self.suspicious_patterns['weixin_in_name'].search(name):
            score -= 30
        if self.suspicious_patterns['agency_in_name'].search(name):
            score -= 40

        # æ­£é¢ä¿¡å·ï¼šçœ‹èµ·æ¥åƒçœŸå®å§“å
        if len(name) >= 2 and len(name) <= 6 and name.isalpha():
            score += 10

        # åŒ…å«æ•™æˆå¤´è¡”
        if any(ind in name for ind in ['æ•™æˆ', 'Prof', 'Dr.', 'åšå£«']):
            score += 15

        return score

    def _analyze_bio(self, bio: str) -> Tuple[int, Dict]:
        """åˆ†æç®€ä»‹ï¼Œè¿”å›å¾—åˆ†è°ƒæ•´å’Œä¿¡å·"""
        score = 0
        signals = {
            'has_identity': False,
            'has_contact': False,
            'agency_words': 0,
        }

        if not bio:
            return score, signals

        bio_lower = bio.lower()

        # æ£€æŸ¥èº«ä»½ä¿¡æ¯
        for ind in self.professor_indicators['identity']:
            if ind in bio:
                signals['has_identity'] = True
                score += 20
                break

        # æ£€æŸ¥è”ç³»æ–¹å¼
        for contact in self.agency_keywords['contact']:
            if contact in bio_lower:
                signals['has_contact'] = True
                signals['agency_words'] += 1
                score -= 15

        # ä¸­ä»‹è¯
        for agency in self.agency_keywords['recruitment']:
            if agency in bio:
                signals['agency_words'] += 1
                score -= 10

        return score, signals

    def _analyze_posts(self, posts: List[Dict]) -> Tuple[int, Dict]:
        """åˆ†æå‘å¸–æ¨¡å¼"""
        score = 0
        signals = {
            'has_research': False,
            'multiple_professors': False,
            'agency_words': 0,
            'professor_words': 0,
        }

        if not posts:
            return score, signals

        # ç»Ÿè®¡å¸–å­ä¸­æåˆ°çš„ä¸åŒ"è€å¸ˆ"
        mentioned_professors = set()

        for post in posts:
            content = post.get('title', '') + ' ' + post.get('desc', '')
            content_lower = content.lower()

            # æ£€æµ‹ç ”ç©¶å†…å®¹
            for research in self.professor_indicators['research']:
                if research.lower() in content_lower:
                    signals['has_research'] = True
                    signals['professor_words'] += 1
                    score += 5
                    break

            # æ£€æµ‹ä¸­ä»‹è¯
            for agency in self.agency_keywords['recruitment']:
                if agency in content:
                    signals['agency_words'] += 1
                    score -= 3

            # æ£€æµ‹è”ç³»æ–¹å¼
            for contact in self.agency_keywords['contact']:
                if contact in content_lower:
                    signals['agency_words'] += 1
                    score -= 5

            # æå–è€å¸ˆåå­—ï¼ˆç®€å•æ¨¡å¼ï¼šXXXè€å¸ˆã€XXXæ•™æˆç­‰ï¼‰
            professor_matches = re.findall(r'([\u4e00-\u9fa5]{2,4})(?:è€å¸ˆ|æ•™æˆ|å¯¼å¸ˆ)', content)
            mentioned_professors.update(professor_matches)

        # å¦‚æœæåˆ°äº†å¤šä¸ªä¸åŒçš„è€å¸ˆï¼Œå¾ˆå¯èƒ½æ˜¯ä¸­ä»‹
        if len(mentioned_professors) >= 3:
            signals['multiple_professors'] = True
            score -= 30

        return score, signals

    def analyze_post(self, post: Dict) -> PostAnalysis:
        """åˆ†æå•æ¡å¸–å­"""
        title = post.get('title', '')
        content = post.get('desc', '') or post.get('content', '')
        full_text = title + ' ' + content
        author = post.get('author', '')

        analysis = PostAnalysis(
            post_id=post.get('id', ''),
            title=title,
            content=content,
            author=author
        )

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹›ç”Ÿè´´
        for word in self.professor_indicators['student'] + ['æ‹›ç”Ÿ', 'æ‹›æ”¶']:
            if word in full_text:
                analysis.is_recruitment = True
                break

        # æ£€æŸ¥ä¸­ä»‹ç‰¹å¾
        agency_signals = 0
        for category, keywords in self.agency_keywords.items():
            for kw in keywords:
                if kw in full_text.lower():
                    agency_signals += 1
                    analysis.suspicious_signals.append(f"{category}: {kw}")

        # æ£€æŸ¥æ•™æˆç‰¹å¾
        professor_signals = 0
        for category, keywords in self.professor_indicators.items():
            for kw in keywords:
                if kw.lower() in full_text.lower():
                    professor_signals += 1

        # åˆ¤æ–­ç½®ä¿¡åº¦
        if agency_signals >= 3:
            analysis.is_agency_post = True
            analysis.confidence = agency_signals * 0.15
        elif professor_signals >= 2 and agency_signals <= 1:
            analysis.is_professor_post = True
            analysis.confidence = professor_signals * 0.2

        # æå–ä¿¡æ¯
        analysis.professor_name = self._extract_professor_name(full_text)
        analysis.university = self._extract_university(full_text)
        analysis.research_area = self._extract_research_area(full_text)
        analysis.contact_method = self._extract_contact(full_text)

        return analysis

    def _extract_professor_name(self, text: str) -> str:
        """æå–æ•™æˆåå­—"""
        # å°è¯•åŒ¹é… "XXæ•™æˆ"ã€"XXè€å¸ˆ" ç­‰
        patterns = [
            r'([\u4e00-\u9fa5]{2,4})æ•™æˆ',
            r'([\u4e00-\u9fa5]{2,4})è€å¸ˆ',
            r'([\u4e00-\u9fa5]{2,4})å¯¼å¸ˆ',
            r'PI\s*:\s*([A-Z][a-z]+)',
        ]
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)
        return ""

    def _extract_university(self, text: str) -> str:
        """æå–å¤§å­¦ä¿¡æ¯"""
        # å¸¸è§å¤§å­¦æ¨¡å¼
        patterns = [
            r'([\u4e00-\u9fa5]{2,6}å¤§å­¦)',
            r'([\u4e00-\u9fa5]{2,6}å­¦é™¢)',
            r'([A-Z][a-z]+\s*[Uu]niversity)',
        ]
        for pattern in patterns:
            matches = re.findall(pattern, text)
            if matches:
                return matches[0]
        return ""

    def _extract_research_area(self, text: str) -> str:
        """æå–ç ”ç©¶æ–¹å‘"""
        areas = []
        research_keywords = [
            'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'è®¡ç®—æœºè§†è§‰', 'è‡ªç„¶è¯­è¨€å¤„ç†', 'NLP',
            'å¼ºåŒ–å­¦ä¹ ', 'æ¨èç³»ç»Ÿ', 'æ•°æ®æŒ–æ˜', 'çŸ¥è¯†å›¾è°±', 'å¤§æ¨¡å‹', 'LLM',
            'Machine Learning', 'Deep Learning', 'CV', 'NLP', 'AI'
        ]
        for kw in research_keywords:
            if kw.lower() in text.lower() and kw not in areas:
                areas.append(kw)
        return ', '.join(areas[:3])

    def _extract_contact(self, text: str) -> str:
        """æå–è”ç³»æ–¹å¼"""
        contacts = []
        for kw in self.agency_keywords['contact']:
            if kw in text.lower():
                contacts.append(kw)
        return ', '.join(contacts[:3])


# ==================== MediaCrawler é›†æˆ ====================

class XHSCrawler:
    """å°çº¢ä¹¦çˆ¬è™«å°è£…ï¼ˆåŸºäºMediaCrawlerï¼‰"""

    def __init__(self):
        # ä» platforms/xiaohongshu/ å›åˆ°çˆ¶ç›®å½•çš„ MediaCrawler
        self.mc_path = Path(__file__).parent.parent.parent / "MediaCrawler"
        self.cookies_path = self.mc_path / "xhs_cookies.json"

    def load_cookies(self) -> Optional[str]:
        """åŠ è½½cookies"""
        if not self.cookies_path.exists():
            return None

        try:
            with open(self.cookies_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            cookies = data.get('cookies', [])
            if cookies:
                return '; '.join([f"{c['name']}={c['value']}" for c in cookies])
        except Exception as e:
            print(f"  âš ï¸ CookieåŠ è½½å¤±è´¥: {e}")
        return None

    def search_posts(self, keyword: str, count: int = 20) -> List[Dict]:
        """æœç´¢å¸–å­ï¼ˆéœ€è¦é…ç½®MediaCrawlerï¼‰"""
        print(f"\nğŸ“¡ æœç´¢å…³é”®è¯: {keyword}")
        print(f"   æç¤º: éœ€è¦å…ˆåœ¨ MediaCrawler/config/base_config.py ä¸­é…ç½®æœç´¢å‚æ•°")
        print(f"   ç„¶åè¿è¡Œ: cd MediaCrawler && python main.py")
        print(f"   ç»“æœå°†ä¿å­˜åœ¨ MediaCrawler/output/xhs/search/")

        # è¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
        return self._get_mock_posts()

    def get_user_posts(self, user_id: str, count: int = 30) -> List[Dict]:
        """è·å–ç”¨æˆ·å¸–å­"""
        print(f"\nğŸ“¡ è·å–ç”¨æˆ·å¸–å­: {user_id}")
        print(f"   æç¤º: éœ€è¦é…ç½® MediaCrawler çš„ XHS_CREATOR_ID_LIST")
        return []

    def _get_mock_posts(self) -> List[Dict]:
        """è·å–æ¨¡æ‹Ÿå¸–å­æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        return [
            {
                'id': '001',
                'title': 'ã€æ‹›ç”Ÿã€‘2025å¹´AI/MLæ–¹å‘åšå£«æ‹›ç”Ÿ',
                'desc': 'XXå¤§å­¦XXæ•™æˆè¯¾é¢˜ç»„æ‹›æ”¶2025å¹´å…¥å­¦çš„åšå£«ç ”ç©¶ç”Ÿã€‚ç ”ç©¶æ–¹å‘ï¼šè®¡ç®—æœºè§†è§‰ã€æ·±åº¦å­¦ä¹ ã€‚æœ‰æ„è€…è¯·ddæˆ‘äº†è§£è¯¦æƒ…ã€‚',
                'author': 'ç•™å­¦å°åŠ©æ‰‹',
                'likes': 128,
                'comments': 45,
            },
            {
                'id': '002',
                'title': 'CVPR 2024 è®ºæ–‡åˆ†äº«ï¼šæˆ‘ä»¬çš„å·¥ä½œè¢«æ¥æ”¶äº†ï¼',
                'desc': 'å¾ˆé«˜å…´æˆ‘ä»¬çš„è®ºæ–‡"Deep Learning for Vision"è¢«CVPR 2024æ¥æ”¶ï¼æ„Ÿè°¢å›¢é˜Ÿæˆå‘˜çš„åŠªåŠ›ã€‚é™„ä¸Šè®ºæ–‡é“¾æ¥å’Œä»£ç ä»“åº“ã€‚',
                'author': 'å¼ æ•™æˆ',
                'likes': 523,
                'comments': 89,
            },
            {
                'id': '003',
                'title': 'ã€æ¨èã€‘å“ˆä½›å¤§å­¦XXæ•™æˆæ‹›äººå•¦ï¼fundingå……è¶³ï¼',
                'desc': 'å“ˆä½›å¤§å­¦XXæ•™æˆæ‹›æ”¶MLæ–¹å‘å…¨å¥–åšå£«ã€‚æ•™æˆäººå¾ˆniceï¼Œfundingå……è¶³ï¼Œåé¢æœ‰é™ï¼Œæ„Ÿå…´è¶£çš„ddæˆ‘å†…æ¨ï¼',
                'author': 'åŒ—ç¾ç”³è¯·é…±',
                'likes': 234,
                'comments': 67,
            },
        ]


# ==================== æ•°æ®åº“å­˜å‚¨ ====================

class MonitorDatabase:
    """ç›‘æ§æ•°æ®åº“"""

    def __init__(self, db_path: str = "data/professor_monitor.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        import sqlite3
        self.conn = sqlite3.connect(str(self.db_path), check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self._init_tables()

    def _init_tables(self):
        """åˆå§‹åŒ–è¡¨"""
        import sqlite3
        cursor = self.conn.cursor()

        # è´¦å·è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS accounts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT UNIQUE,
                name TEXT,
                description TEXT,
                credibility_score REAL DEFAULT 0,
                is_professor INTEGER DEFAULT 0,
                is_agency INTEGER DEFAULT 0,
                confidence TEXT,
                last_checked TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # å¸–å­è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id TEXT UNIQUE,
                user_id TEXT,
                title TEXT,
                content TEXT,
                is_recruitment INTEGER DEFAULT 0,
                is_professor_post INTEGER DEFAULT 0,
                is_agency_post INTEGER DEFAULT 0,
                confidence REAL DEFAULT 0,
                professor_name TEXT,
                university TEXT,
                research_area TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES accounts(user_id)
            )
        """)

        # ç›‘æ§å…³é”®è¯è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS keywords (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT UNIQUE,
                enabled INTEGER DEFAULT 1,
                last_checked TIMESTAMP,
                hit_count INTEGER DEFAULT 0
            )
        """)

        # é€šçŸ¥è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS notifications (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id TEXT,
                notification_type TEXT,
                message TEXT,
                sent INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (post_id) REFERENCES posts(post_id)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_posts_user ON posts(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_posts_recruitment ON posts(is_recruitment)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_accounts_professor ON accounts(is_professor)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_accounts_agency ON accounts(is_agency)")

        self.conn.commit()

    def save_account(self, profile: AccountProfile) -> int:
        """ä¿å­˜è´¦å·åˆ†æç»“æœ"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO accounts
            (user_id, name, description, credibility_score, is_professor, is_agency,
             confidence, last_checked)
            VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (profile.user_id, profile.name, profile.description,
              profile.credibility_score, int(profile.is_professor),
              int(profile.is_agency), profile.confidence))
        self.conn.commit()
        return cursor.lastrowid

    def save_post(self, analysis: PostAnalysis, user_id: str) -> int:
        """ä¿å­˜å¸–å­åˆ†æç»“æœ"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO posts
            (post_id, user_id, title, content, is_recruitment, is_professor_post,
             is_agency_post, confidence, professor_name, university, research_area)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (analysis.post_id, user_id, analysis.title, analysis.content,
              int(analysis.is_recruitment), int(analysis.is_professor_post),
              int(analysis.is_agency_post), analysis.confidence,
              analysis.professor_name, analysis.university, analysis.research_area))
        self.conn.commit()
        return cursor.lastrowid

    def get_professor_posts(self, hours: int = 24) -> List[Dict]:
        """è·å–æœ€è¿‘çš„æ•™æˆå‘å¸–"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT p.*, a.name as author_name, a.credibility_score
            FROM posts p
            JOIN accounts a ON p.user_id = a.user_id
            WHERE a.is_professor = 1
            AND datetime(p.created_at) >= datetime('now', '-' || ? || ' hours')
            ORDER BY p.created_at DESC
        """, (hours,))
        return [dict(row) for row in cursor.fetchall()]

    def get_agency_accounts(self) -> List[Dict]:
        """è·å–å·²è¯†åˆ«çš„ä¸­ä»‹è´¦å·"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM accounts
            WHERE is_agency = 1
            ORDER BY credibility_score ASC
        """)
        return [dict(row) for row in cursor.fetchall()]

    def close(self):
        """å…³é—­æ•°æ®åº“"""
        if self.conn:
            self.conn.close()


# ==================== ç›‘æ§å™¨ ====================

class ProfessorMonitor:
    """æ•™æˆå¸–å­ç›‘æ§å™¨"""

    def __init__(self, enable_notification: bool = True):
        self.analyzer = CredibilityAnalyzer()
        self.crawler = XHSCrawler()
        self.db = MonitorDatabase()
        self.notifier = None

        # åˆå§‹åŒ–é€šçŸ¥å™¨
        if enable_notification:
            try:
                from telegram_notifier import TelegramNotifier
                self.notifier = TelegramNotifier()
                print("âœ… Telegram é€šçŸ¥å·²å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸ é€šçŸ¥åˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"   ç›‘æ§å°†ç»§ç»­è¿è¡Œï¼Œä½†ä¸ä¼šå‘é€é€šçŸ¥")

    def check_user(self, user_id: str, user_name: str = "",
                   description: str = "", posts: List[Dict] = None) -> AccountProfile:
        """æ£€æŸ¥å•ä¸ªç”¨æˆ·"""
        print(f"\n{'='*60}")
        print(f"ğŸ” åˆ†æè´¦å·: @{user_name}")
        print(f"{'='*60}")

        # åˆ›å»ºè´¦å·ç”»åƒ
        profile = AccountProfile(
            user_id=user_id,
            name=user_name,
            description=description,
            posts=posts or []
        )

        # åˆ†æå¯ä¿¡åº¦
        profile = self.analyzer.analyze_account(profile)

        # æ‰“å°ç»“æœ
        self._print_profile_result(profile)

        # ä¿å­˜åˆ°æ•°æ®åº“
        self.db.save_account(profile)

        return profile

    def analyze_post(self, post: Dict, user_id: str = "unknown") -> PostAnalysis:
        """åˆ†æå•æ¡å¸–å­"""
        analysis = self.analyzer.analyze_post(post)
        self.db.save_post(analysis, user_id)
        return analysis

    def scan_and_alert(self, posts: List[Dict], auto_notify: bool = True) -> List[PostAnalysis]:
        """æ‰«æå¸–å­å¹¶ç­›é€‰çœŸå®æ•™æˆå‘å¸–"""
        print(f"\nğŸ“Š æ‰«æ {len(posts)} æ¡å¸–å­...")

        professor_posts = []
        agency_posts = []
        notified_count = 0

        for post in posts:
            analysis = self.analyzer.analyze_post(post)

            if analysis.is_professor_post and not analysis.is_agency_post:
                professor_posts.append(analysis)
            elif analysis.is_agency_post:
                agency_posts.append(analysis)

        print(f"\nâœ… å‘ç° {len(professor_posts)} æ¡ç–‘ä¼¼çœŸå®æ•™æˆå‘å¸–")
        print(f"âš ï¸ å‘ç° {len(agency_posts)} æ¡ç–‘ä¼¼ä¸­ä»‹å‘å¸–")

        # å‘é€é€šçŸ¥
        if auto_notify and self.notifier:
            notified_count = self._send_professor_post_notifications(professor_posts)

        print(f"ğŸ“¤ å·²å‘é€ {notified_count} æ¡é€šçŸ¥åˆ° Telegram")

        return professor_posts

    def _send_professor_post_notifications(self, analyses: List[PostAnalysis]) -> int:
        """å‘é€æ•™æˆå¸–å­é€šçŸ¥"""
        count = 0

        for analysis in analyses:
            # åªå¯¹é«˜å¯ä¿¡åº¦çš„å¸–å­å‘é€é€šçŸ¥
            if analysis.confidence >= 0.6:
                # æ„é€ å¸–å­é“¾æ¥
                post_url = f"https://www.xiaohongshu.com/explore/{analysis.post_id}"

                success = self.notifier.send_professor_post(
                    professor_name=analysis.author,
                    university=analysis.university or "æœªçŸ¥",
                    research_area=analysis.research_area or "AI/ML",
                    post_title=analysis.title,
                    post_url=post_url,
                    credibility_score=analysis.confidence * 100
                )

                if success:
                    count += 1

        return count

    def _print_profile_result(self, profile: AccountProfile):
        """æ‰“å°è´¦å·åˆ†æç»“æœ"""
        print(f"\nğŸ“‹ è´¦å·åˆ†æç»“æœ:")
        print(f"   åç§°: {profile.name}")
        print(f"   å¯ä¿¡åº¦è¯„åˆ†: {profile.credibility_score:.1f}/100")

        status = []
        if profile.is_professor:
            status.append("âœ… ç–‘ä¼¼çœŸå®æ•™æˆ")
        if profile.is_agency:
            status.append("âš ï¸ ç–‘ä¼¼ä¸­ä»‹è´¦å·")

        if status:
            print(f"   åˆ¤å®š: {' | '.join(status)} (ç½®ä¿¡åº¦: {profile.confidence})")
        else:
            print(f"   åˆ¤å®š: â“ æ— æ³•ç¡®å®š")

        print(f"\nğŸ“Š ç‰¹å¾åˆ†æ:")
        print(f"   æœ‰ä¸ªäººèº«ä»½ä¿¡æ¯: {'âœ…' if profile.has_personal_identity else 'âŒ'}")
        print(f"   æœ‰ç ”ç©¶å†…å®¹: {'âœ…' if profile.has_research_content else 'âŒ'}")
        print(f"   æåŠå¤šä½æ•™æˆ: {'âš ï¸' if profile.has_multiple_professors else 'âœ…'}")
        print(f"   æœ‰è”ç³»æ–¹å¼: {'âš ï¸' if profile.has_contact_info else 'âœ…'}")
        print(f"   ä¸­ä»‹è¯æ•°é‡: {profile.agency_word_count}")
        print(f"   æ•™æˆç›¸å…³è¯: {profile.professor_word_count}")


# ==================== å‘½ä»¤è¡Œå·¥å…· ====================

def main():
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦AIæ•™æˆç›‘æ§ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. åˆ†æå•ä¸ªè´¦å·:
   python xhs_professor_monitor.py --analyze-user USER_ID --name "ç”¨æˆ·å"

2. æ‰¹é‡åˆ†æå¸–å­:
   python xhs_professor_monitor.py --analyze-file posts.json

3. ç›‘æ§æ¨¡å¼:
   python xhs_professor_monitor.py --monitor --interval 300

4. æŸ¥çœ‹å·²è¯†åˆ«çš„ä¸­ä»‹:
   python xhs_professor_monitor.py --list-agency
        """
    )

    parser.add_argument('--analyze-user', metavar='USER_ID',
                       help='åˆ†ææŒ‡å®šç”¨æˆ·')
    parser.add_argument('--name', metavar='NAME',
                       help='ç”¨æˆ·å')
    parser.add_argument('--bio', metavar='BIO',
                       help='ç”¨æˆ·ç®€ä»‹')

    parser.add_argument('--analyze-file', metavar='FILE',
                       help='åˆ†ææ–‡ä»¶ä¸­çš„å¸–å­æ•°æ® (JSON)')

    parser.add_argument('--keywords', metavar='KEYWORDS',
                       help='ç›‘æ§å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰')

    parser.add_argument('--monitor', action='store_true',
                       help='å¯åŠ¨æŒç»­ç›‘æ§æ¨¡å¼')
    parser.add_argument('--interval', type=int, default=300,
                       help='ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300')

    parser.add_argument('--list-agency', action='store_true',
                       help='åˆ—å‡ºå·²è¯†åˆ«çš„ä¸­ä»‹è´¦å·')

    parser.add_argument('--list-professors', action='store_true',
                       help='åˆ—å‡ºå·²è¯†åˆ«çš„æ•™æˆè´¦å·')

    parser.add_argument('--test', action='store_true',
                       help='è¿è¡Œæµ‹è¯•æ¨¡å¼ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰')

    args = parser.parse_args()

    monitor = ProfessorMonitor()

    # åˆ—å‡ºä¸­ä»‹
    if args.list_agency:
        agencies = monitor.db.get_agency_accounts()
        print(f"\nâš ï¸ å·²è¯†åˆ«çš„ä¸­ä»‹è´¦å· ({len(agencies)} ä¸ª):\n")
        for a in agencies:
            print(f"  - {a['name']} (è¯„åˆ†: {a['credibility_score']:.0f})")
        return

    # åˆ—å‡ºæ•™æˆ
    if args.list_professors:
        cursor = monitor.db.conn.cursor()
        cursor.execute("SELECT * FROM accounts WHERE is_professor = 1")
        professors = [dict(row) for row in cursor.fetchall()]
        print(f"\nâœ… å·²è¯†åˆ«çš„æ•™æˆè´¦å· ({len(professors)} ä¸ª):\n")
        for p in professors:
            print(f"  - {p['name']} (è¯„åˆ†: {p['credibility_score']:.0f}, ç½®ä¿¡åº¦: {p['confidence']})")
        return

    # åˆ†æç”¨æˆ·
    if args.analyze_user:
        monitor.check_user(
            user_id=args.analyze_user,
            user_name=args.name or "æœªçŸ¥ç”¨æˆ·",
            description=args.bio or ""
        )
        return

    # æµ‹è¯•æ¨¡å¼
    if args.test:
        print("\n" + "="*60)
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ - ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        print("="*60)

        # æ¨¡æ‹Ÿæ•°æ®
        test_cases = [
            {
                'name': 'å¼ æ•™æˆAI',
                'description': 'XXå¤§å­¦è®¡ç®—æœºç³»æ•™æˆï¼Œç ”ç©¶æ–¹å‘ï¼šæ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰',
                'posts': [
                    {'title': 'CVPR 2024 è®ºæ–‡åˆ†äº«', 'desc': 'æˆ‘ä»¬çš„è®ºæ–‡è¢«æ¥æ”¶äº†ï¼'},
                    {'title': 'å®éªŒå®¤æ‹›ç”Ÿ', 'desc': '2025å¹´æ‹›æ”¶åšå£«ç ”ç©¶ç”Ÿ'},
                ]
            },
            {
                'name': 'ç•™å­¦ç”³è¯·ä¸­ä»‹8866',
                'description': 'ä¸“æ³¨è‹±ç¾ç”³è¯·ï¼Œddæˆ‘äº†è§£è¯¦æƒ…',
                'posts': [
                    {'title': 'å“ˆä½›å¤§å­¦AIæ•™æˆæ‹›äºº', 'desc': 'XXæ•™æˆäººå¾ˆniceï¼Œåé¢æœ‰é™ddæˆ‘'},
                    {'title': 'MIT MLæ–¹å‘å†…æ¨', 'desc': 'XXæ•™æˆfundingå……è¶³ï¼Œæœ‰éœ€è¦çš„è”ç³»'},
                    {'title': 'æ–¯å¦ç¦CVå®éªŒå®¤æ‹›ç”Ÿ', 'desc': 'XXå¯¼å¸ˆæ„¿æ„å¸®å­¦ç”Ÿï¼Œç§ä¿¡äº†è§£'},
                ]
            },
            {
                'name': 'å­¦æœ¯èµ„è®¯æ¬è¿å·¥',
                'description': 'åˆ†äº«æœ€æ–°å­¦æœ¯èµ„è®¯',
                'posts': [
                    {'title': 'ICML 2024 æœ€ä½³è®ºæ–‡è§£è¯»',
                        'desc': 'æœ¬å±ŠICMLçš„æœ€ä½³è®ºæ–‡æ˜¯...'},
                ]
            },
        ]

        for i, case in enumerate(test_cases, 1):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•ç”¨ä¾‹ {i}: {case['name']}")
            print(f"{'='*60}")

            profile = AccountProfile(
                user_id=f"test_{i}",
                name=case['name'],
                description=case['description'],
                posts=[{'title': p['title'], 'desc': p['desc']} for p in case['posts']]
            )

            profile = monitor.analyzer.analyze_account(profile)
            monitor._print_profile_result(profile)
            monitor.db.save_account(profile)

        print(f"\n{'='*60}")
        print("âœ… æµ‹è¯•å®Œæˆ")
        print(f"{'='*60}")

        # æ˜¾ç¤ºæ€»ç»“
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        cursor = monitor.db.conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM accounts WHERE is_professor = 1")
        prof_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM accounts WHERE is_agency = 1")
        agency_count = cursor.fetchone()[0]
        print(f"   è¯†åˆ«ä¸ºæ•™æˆ: {prof_count} ä¸ª")
        print(f"   è¯†åˆ«ä¸ºä¸­ä»‹: {agency_count} ä¸ª")

        return

    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ“ä½œï¼Œæ˜¾ç¤ºå¸®åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()
