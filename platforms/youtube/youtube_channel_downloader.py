#!/usr/bin/env python3
"""
YouTube é¢‘é“è§†é¢‘æ‰¹é‡ä¸‹è½½ä¸è½¬å½•å·¥å…·

æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. APIæ¨¡å¼ï¼šä½¿ç”¨ YouTube Data API è·å–è§†é¢‘åˆ—è¡¨ï¼ˆéœ€è¦ API Keyï¼‰
2. æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨ yt-dlp è·å–è§†é¢‘åˆ—è¡¨

åŠŸèƒ½ï¼š
1. ä» YouTube é¢‘é“/ç”¨æˆ·/æ’­æ”¾åˆ—è¡¨é“¾æ¥æå–æ‰€æœ‰è§†é¢‘
2. æ‰¹é‡ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°
3. ä½¿ç”¨ Gemini API è¿›è¡Œè§†é¢‘å†…å®¹åˆ†æè½¬å½•

ä½¿ç”¨ç¤ºä¾‹:
    # ä½¿ç”¨ API æ¨¡å¼ï¼ˆæ¨èï¼Œæ›´ç¨³å®šï¼‰
    python youtube_channel_downloader.py --channel "https://www.youtube.com/@username" --api-key YOUR_API_KEY

    # æ™®é€šæ¨¡å¼
    python youtube_channel_downloader.py --channel "https://www.youtube.com/@username"

    # ä¸‹è½½å¹¶è½¬å½•
    python youtube_channel_downloader.py --channel "https://www.youtube.com/@username" --transcribe

    # ä½¿ç”¨ä»£ç†
    set HTTPS_PROXY=http://127.0.0.1:7890
    python youtube_channel_downloader.py --channel "https://www.youtube.com/@username"
"""

import os
import sys
import csv
import re
import time
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

try:
    import yt_dlp
except ImportError:
    print("âŒ æœªå®‰è£… yt-dlp åº“")
    print("è¯·è¿è¡Œ: pip install yt-dlp")
    sys.exit(1)

try:
    import requests
except ImportError:
    print("âŒ æœªå®‰è£… requests åº“")
    print("è¯·è¿è¡Œ: pip install requests")
    sys.exit(1)

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


# ==================== é…ç½® ====================

YOUTUBE_API_URL = "https://www.googleapis.com/youtube/v3"

# å¯¼å…¥ API é…ç½®
try:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from config.config_api import API_CONFIG
    DEFAULT_API_KEY = API_CONFIG.get('youtube', {}).get('api_key', '')
except ImportError:
    DEFAULT_API_KEY = ''


# ==================== å·¥å…·å‡½æ•° ====================

def sanitize_filename(name: str, max_length: int = 200) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    illegal_chars = r'[<>:"/\\|?*]'
    name = re.sub(illegal_chars, '_', name)
    name = ''.join(char for char in name if ord(char) >= 32)
    name = name.strip('. ')
    if len(name) > max_length:
        name = name[:max_length].rsplit(' ', 1)[0]
    return name or "untitled"


def detect_channel_type(url: str) -> str:
    """æ£€æµ‹ YouTube é“¾æ¥ç±»å‹"""
    url_lower = url.lower()

    if 'youtube.com/playlist' in url_lower or 'list=' in url_lower:
        return 'playlist'
    elif '/channel/' in url_lower or '/c/' in url_lower or '/@' in url_lower:
        return 'channel'
    elif '/watch?v=' in url_lower or 'youtu.be/' in url_lower:
        return 'video'
    else:
        return 'unknown'


def extract_channel_id_from_url(url: str) -> str:
    """
    ä» YouTube URL ä¸­æå–é¢‘é“ ID

    æ”¯æŒçš„æ ¼å¼ï¼š
    - https://www.youtube.com/@username
    - https://www.youtube.com/c/username
    - https://www.youtube.com/channel/UCxxxxxx
    """
    # ç›´æ¥æ˜¯é¢‘é“ ID
    if '/channel/UC' in url:
        match = re.search(r'/channel/(UC[\w-]+)', url)
        if match:
            return match.group(1)

    return None


def get_channel_id_by_handle(api_key: str, handle: str) -> str:
    """
    é€šè¿‡ @username è·å–é¢‘é“ ID

    Args:
        api_key: YouTube Data API Key
        handle: @username (ä¸å«@ç¬¦å·)

    Returns:
        é¢‘é“ ID æˆ– None
    """
    params = {
        'key': api_key,
        'part': 'id',
        'forHandle': handle
    }

    try:
        response = requests.get(f"{YOUTUBE_API_URL}/channels", params=params, timeout=30)
        response.raise_for_status()
        data = response.json()

        if data.get('items'):
            return data['items'][0]['id']
    except Exception as e:
        print(f"   â””â”€ âš ï¸  API è·å–é¢‘é“ ID å¤±è´¥: {e}")

    return None


def get_channel_videos_by_api(api_key: str, channel_id: str, limit: int = None) -> List[Dict]:
    """
    ä½¿ç”¨ YouTube Data API è·å–é¢‘é“çš„æ‰€æœ‰è§†é¢‘

    Args:
        api_key: YouTube Data API Key
        channel_id: é¢‘é“ ID (UCxxxxxx)
        limit: é™åˆ¶æ•°é‡

    Returns:
        è§†é¢‘åˆ—è¡¨
    """
    videos = []
    next_page_token = None
    total_retrieved = 0

    print(f"   ğŸ“¡ ä½¿ç”¨ YouTube API è·å–è§†é¢‘åˆ—è¡¨...")

    while True:
        params = {
            'key': api_key,
            'part': 'snippet',
            'channelId': channel_id,
            'order': 'date',  # æŒ‰æ—¥æœŸæ’åº
            'type': 'video',
            'maxResults': min(50, limit - total_retrieved) if limit else 50,
        }

        if next_page_token:
            params['pageToken'] = next_page_token

        try:
            response = requests.get(f"{YOUTUBE_API_URL}/search", params=params, timeout=30)
            response.raise_for_status()
            data = response.json()

            # è·å–è§†é¢‘è¯¦æƒ…ï¼ˆåŒ…å«æ—¶é•¿ï¼‰
            video_ids = [item['id']['videoId'] for item in data.get('items', [])]
            if video_ids:
                videos_details = get_videos_details(api_key, video_ids)

                for item in data.get('items', []):
                    video_id = item['id']['videoId']
                    snippet = item['snippet']
                    details = videos_details.get(video_id, {})

                    videos.append({
                        'url': f"https://www.youtube.com/watch?v={video_id}",
                        'title': snippet['title'],
                        'id': video_id,
                        'duration': details.get('duration', 0),
                        'published_at': snippet.get('publishedAt', ''),
                        'description': snippet.get('description', '')[:200],
                    })

                total_retrieved = len(videos)
                percent = (total_retrieved / limit * 100) if limit else total_retrieved
                print(f"\r   ğŸ“¡ å·²è·å– {total_retrieved} ä¸ªè§†é¢‘{'...' if limit and total_retrieved < limit else ''}", end='', flush=True)

            # æ£€æŸ¥æ˜¯å¦ç»§ç»­
            if limit and total_retrieved >= limit:
                break

            next_page_token = data.get('nextPageToken')
            if not next_page_token:
                break

        except Exception as e:
            print(f"\r   âš ï¸  API è¯·æ±‚å¤±è´¥: {e}")
            break

    print()  # æ¢è¡Œ
    return videos[:limit] if limit else videos


def get_videos_details(api_key: str, video_ids: List[str]) -> Dict[str, Dict]:
    """
    æ‰¹é‡è·å–è§†é¢‘è¯¦æƒ…

    Args:
        api_key: YouTube Data API Key
        video_ids: è§†é¢‘ ID åˆ—è¡¨

    Returns:
        {video_id: {duration, ...}}
    """
    details = {}

    # YouTube API ä¸€æ¬¡æœ€å¤šæŸ¥è¯¢ 50 ä¸ªè§†é¢‘
    for i in range(0, len(video_ids), 50):
        batch = video_ids[i:i+50]

        params = {
            'key': api_key,
            'part': 'contentDetails',
            'id': ','.join(batch)
        }

        try:
            response = requests.get(f"{YOUTUBE_API_URL}/videos", params=params, timeout=30)
            response.raise_for_status()
            data = response.json()

            for item in data.get('items', []):
                video_id = item['id']
                # è§£ææ—¶é•¿ (PT1H30M15S -> seconds)
                duration_str = item['contentDetails'].get('duration', 'PT0S')
                duration = parse_duration(duration_str)

                details[video_id] = {
                    'duration': duration,
                    'duration_str': duration_str
                }

        except Exception as e:
            print(f"\n   âš ï¸  è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥: {e}")

    return details


def parse_duration(duration_str: str) -> int:
    """
    è§£æ ISO 8601 æ—¶é•¿æ ¼å¼ (PT1H30M15S) ä¸ºç§’æ•°

    Args:
        duration_str: PT æ ¼å¼çš„æ—¶é•¿å­—ç¬¦ä¸²

    Returns:
        ç§’æ•°
    """
    if not duration_str or not duration_str.startswith('PT'):
        return 0

    duration_str = duration_str[2:]  # ç§»é™¤ PT å‰ç¼€
    hours = minutes = seconds = 0

    # è§£æå°æ—¶
    if 'H' in duration_str:
        h_idx = duration_str.index('H')
        hours = int(duration_str[:h_idx])
        duration_str = duration_str[h_idx+1:]

    # è§£æåˆ†é’Ÿ
    if 'M' in duration_str:
        m_idx = duration_str.index('M')
        minutes = int(duration_str[:m_idx])
        duration_str = duration_str[m_idx+1:]

    # è§£æç§’
    if 'S' in duration_str:
        s_idx = duration_str.index('S')
        seconds = int(duration_str[:s_idx])

    return hours * 3600 + minutes * 60 + seconds


def extract_channel_videos_with_api(channel_url: str, api_key: str, limit: int = None) -> Dict[str, List[Dict]]:
    """
    ä½¿ç”¨ YouTube Data API æå–é¢‘é“è§†é¢‘

    Args:
        channel_url: YouTube é¢‘é“é“¾æ¥
        api_key: YouTube Data API Key
        limit: é™åˆ¶æ•°é‡

    Returns:
        dict: {channel_name, videos}
    """
    result = {
        'channel_name': 'YouTube_Channel',
        'videos': []
    }

    link_type = detect_channel_type(channel_url)

    # è·å–é¢‘é“ ID
    channel_id = extract_channel_id_from_url(channel_url)

    # å¦‚æœæ˜¯ @username æ ¼å¼ï¼Œéœ€è¦å…ˆè·å–é¢‘é“ ID
    if not channel_id:
        if link_type == 'channel':
            # ä» URL æå– handle
            if '/@' in channel_url:
                handle = channel_url.split('/@')[-1].split('/')[0]
            elif '/c/' in channel_url:
                handle = channel_url.split('/c/')[-1].split('/')[0]
            else:
                print("   âš ï¸  æ— æ³•è¯†åˆ«é¢‘é“æ ¼å¼")
                return result

            print(f"   ğŸ“¡ è·å–é¢‘é“ ID: @{handle}")
            channel_id = get_channel_id_by_handle(api_key, handle)

            if not channel_id:
                print("   âŒ æ— æ³•è·å–é¢‘é“ ID")
                return result

    # è·å–é¢‘é“åç§°
    try:
        params = {
            'key': api_key,
            'part': 'snippet',
            'id': channel_id
        }
        response = requests.get(f"{YOUTUBE_API_URL}/channels", params=params, timeout=30)
        response.raise_for_status()
        data = response.json()

        if data.get('items'):
            result['channel_name'] = sanitize_filename(data['items'][0]['snippet']['title'])

    except Exception as e:
        print(f"   âš ï¸  è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")

    # è·å–è§†é¢‘åˆ—è¡¨
    videos = get_channel_videos_by_api(api_key, channel_id, limit)
    result['videos'] = videos

    print(f"   âœ… æˆåŠŸæå– {len(videos)} ä¸ªè§†é¢‘")

    return result


def extract_channel_videos_ytdlp(channel_url: str, limit: int = None) -> Dict[str, List[Dict]]:
    """
    ä½¿ç”¨ yt-dlp æå–é¢‘é“è§†é¢‘ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰

    Args:
        channel_url: YouTube é¢‘é“é“¾æ¥
        limit: é™åˆ¶æ•°é‡

    Returns:
        dict: {channel_name, videos}
    """
    result = {
        'channel_name': 'YouTube_Channel',
        'videos': []
    }

    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': 'in_search',
        'playlistend': limit,
    }

    print(f"   ğŸ“¡ ä½¿ç”¨ yt-dlp è·å–è§†é¢‘åˆ—è¡¨...")

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(channel_url, download=False)

            if info:
                if info.get('title'):
                    result['channel_name'] = sanitize_filename(info['title'])
                elif info.get('channel'):
                    result['channel_name'] = sanitize_filename(info['channel'])
                elif info.get('uploader'):
                    result['channel_name'] = sanitize_filename(info['uploader'])

                entries = []
                if 'entries' in info:
                    entries = info['entries']
                elif detect_channel_type(channel_url) == 'video':
                    entries = [info]

                for entry in entries:
                    if entry is None:
                        continue

                    video_url = entry.get('url')
                    if not video_url and entry.get('id'):
                        video_url = f"https://www.youtube.com/watch?v={entry['id']}"

                    if video_url:
                        result['videos'].append({
                            'url': video_url,
                            'title': entry.get('title', 'Untitled'),
                            'id': entry.get('id', ''),
                            'duration': entry.get('duration', 0)
                        })

    except Exception as e:
        print(f"   âŒ è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")

    print(f"   âœ… æˆåŠŸæå– {len(result['videos'])} ä¸ªè§†é¢‘")
    return result


def save_temp_csv(videos: List[Dict], channel_name: str, output_dir: str) -> str:
    """ä¿å­˜è§†é¢‘åˆ—è¡¨åˆ°ä¸´æ—¶ CSV æ–‡ä»¶"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_file = output_path / f"{channel_name}_{timestamp}.csv"

    print(f"   ğŸ“„ æ­£åœ¨ä¿å­˜ CSV æ–‡ä»¶...")

    with open(csv_file, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['åºå·', 'æ ‡é¢˜', 'é“¾æ¥', 'æ—¶é•¿'])

        for i, video in enumerate(videos, 1):
            duration_str = f"{video['duration']}ç§’" if video.get('duration') else ''
            writer.writerow([
                i,
                video['title'],
                video['url'],
                duration_str
            ])

    print(f"   âœ… CSV æ–‡ä»¶å·²ä¿å­˜: {csv_file.name}")
    return str(csv_file)


def download_videos(csv_file: str, output_dir: str) -> tuple:
    """
    è°ƒç”¨ download_videos_from_csv.py è¿›è¡Œæ‰¹é‡ä¸‹è½½

    Returns:
        (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, è·³è¿‡æ•°é‡)
    """
    try:
        import sys
        sys.path.insert(0, str(Path(__file__).parent))

        from download_videos_from_csv import parse_csv, batch_download, get_author_name_from_csv

        print(f"   ğŸ“– æ­£åœ¨è§£æ CSV æ–‡ä»¶...")
        videos = parse_csv(csv_file)
        if not videos:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°è§†é¢‘")
            return (0, 0, 0)

        print(f"   ğŸ“¥ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(videos)} ä¸ªè§†é¢‘...")
        results = batch_download(videos, get_author_name_from_csv(csv_file), output_dir)

        success = sum(1 for r in results if r['success'] and 'skip_reason' not in r)
        skipped = sum(1 for r in results if r['success'] and 'skip_reason' in r)
        failed = sum(1 for r in results if not r['success'])

        return (success, failed, skipped)

    except Exception as e:
        print(f"   âŒ ä¸‹è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return (0, 1, 0)


def transcribe_videos(
    video_dir: str,
    output_dir: str = "gemini_analysis",
    mode: str = "knowledge",
    model: str = "flash-lite"
) -> tuple:
    """
    è°ƒç”¨ video_understand_gemini.py è¿›è¡Œæ‰¹é‡è½¬å½•

    Returns:
        (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡)
    """
    try:
        import sys
        sys.path.insert(0, str(Path(__file__).parent))

        from video_understand_gemini import (
            VideoProcessor, get_prompt, batch_analyze, load_completed_videos
        )
        from pathlib import Path

        video_path = Path(video_dir)

        if not video_path.exists():
            print(f"   âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_dir}")
            return (0, 0)

        videos = list(video_path.glob("*.mp4")) + list(video_path.glob("*.mov")) + \
                list(video_path.glob("*.avi")) + list(video_path.glob("*.mkv"))
        videos = list(set(videos))

        if not videos:
            print(f"   âš ï¸  æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return (0, 0)

        completed = load_completed_videos(output_dir)
        pending = [v for v in videos if v.stem not in completed]

        print(f"   ğŸ“¹ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
        print(f"   â­ï¸  è·³è¿‡å·²å®Œæˆçš„: {len(videos) - len(pending)} ä¸ª")
        print(f"   ğŸ“ å¾…å¤„ç†: {len(pending)} ä¸ª")

        if not pending:
            print(f"   âœ… æ‰€æœ‰è§†é¢‘éƒ½å·²å¤„ç†å®Œæˆ!")
            return (len(videos), 0)

        print(f"   ğŸ”§ åˆå§‹åŒ– Gemini æ¨¡å‹: {model}...")
        processor = VideoProcessor(model=model)

        prompt = get_prompt(mode)

        batch_analyze(
            video_dir=video_dir,
            processor=processor,
            prompt=prompt,
            output_dir=output_dir,
            skip_completed=True
        )

        return (len(pending), 0)

    except Exception as e:
        print(f"   âŒ è½¬å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return (0, 1)


def show_video_list(videos: List[Dict], show_count: int = 20):
    """æ˜¾ç¤ºè§†é¢‘åˆ—è¡¨"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ è§†é¢‘åˆ—è¡¨é¢„è§ˆ")
    print("=" * 80)

    display_count = min(show_count, len(videos))
    for i, video in enumerate(videos[:display_count], 1):
        duration = video.get('duration', 0)
        duration_str = f"{duration//60}:{duration%60:02d}" if duration else "--:--"
        print(f"{i:3}. [{duration_str}] {video['title'][:55]}...")

    if len(videos) > show_count:
        print(f"\n   ... è¿˜æœ‰ {len(videos) - show_count} ä¸ªè§†é¢‘æœªæ˜¾ç¤º")

    print("=" * 80)


def print_summary(results: Dict[str, int], start_time: float):
    """æ‰“å°æ‰§è¡Œæ‘˜è¦"""
    elapsed = time.time() - start_time

    print("\n" + "=" * 80)
    print("ğŸ“Š æ‰§è¡Œæ‘˜è¦")
    print("=" * 80)

    if results.get('extracted'):
        print(f"   ğŸ“¡ æå–è§†é¢‘: {results['extracted']} ä¸ª")

    if results.get('downloaded') is not None:
        print(f"   ğŸ“¥ ä¸‹è½½è§†é¢‘: {results['downloaded']} ä¸ªæˆåŠŸ | {results.get('failed_dl', 0)} ä¸ªå¤±è´¥ | {results.get('skipped', 0)} ä¸ªè·³è¿‡")

    if results.get('transcribed') is not None:
        print(f"   ğŸ“ è½¬å½•è§†é¢‘: {results['transcribed']} ä¸ªæˆåŠŸ | {results.get('failed_trans', 0)} ä¸ªå¤±è´¥")

    print(f"   â±ï¸  æ€»è€—æ—¶: {elapsed:.1f} ç§’")
    print("=" * 80)


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="YouTube é¢‘é“è§†é¢‘æ‰¹é‡ä¸‹è½½ä¸è½¬å½•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. ä½¿ç”¨ YouTube APIï¼ˆæ¨èï¼Œç¨³å®šï¼‰:
   python youtube_channel_downloader.py --channel "https://www.youtube.com/@username" --api-key YOUR_API_KEY

2. ä¸ä½¿ç”¨ API:
   python youtube_channel_downloader.py --channel "https://www.youtube.com/@username"

3. ä¸‹è½½å¹¶è½¬å½•:
   python youtube_channel_downloader.py --channel "https://www.youtube.com/@username" --transcribe

4. é™åˆ¶æ•°é‡:
   python youtube_channel_downloader.py --channel "https://www.youtube.com/@username" --limit 3

è·å– YouTube API Key:
1. è®¿é—® https://console.cloud.google.com/
2. åˆ›å»ºé¡¹ç›®å¹¶å¯ç”¨ YouTube Data API v3
3. åˆ›å»º API Keyï¼ˆæ— éœ€è®¾ç½® OAuthï¼‰
4. å…è´¹é…é¢: 10,000 å•ä½/å¤©ï¼ˆè·å–è§†é¢‘åˆ—è¡¨çº¦æ¶ˆè€— 1-5 å•ä½/é¢‘é“ï¼‰
        """
    )

    parser.add_argument('-c', '--channel', required=True, help='YouTube é¢‘é“/æ’­æ”¾åˆ—è¡¨é“¾æ¥')
    parser.add_argument('-o', '--output', default='youtube_videos', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: youtube_videosï¼‰')
    parser.add_argument('-t', '--transcribe', action='store_true', help='ä¸‹è½½åä½¿ç”¨ Gemini è¿›è¡Œè½¬å½•')
    parser.add_argument('--transcribe-dir', help='åªè½¬å½•å·²æœ‰è§†é¢‘ï¼Œä¸ä¸‹è½½ï¼ˆæŒ‡å®šè§†é¢‘ç›®å½•ï¼‰')
    parser.add_argument('-m', '--mode', choices=['summary', 'brief', 'detailed', 'transcript', 'knowledge'],
                        default='knowledge', help='è½¬å½•æç¤ºè¯æ¨¡å¼ï¼ˆé»˜è®¤: knowledgeï¼‰')
    parser.add_argument('--model', choices=['flash', 'flash-lite', 'pro'],
                        default='flash-lite', help='Gemini æ¨¡å‹ï¼ˆé»˜è®¤: flash-liteï¼‰')
    parser.add_argument('--limit', type=int, help='é™åˆ¶ä¸‹è½½æ•°é‡')
    parser.add_argument('--no-download', action='store_true', help='ä¸ä¸‹è½½ï¼Œåªæå–è§†é¢‘åˆ—è¡¨')
    parser.add_argument('-y', '--yes', action='store_true', help='è·³è¿‡ç¡®è®¤ç›´æ¥å¼€å§‹')
    parser.add_argument('--api-key', help='YouTube Data API Keyï¼ˆæ¨èä½¿ç”¨ï¼‰')

    args = parser.parse_args()

    start_time = time.time()
    results = {}

    # åªè½¬å½•æ¨¡å¼
    if args.transcribe_dir:
        print(f"\n{'='*80}")
        print(f"ğŸ“ åªè½¬å½•æ¨¡å¼")
        print(f"{'='*80}")
        print(f"è§†é¢‘ç›®å½•: {args.transcribe_dir}")
        print(f"è½¬å½•æ¨¡å¼: {args.mode}")
        print(f"ä½¿ç”¨æ¨¡å‹: {args.model}")

        if args.yes or input("\næ˜¯å¦å¼€å§‹è½¬å½•? (y/n): ").strip().lower() == 'y':
            success, failed = transcribe_videos(args.transcribe_dir, args.output, args.mode, args.model)
            results['transcribed'] = success
            results['failed_trans'] = failed
            print_summary(results, start_time)
        return

    # æå–è§†é¢‘åˆ—è¡¨
    print(f"\n{'='*80}")
    print(f"ğŸ¬ YouTube é¢‘é“ä¸‹è½½å·¥å…·")
    print(f"{'='*80}")
    print(f"ğŸ”— é“¾æ¥: {args.channel}")

    link_type = detect_channel_type(args.channel)
    type_names = {
        'channel': 'é¢‘é“',
        'playlist': 'æ’­æ”¾åˆ—è¡¨',
        'video': 'å•ä¸ªè§†é¢‘',
        'unknown': 'æœªçŸ¥ç±»å‹'
    }
    print(f"ğŸ“‹ ç±»å‹: {type_names.get(link_type, 'æœªçŸ¥')}")

    # æå–è§†é¢‘
    api_key = args.api_key or DEFAULT_API_KEY
    if api_key:
        print(f"ğŸ”‘ ä½¿ç”¨ API æ¨¡å¼")
        channel_info = extract_channel_videos_with_api(args.channel, api_key, args.limit)
    else:
        print(f"ğŸ“¡ ä½¿ç”¨ yt-dlp æ¨¡å¼ï¼ˆå¯èƒ½ä¸ç¨³å®šï¼‰")
        channel_info = extract_channel_videos_ytdlp(args.channel, args.limit)

    if not channel_info['videos']:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘")
        return

    results['extracted'] = len(channel_info['videos'])
    channel_name = channel_info['channel_name']
    videos = channel_info['videos']

    print(f"ğŸ“º é¢‘é“åç§°: {channel_name}")
    print(f"ğŸ”¢ è§†é¢‘æ•°é‡: {len(videos)}")

    total_duration = sum(v.get('duration', 0) for v in videos)
    hours = total_duration // 3600
    minutes = (total_duration % 3600) // 60
    print(f"â±ï¸  æ€»æ—¶é•¿: {hours}å°æ—¶{minutes}åˆ†é’Ÿ")

    show_video_list(videos)

    # åªæå–æ¨¡å¼
    if args.no_download:
        csv_file = save_temp_csv(videos, channel_name, args.output)
        print(f"\nâœ… è§†é¢‘åˆ—è¡¨å·²ä¿å­˜åˆ°: {csv_file}")
        print_summary(results, start_time)
        return

    # ç¡®è®¤ä¸‹è½½
    if not args.yes:
        response = input("\nâš ï¸  æ˜¯å¦å¼€å§‹ä¸‹è½½? (y/n): ").strip().lower()
        if response != 'y':
            print("â­ï¸  å·²å–æ¶ˆ")
            return

    # ä¿å­˜ä¸´æ—¶ CSV
    print(f"\n{'='*80}")
    print(f"ğŸ“¥ ç¬¬1æ­¥: å‡†å¤‡ä¸‹è½½")
    print(f"{'='*80}")
    csv_file = save_temp_csv(videos, channel_name, args.output)

    # ä¸‹è½½è§†é¢‘
    print(f"\n{'='*80}")
    print(f"ğŸ“¥ ç¬¬2æ­¥: ä¸‹è½½è§†é¢‘")
    print(f"{'='*80}")
    print(f"   ğŸ’¡ æç¤º: å¦‚æœé‡åˆ° 403 é”™è¯¯ï¼Œè¯·è®¾ç½®ä»£ç†æˆ–å¯¼å‡º cookies")
    print(f"   ğŸ’¡ ä»£ç†: set HTTPS_PROXY=http://127.0.0.1:7890")
    print(f"   ğŸ’¡ Cookies: å¯¼å‡ºä¸º cookies_youtube.txt")

    downloaded, failed_dl, skipped = download_videos(csv_file, args.output)
    results['downloaded'] = downloaded
    results['failed_dl'] = failed_dl
    results['skipped'] = skipped

    # è½¬å½•
    if args.transcribe:
        print(f"\n{'='*80}")
        print(f"ğŸ“¥ ç¬¬3æ­¥: è½¬å½•è§†é¢‘")
        print(f"{'='*80}")
        print(f"   æ¨¡å¼: {args.mode}")
        print(f"   æ¨¡å‹: {args.model}")

        video_dir = Path(args.output) / channel_name

        if video_dir.exists():
            transcribed, failed_trans = transcribe_videos(str(video_dir), args.output, args.mode, args.model)
            results['transcribed'] = transcribed
            results['failed_trans'] = failed_trans
        else:
            print(f"   âš ï¸  è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_dir}")
            results['transcribed'] = 0

    print_summary(results, start_time)
    print(f"\nâœ… å…¨éƒ¨å®Œæˆ!")


if __name__ == "__main__":
    main()
