#!/usr/bin/env python3
"""
æµ‹è¯•å°çº¢ä¹¦å›¾æ–‡æå–åŠŸèƒ½

åŠŸèƒ½ï¼š
1. çˆ¬å–ç”¨æˆ·ä¸»é¡µçš„ç¬”è®°åˆ—è¡¨
2. é€‰æ‹©ä¸€ä¸ªå›¾æ–‡ç¬”è®°
3. æå–å›¾ç‰‡å¹¶ä»¥æ ¼å¼åŒ–å½¢å¼å±•ç¤º
"""

import os
import sys
import re
import json
import requests
from pathlib import Path
from datetime import datetime

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def get_user_notes(user_url: str) -> list:
    """
    è·å–ç”¨æˆ·çš„ç¬”è®°åˆ—è¡¨

    Args:
        user_url: ç”¨æˆ·ä¸»é¡µé“¾æ¥ï¼ˆå¸¦xsec_tokenï¼‰

    Returns:
        ç¬”è®°åˆ—è¡¨
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    }

    print(f"ğŸ“¡ è¯·æ±‚ç”¨æˆ·ä¸»é¡µ...")
    print(f"   URL: {user_url[:80]}...")

    response = requests.get(user_url, headers=headers, timeout=30)

    if response.status_code != 200:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
        return []

    html = response.text
    print(f"âœ… é¡µé¢è·å–æˆåŠŸ (é•¿åº¦: {len(html)})")

    # æå–ç”¨æˆ·å
    title_match = re.search(r'<title[^>]*>(.+?)</title>', html)
    user_name = "æœªçŸ¥ç”¨æˆ·"
    if title_match:
        user_name = title_match.group(1).split('-')[0].strip()
    print(f"ğŸ‘¤ ç”¨æˆ·å: {user_name}")

    # æŸ¥æ‰¾ __INITIAL_STATE__ JSON æ•°æ®
    start_idx = html.find('window.__INITIAL_STATE__=')
    if start_idx == -1:
        print(f"âŒ æœªæ‰¾åˆ° __INITIAL_STATE__")
        return []

    start_idx += len('window.__INITIAL_STATE__=')
    end_idx = html.find('</script>', start_idx)
    json_str = html[start_idx:end_idx]

    # å°è¯•è§£æ JSONï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
    data = None
    try:
        # å°çº¢ä¹¦çš„ JSON å¯èƒ½åŒ…å«æ¢è¡Œï¼Œéœ€è¦æ¸…ç†
        json_str_clean = json_str.replace('\n', '\\n').replace('\r', '\\r')
        data = json.loads(json_str_clean)
    except json.JSONDecodeError:
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æ‰¾åˆ°å®Œæ•´çš„éƒ¨åˆ†
        print(f"âš ï¸  JSONè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")

    # æå–ç¬”è®°åˆ—è¡¨
    notes = []

    # æ–¹æ³•1: ä» JSON ä¸­æå–
    if data:
        try:
            # è·¯å¾„1: noteData.byNoteId
            if 'noteData' in data and 'byNoteId' in data['noteData']:
                note_dict = data['noteData']['byNoteId']
                for note_id, note_info in note_dict.items():
                    if isinstance(note_info, dict) and 'title' in note_info:
                        notes.append({
                            'note_id': note_id,
                            'title': note_info.get('title', ''),
                            'type': note_info.get('type', 'normal'),
                            'desc': note_info.get('desc', '')[:100],
                            'liked_count': note_info.get('liked_count', 0),
                        })
            # è·¯å¾„2: user.noteStore.notes
            elif 'user' in data and 'noteStore' in data['user']:
                note_store = data['user']['noteStore']
                if 'notes' in note_store:
                    for note_item in note_store['notes']:
                        notes.append({
                            'note_id': note_item.get('id', ''),
                            'title': note_item.get('title', ''),
                            'type': note_item.get('type', 'normal'),
                            'desc': note_item.get('desc', '')[:100],
                            'liked_count': note_item.get('liked_count', 0),
                        })
        except Exception as e:
            print(f"âš ï¸  ä» JSON æå–å¤±è´¥: {e}")

    # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»åŸå§‹ HTML ä¸­æå–ç¬”è®° ID å’Œæ ‡é¢˜
    if not notes:
        print(f"ğŸ” ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç¬”è®°...")
        # æŸ¥æ‰¾æ‰€æœ‰ explore/ é“¾æ¥
        explore_pattern = r'href="/explore/([a-f0-9]+)\?'
        note_ids = re.findall(explore_pattern, html)
        note_ids = list(set(note_ids))  # å»é‡

        # æŸ¥æ‰¾æ ‡é¢˜
        title_pattern = r'"title":"([^"]+)"'
        titles = re.findall(title_pattern, html)

        print(f"   æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°ID, {len(titles)} ä¸ªæ ‡é¢˜")

        # åŒ¹é… ID å’Œæ ‡é¢˜ï¼ˆç®€å•é…å¯¹ï¼‰
        for i, note_id in enumerate(note_ids[:20]):  # é™åˆ¶20ä¸ª
            title = titles[i] if i < len(titles) else f"ç¬”è®°{i+1}"
            try:
                title = title.encode('utf-8').decode('unicode_escape')
            except:
                pass
            notes.append({
                'note_id': note_id,
                'title': title,
                'type': 'normal',
                'desc': '',
                'liked_count': 0,
            })

    print(f"ğŸ“ æ‰¾åˆ° {len(notes)} æ¡ç¬”è®°")

    return notes, user_name


def extract_xhs_images(url: str) -> dict:
    """
    ä»å°çº¢ä¹¦é“¾æ¥æå–ç¬”è®°çš„å›¾ç‰‡

    Returns:
        {
            'title': 'æ ‡é¢˜',
            'images': [
                {'url': 'å›¾ç‰‡URL', 'index': 1},
                ...
            ],
            'text': 'ç¬”è®°æ–‡å­—å†…å®¹'
        }
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.xiaohongshu.com/',
    }

    print(f"\nğŸ“¡ è¯·æ±‚ç¬”è®°é¡µé¢...")

    try:
        response = requests.get(url, headers=headers, timeout=30)

        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return None

        html = response.text
        print(f"âœ… é¡µé¢è·å–æˆåŠŸ")

    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

    # æå–æ ‡é¢˜
    title = "å°çº¢ä¹¦ç¬”è®°"
    title_match = re.search(r'<title[^>]*>(.+?)</title>', html)
    if title_match:
        title = title_match.group(1).replace(' - å°çº¢ä¹¦', '').strip()
    print(f"ğŸ“ æ ‡é¢˜: {title}")

    # æå–æ–‡å­—å†…å®¹
    text_content = ""
    desc_match = re.search(r'"desc":"([^"]+)"', html)
    if desc_match:
        # è§£ç  Unicode è½¬ä¹‰
        text_content = desc_match.group(1).encode('utf-8').decode('unicode_escape')
    print(f"ğŸ“„ æ–‡å­—å†…å®¹: {text_content[:100]}...")

    # æå–å›¾ç‰‡
    start_idx = html.find('window.__INITIAL_STATE__=')
    if start_idx == -1:
        print(f"âŒ æœªæ‰¾åˆ° __INITIAL_STATE__")
        return None

    start_idx += len('window.__INITIAL_STATE__=')
    end_idx = html.find('</script>', start_idx)
    json_str = html[start_idx:end_idx]

    data = None
    try:
        data = json.loads(json_str)
    except:
        pass

    image_urls = []

    if data:
        try:
            note = data.get('note', {})
            note_detail = note.get('noteDetail', {})
            image_list = note_detail.get('imageList', [])

            if image_list:
                for i, img_obj in enumerate(image_list):
                    if isinstance(img_obj, dict):
                        url = (img_obj.get('urlDefault') or
                               img_obj.get('url_default') or
                               img_obj.get('url'))
                        if url:
                            # æ¸…ç† URL
                            url = url.split('?')[0]
                            try:
                                url = url.encode('utf-8').decode('unicode_escape')
                            except:
                                pass
                            url = url.replace(r'\/', '/')
                            if url.startswith('http://'):
                                url = 'https://' + url[7:]

                            image_urls.append({
                                'index': i + 1,
                                'url': url
                            })
        except Exception as e:
            print(f"âš ï¸  æå–å›¾ç‰‡å¤±è´¥: {e}")

    print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(image_urls)} å¼ å›¾ç‰‡")

    return {
        'title': title,
        'images': image_urls,
        'text': text_content
    }


def format_display_result(result: dict) -> str:
    """
    æ ¼å¼åŒ–æ˜¾ç¤ºæå–ç»“æœ
    """
    if not result:
        return "âŒ æå–å¤±è´¥"

    output = []
    output.append("=" * 80)
    output.append("ğŸ“‹ å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æå–ç»“æœ")
    output.append("=" * 80)
    output.append("")
    output.append(f"ğŸ“ æ ‡é¢˜: {result['title']}")
    output.append("")
    output.append(f"ğŸ“„ æ–‡å­—å†…å®¹:")
    output.append(f"   {result['text']}")
    output.append("")
    output.append(f"ğŸ–¼ï¸  å›¾ç‰‡åˆ—è¡¨ ({len(result['images'])} å¼ ):")
    output.append("")

    for img in result['images']:
        output.append(f"   [{img['index']}] {img['url']}")

    output.append("")
    output.append("=" * 80)

    return "\n".join(output)


def main():
    # ç”¨æˆ·ä¸»é¡µé“¾æ¥
    user_url = "https://www.xiaohongshu.com/user/profile/5b3ac81e11be107c7a5b7505?xsec_token=ABPLGMaYH1NMtjc6IEYUR-YLFSXtRx5IjPIM7yj019c0w=&xsec_source=pc_feed"

    print("\n" + "=" * 80)
    print("ğŸ” å°çº¢ä¹¦å›¾æ–‡æå–æµ‹è¯•")
    print("=" * 80)
    print()

    # æ­¥éª¤1: è·å–ç”¨æˆ·ç¬”è®°åˆ—è¡¨
    notes_result = get_user_notes(user_url)

    if isinstance(notes_result, tuple):
        notes, user_name = notes_result
    else:
        notes = notes_result
        user_name = "æœªçŸ¥ç”¨æˆ·"

    print(f"ğŸ‘¤ ç”¨æˆ·: {user_name}")

    if not notes:
        print("âŒ æœªæ‰¾åˆ°ç¬”è®°")
        return

    # æ˜¾ç¤ºç¬”è®°åˆ—è¡¨
    print("\n" + "-" * 80)
    print("ğŸ“‹ ç¬”è®°åˆ—è¡¨:")
    print("-" * 80)

    for i, note in enumerate(notes[:10], 1):  # åªæ˜¾ç¤ºå‰10æ¡
        note_type = note.get('type', 'normal')
        type_emoji = "ğŸ–¼ï¸" if note_type == 'normal' else "ğŸ¬"
        print(f"{i:2}. {type_emoji} {note['title'][:50]}")

    # é€‰æ‹©ç¬¬ä¸€ä¸ªå›¾æ–‡ç¬”è®°
    print("\n" + "-" * 80)
    print("ğŸ” é€‰æ‹©ç¬¬ä¸€ä¸ªå›¾æ–‡ç¬”è®°è¿›è¡Œæµ‹è¯•...")
    print("-" * 80)

    image_note = None
    for note in notes:
        if note.get('type') == 'normal':
            image_note = note
            break

    if not image_note and notes:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°normalç±»å‹ï¼Œå°±ç”¨ç¬¬ä¸€ä¸ª
        image_note = notes[0]

    if not image_note:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯æµ‹è¯•çš„ç¬”è®°")
        return

    note_id = image_note.get('note_id', '')
    print(f"ğŸ“ é€‰æ‹©ç¬”è®°: {image_note['title'][:50]}")
    print(f"ğŸ†” ç¬”è®°ID: {note_id}")

    # æ„å»ºç¬”è®°é“¾æ¥
    note_url = f"https://www.xiaohongshu.com/explore/{note_id}?xsec_source=pc_feed"

    # æ­¥éª¤2: æå–å›¾ç‰‡
    result = extract_xhs_images(note_url)

    # æ­¥éª¤3: æ ¼å¼åŒ–æ˜¾ç¤º
    print("\n")
    print(format_display_result(result))

    # æ­¥éª¤4: ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_dir = Path("output/test_xhs")
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    result_file = output_dir / f"extract_result_{timestamp}.txt"

    with open(result_file, 'w', encoding='utf-8') as f:
        f.write(format_display_result(result))
        f.write("\n\n")
        f.write(f"åŸå§‹ç¬”è®°é“¾æ¥: {note_url}\n")
        f.write(f"æå–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")


if __name__ == "__main__":
    main()
