#!/usr/bin/env python3
"""
ä½¿ç”¨ Gemini API æ‰¹é‡ç”Ÿæˆå­—å¹•æ‘˜è¦å’Œæ±‡æ€»æŠ¥å‘Šï¼ˆæ”¯æŒå¹¶å‘å¤„ç†ï¼‰

æ–¹æ¡ˆ2ï¼šåˆ†æ‰¹æ‘˜è¦å†æ±‡æ€»
1. è¯»å–ä½œè€…æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ SRT æ–‡ä»¶
2. æ¯ä¸ª SRT å‘ç»™ Gemini â†’ ç”ŸæˆçŸ¥è¯†åº“å‹æ‘˜è¦ï¼ˆåŸºäº knowledge æ¨¡å¼ï¼‰
3. æŠŠæ‰€æœ‰æ‘˜è¦åˆå¹¶å‘ç»™ Gemini â†’ ç”Ÿæˆæ€»æŠ¥å‘Š
4. ä¿å­˜åˆ° {ä½œè€…å}_AIæ€»ç»“.md

ä½¿ç”¨ç¤ºä¾‹:
    # å¤„ç†æŒ‡å®šä½œè€…çš„å­—å¹•æ–‡ä»¶å¤¹
    python gemini_subtitle_summary.py "output/subtitles/å°å¤©fotos"

    # æŒ‡å®šå¹¶å‘æ•°ï¼ˆé»˜è®¤3ï¼‰
    python gemini_subtitle_summary.py "output/subtitles/å°å¤©fotos" -j 5

    # æŒ‡å®šGeminiæ¨¡å‹
    python gemini_subtitle_summary.py "output/subtitles/å°å¤©fotos" --model flash-lite
"""

import asyncio
import os
import sys
import time
import json
import argparse
import re
import threading
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor

# ä¼˜å…ˆä½¿ç”¨æ–° SDK
try:
    from google import genai
    USE_NEW_SDK = True
except ImportError:
    try:
        import google.generativeai as genai
        USE_NEW_SDK = False
    except ImportError:
        print("âŒ æœªå®‰è£… google-genai æˆ– google-generativeai åº“")
        print("è¯·è¿è¡Œ: pip install google-genai")
        sys.exit(1)

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# çº¿ç¨‹å®‰å…¨çš„æ‰“å°é”
print_lock = threading.Lock()


# ==================== é…ç½® ====================

GEMINI_MODELS = {
    'flash-lite': 'gemini-2.5-flash-lite',
    'flash': 'gemini-2.5-flash',
    'pro': 'gemini-2.5-pro',
}


def get_api_key() -> str:
    """è·å– Gemini API Key"""
    # 1. ç¯å¢ƒå˜é‡
    api_key = os.environ.get('GEMINI_API_KEY')
    if api_key:
        return api_key

    # 2. é…ç½®æ–‡ä»¶
    try:
        sys.path.insert(0, str(Path(__file__).parent))
        from config_api import API_CONFIG
        api_key = API_CONFIG.get('gemini', {}).get('api_key')
        if api_key:
            return api_key
    except ImportError:
        pass

    return None


class GeminiClient:
    """Gemini API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ–°æ—§ SDKï¼‰"""

    def __init__(self, model: str = 'flash-lite', api_key: str = None):
        self.api_key = api_key or get_api_key()
        self.model_name = GEMINI_MODELS.get(model, GEMINI_MODELS['flash-lite'])
        self.use_new_sdk = USE_NEW_SDK

        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° Gemini API Key")

        if self.use_new_sdk:
            # æ–° SDK
            self.client = genai.Client(api_key=self.api_key)
        else:
            # æ—§ SDK
            import google.generativeai as genai_old
            genai_old.configure(api_key=self.api_key)

    def generate_content(self, prompt: str) -> Dict:
        """
        ç”Ÿæˆå†…å®¹

        Returns:
            {'text': 'ç”Ÿæˆå†…å®¹', 'tokens': int, 'input_tokens': int, 'output_tokens': int,
             'success': bool, 'error': str}
        """
        try:
            if self.use_new_sdk:
                # æ–° SDK
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=prompt
                )
                text = response.text
                # æ–° SDK token ä¿¡æ¯
                input_tokens = 0
                output_tokens = 0
                total_tokens = 0
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    metadata = response.usage_metadata
                    input_tokens = getattr(metadata, 'prompt_token_count', 0) or 0
                    output_tokens = getattr(metadata, 'candidates_token_count', 0) or 0
                    total_tokens = getattr(metadata, 'total_token_count', 0) or 0
            else:
                # æ—§ SDK
                import google.generativeai as genai_old
                model = genai_old.GenerativeModel(self.model_name)
                response = model.generate_content(prompt)
                text = response.text
                input_tokens = 0
                output_tokens = 0
                total_tokens = 0
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    metadata = response.usage_metadata
                    input_tokens = getattr(metadata, 'prompt_token_count', 0) or 0
                    output_tokens = getattr(metadata, 'candidates_token_count', 0) or 0
                    total_tokens = getattr(metadata, 'total_token_count', 0) or 0

            return {
                'text': text.strip() if text else '',
                'tokens': total_tokens,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'success': True
            }

        except Exception as e:
            return {
                'text': '',
                'tokens': 0,
                'input_tokens': 0,
                'output_tokens': 0,
                'success': False,
                'error': str(e)
            }


# ==================== SRT å¤„ç† ====================

def parse_srt(srt_path: Path) -> List[Dict]:
    """
    è§£æ SRT æ–‡ä»¶ï¼Œè¿”å›å­—å¹•æ¡ç›®åˆ—è¡¨

    Returns:
        [
            {'index': 1, 'start': '00:00:01,000', 'end': '00:00:04,000', 'text': 'å­—å¹•å†…å®¹'},
            ...
        ]
    """
    entries = []

    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # SRT æ ¼å¼è§£æ
    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?=\n\n|\n\d+\n|$)'
    matches = re.findall(pattern, content, re.DOTALL)

    for match in matches:
        index, start, end, text = match
        entries.append({
            'index': int(index),
            'start': start,
            'end': end,
            'text': text.strip().replace('\n', ' ')
        })

    return entries


def srt_to_text(srt_path: Path, max_length: int = 15000) -> str:
    """
    å°† SRT è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œæ§åˆ¶é•¿åº¦é¿å…è¶…é™

    Args:
        srt_path: SRT æ–‡ä»¶è·¯å¾„
        max_length: æœ€å¤§æ–‡æœ¬é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰

    Returns:
        å­—å¹•æ–‡æœ¬å†…å®¹
    """
    entries = parse_srt(srt_path)

    # åˆå¹¶æ‰€æœ‰å­—å¹•æ–‡æœ¬
    full_text = ' '.join([e['text'] for e in entries])

    # å¦‚æœè¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œæˆªæ–­å¹¶ä¿ç•™å‰80%
    if len(full_text) > max_length:
        full_text = full_text[:int(max_length * 0.8)] + '\n\n[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­...]'

    return full_text


# ==================== Gemini è°ƒç”¨ ====================

class GeminiSummarizer:
    """Gemini å­—å¹•æ‘˜è¦ç”Ÿæˆå™¨"""

    def __init__(self, model: str = 'flash-lite', api_key: str = None):
        self.client = GeminiClient(model=model, api_key=api_key)
        self.model_name = self.client.model_name

    def generate_summary(self, text: str, title: str = "") -> Dict:
        """
        ä¸ºå•ä¸ªå­—å¹•ç”ŸæˆçŸ¥è¯†åº“å‹æ‘˜è¦ï¼ˆåŸºäº knowledge æ¨¡å¼ï¼‰

        Args:
            text: å­—å¹•æ–‡æœ¬
            title: è§†é¢‘æ ‡é¢˜

        Returns:
            {'summary': 'æ‘˜è¦å†…å®¹', 'tokens': int}
        """
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿å°†è§†é¢‘å­—å¹•å†…å®¹è½¬åŒ–ä¸ºç»“æ„åŒ–çš„çŸ¥è¯†åº“ç¬”è®°ã€‚è¯·è¯¦ç»†åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•ï¼Œè¾“å‡ºç”¨äºæ„å»º"ç¬¬äºŒå¤§è„‘"çš„ç¬”è®°ã€‚

{'# ' + title if title else ''}

## ğŸ“‹ è§†é¢‘åŸºæœ¬ä¿¡æ¯
- **æ ¸å¿ƒä¸»é¢˜**: [ä¸€å¥è¯æ¦‚æ‹¬]
- **å†…å®¹ç»“æ„**: [æµæ°´è´¦å¼/è§‚ç‚¹è®ºè¯å¼/æ–°é—»æ±‡æ€»å¼/æ•…äº‹å™è¿°å¼]

## ğŸ“– è§†é¢‘å¤§æ„ï¼ˆ100-200å­—ï¼‰
[ç”¨ç²¾ç‚¼çš„ä¹¦é¢è¯­è¨€æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹ï¼Œå»é™¤å†—ä½™çš„å‰æƒ…æè¦å’Œæ— å…³ä¿¡æ¯]

## ğŸ¯ æ ¸å¿ƒè§‚ç‚¹ï¼ˆä¸‰æ®µè®ºï¼‰
[å¦‚æœè§†é¢‘æœ‰æ˜ç¡®è®ºç‚¹ï¼Œç”¨ä¸‰æ®µè®ºå½¢å¼å‘ˆç°]
- **å¤§å‰æ**: [æ™®éæ€§å‰ææˆ–èƒŒæ™¯]
- **å°å‰æ**: [å…·ä½“æƒ…å¢ƒæˆ–æ¡ä»¶]
- **ç»“è®º**: [æœ€ç»ˆè§‚ç‚¹æˆ–ä¸»å¼ ]

[å¦‚æœæ˜¯æ–°é—»åˆ†äº«ç±»ï¼Œåˆ™åˆ—å‡º]
- **æ–°é—»æ¡ç›®1**: [æ ‡é¢˜ + å…³é”®ä¿¡æ¯]
- **æ–°é—»æ¡ç›®2**: [æ ‡é¢˜ + å…³é”®ä¿¡æ¯]

## ğŸ“Š è®ºç‚¹è®ºæ®ç»“æ„
1. **ä¸»è¦è®ºç‚¹**
   - è®ºè¿°å†…å®¹: [è¯¦ç»†è¯´æ˜]
   - æ”¯æŒè®ºæ®: [æ•°æ®ã€æ¡ˆä¾‹ã€é€»è¾‘æ¨ç†]
   - å¯ä¿¡åº¦è¯„ä¼°: [é«˜/ä¸­/ä½ï¼Œè¯´æ˜ç†ç”±]

2. **æ¬¡è¦è®ºç‚¹**ï¼ˆå¦‚æœ‰ï¼‰
   - è®ºè¿°å†…å®¹: [è¯¦ç»†è¯´æ˜]
   - æ”¯æŒè®ºæ®: [æ•°æ®ã€æ¡ˆä¾‹ã€é€»è¾‘æ¨ç†]

## ğŸ’ é‡‘å¥/å¥½è¯å¥½å¥æå–
[è¯·æå–ä»¥ä¸‹ç±»å‹çš„å¥å­]

### 1. å¼•ç»æ®å…¸
- åŸå¥: "..."

### 2. æ•…äº‹/æ¡ˆä¾‹
- åŸå¥/æè¿°: "..."

### 3. ç²¾è¾Ÿè®ºæ®
- åŸå¥: "..."

### 4. æ·±åˆ»è§‚ç‚¹
- åŸå¥: "..."

### 5. å¥½è¯å¥½å¥
- åŸå¥: "..."

## ğŸ“ ä¹¦é¢æ–‡ç¨¿
[å°†å­—å¹•å†…å®¹æ•´ç†æˆç²¾ç‚¼çš„ä¹¦é¢è¡¨è¾¾æ–‡ç¨¿ï¼Œè¦æ±‚ï¼š
- å»é™¤æ‰€æœ‰å£è¯­åŒ–å†—ä½™ï¼ˆå¦‚"é‚£ä¸ª"ã€"å°±æ˜¯"ã€"ç„¶å"ç­‰ï¼‰
- ä½¿ç”¨æ­£å¼ã€ç»“æ„åŒ–çš„ä¹¦é¢è¯­è¨€
- ä¿ç•™æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘é“¾æ¡
- é€‚åˆä½œä¸ºæ¨¡å‹è®­ç»ƒçš„è¯­è¨€ææ–™
- å­—æ•°æ§åˆ¶åœ¨åŸæ–‡çš„30%-50%]

## âš ï¸ å†…å®¹è´¨é‡åˆ†æ
### æƒ…ç»ªæ“æ§æ£€æµ‹
- **åˆ¶é€ ç„¦è™‘/FOMOæƒ…ç»ª**: [æ˜¯/å¦]
- **åˆ†æ**: [å¦‚æœæœ‰ï¼Œè¯´æ˜ä½¿ç”¨äº†ä»€ä¹ˆæ‰‹æ³•]

### ä¿¡æ¯å¯é æ€§
- **ä¿¡æ¯æºå¯ä¿¡åº¦**: [é«˜/ä¸­/ä½]
- **äº‹å®æ ¸æŸ¥**: [æœ‰å“ªäº›å¯éªŒè¯çš„äº‹å®]
- **æ½œåœ¨åè§**: [æ˜¯å¦å­˜åœ¨æ˜æ˜¾åè§]

### çŸ¥è¯†ä»·å€¼è¯„ä¼°
- **æ–°é¢–æ€§**: [â˜…â˜…â˜…â˜…â˜…]
- **å®ç”¨æ€§**: [â˜…â˜…â˜…â˜…â˜…]
- **æ·±åº¦**: [â˜…â˜…â˜…â˜…â˜…]
- **æ¨èæ”¶è—**: [æ˜¯/å¦]

---
è¯·ç¡®ä¿è¾“å‡ºç»“æ„å®Œæ•´ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰å®è´¨å†…å®¹ã€‚å¦‚æœæŸéƒ¨åˆ†ç¡®å®ä¸é€‚ç”¨ï¼Œè¯·æ ‡æ³¨"[ä¸é€‚ç”¨]"å¹¶è¯´æ˜åŸå› ã€‚

---

## å­—å¹•å†…å®¹

{text}"""

        result = self.client.generate_content(prompt)

        if result['success']:
            return {
                'summary': result['text'],
                'tokens': result['tokens'],
                'success': True
            }
        else:
            return {
                'summary': f"ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                'tokens': 0,
                'success': False,
                'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
            }

    def generate_final_summary(self, summaries: List[Dict], author_name: str,
                               custom_prompt: str = None) -> Dict:
        """
        ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Šï¼ˆçŸ¥è¯†åº“å‹ï¼‰

        Args:
            summaries: æ‘˜è¦åˆ—è¡¨ [{'title': '', 'summary': ''}, ...]
            author_name: ä½œè€…åç§°
            custom_prompt: è‡ªå®šä¹‰æ±‡æ€»æç¤ºè¯

        Returns:
            {'report': 'æ±‡æ€»æŠ¥å‘Š', 'tokens': int}
        """
        # æ„å»ºæ‘˜è¦æ±‡æ€»æ–‡æœ¬
        summaries_text = ""
        for i, item in enumerate(summaries, 1):
            summaries_text += f"\n## è§†é¢‘ {i}: {item['title']}\n{item['summary']}\n"

        default_prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿å°†å¤šä¸ªè§†é¢‘å†…å®¹è½¬åŒ–ä¸ºç»“æ„åŒ–çš„çŸ¥è¯†åº“ç¬”è®°ã€‚è¯·åŸºäºä»¥ä¸‹è§†é¢‘å­—å¹•çš„çŸ¥è¯†åº“ç¬”è®°ï¼Œç”Ÿæˆä¸€ä»½å…¨é¢çš„ä½œè€…å†…å®¹åˆ†ææŠ¥å‘Šã€‚

ä½œè€…: {author_name}
è§†é¢‘æ•°é‡: {len(summaries)}

## å„è§†é¢‘çŸ¥è¯†åº“ç¬”è®°

{summaries_text}

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆä½¿ç”¨ Markdown æ ¼å¼ï¼‰ï¼š

# {author_name} è§†é¢‘å†…å®¹åˆ†ææŠ¥å‘Š

## ğŸ“‹ ä½œè€…æ¦‚è¿°
- **å†…å®¹é¢†åŸŸ/ä¸»é¢˜**: [ä½œè€…ä¸»è¦å…³æ³¨çš„å†…å®¹é¢†åŸŸ]
- **åˆ›ä½œé£æ ¼ç‰¹ç‚¹**: [å™è¿°æ–¹å¼ã€è¡¨è¾¾é£æ ¼ã€è§†é¢‘èŠ‚å¥ç­‰]
- **ç›®æ ‡å—ä¼—åˆ†æ**: [ä¸»è¦é¢å‘å“ªç±»äººç¾¤]
- **å†…å®¹æ›´æ–°é¢‘ç‡**: [ä»è§†é¢‘æ•°é‡æ¨æ–­æ›´æ–°è§„å¾‹]

## ğŸ¯ æ ¸å¿ƒä¸»é¢˜æ±‡æ€»
åˆ—å‡ºä½œè€…æœ€å¸¸è®¨è®ºçš„3-5ä¸ªæ ¸å¿ƒä¸»é¢˜ï¼Œæ¯ä¸ªä¸»é¢˜åŒ…æ‹¬ï¼š
- **ä¸»é¢˜åç§°**: [ä¸»é¢˜]
- **è®¨è®ºé¢‘æ¬¡**: [é«˜/ä¸­/ä½]
- **ä»£è¡¨æ€§è§‚ç‚¹**: [ä½œè€…åœ¨è¯¥ä¸»é¢˜ä¸Šçš„æ ¸å¿ƒç«‹åœº]
- **ç›¸å…³è§†é¢‘**: [æ¶‰åŠè¯¥ä¸»é¢˜çš„è§†é¢‘]

## ğŸ’¡ è§‚ç‚¹å€¾å‘ä¸æ€ç»´æ–¹å¼
- **ä¸»è¦è§‚ç‚¹å’Œç«‹åœº**: [ä½œè€…çš„æ ¸å¿ƒä¿¡å¿µå’Œä»·å€¼å–å‘]
- **è®ºè¯é£æ ¼**: [æ•°æ®é©±åŠ¨/ç»éªŒåˆ†äº«/ç†è®ºåˆ†æ/æƒ…æ„Ÿå…±é¸£]
- **ç‹¬ç‰¹è§è§£**: [ä½œè€…åŒºåˆ«äºä»–äººçš„ç‹¬ç‰¹è§†è§’]
- **å¯èƒ½çš„è®¤çŸ¥åå·®**: [å®¢è§‚åˆ†æä½œè€…å¯èƒ½å­˜åœ¨çš„åè§]

## ğŸ“Š å†…å®¹ç‰¹è‰²åˆ†æ
### æ ‡é¢˜é£æ ¼
- å‘½åè§„å¾‹: [å¦‚ï¼šè®¾é—®å¼/æ•°å­—å¼/çƒ­ç‚¹å¼]
- å…³é”®è¯åå¥½: [å¸¸ä½¿ç”¨çš„å…³é”®è¯ç±»å‹]

### å™è¿°æ–¹å¼
- å¼€å¤´é£æ ¼: [å¦‚ä½•å¼•å…¥è¯é¢˜]
- ç»“æ„æ¨¡å¼: [å±‚å±‚é€’è¿›/å¹¶åˆ—å¼/æ•…äº‹å‹]
- ç»“å°¾é£æ ¼: [æ€»ç»“å‡å/ç•™ç™½æ€è€ƒ/è¡ŒåŠ¨å·å¬]

### ä¸ªæ€§åŒ–å…ƒç´ 
- å£å¤´ç¦…/æ ‡å¿—æ€§è¡¨è¾¾
- å¸¸ç”¨æ¡ˆä¾‹/ç±»æ¯”
- ä¸ªæ€§åŒ–è§†è§‰/éŸ³é¢‘å…ƒç´ ï¼ˆå¦‚æœ‰æåŠï¼‰

## ğŸŒŸ ä»£è¡¨æ€§å†…å®¹æç‚¼
### é«˜ä»·å€¼è§†é¢‘ï¼ˆ2-3ä¸ªï¼‰
- **è§†é¢‘æ ‡é¢˜**: [æ ‡é¢˜]
  - æ ¸å¿ƒä»·å€¼: [ä¸ºä»€ä¹ˆå€¼å¾—çœ‹]
  - å…³é”®æ”¶è·: [è§‚ä¼—èƒ½è·å¾—ä»€ä¹ˆ]
  - æ¨èæŒ‡æ•°: â˜…â˜…â˜…â˜…â˜…

### é‡‘å¥/è§‚ç‚¹æ±‡æ€»ï¼ˆè·¨è§†é¢‘ï¼‰
[ä»æ‰€æœ‰è§†é¢‘ä¸­æå–å‡ºçš„æœ€å€¼å¾—è®°å½•çš„å¥å­å’Œè§‚ç‚¹]

## ğŸ“ˆ å†…å®¹è¶‹åŠ¿åˆ†æ
- **å†…å®¹æ¼”è¿›**: [ä½œè€…çš„å†…å®¹é£æ ¼/ä¸»é¢˜éšæ—¶é—´çš„å˜åŒ–]
- **å½“å‰çƒ­ç‚¹**: [ä½œè€…æœ€è¿‘å…³æ³¨çš„è¯é¢˜]
- **æœªæ¥å±•æœ›**: [åŸºäºå†…å®¹è¶‹åŠ¿çš„é¢„æµ‹]

## ğŸ“ å­¦ä¹ ä»·å€¼è¯„ä¼°
- **æ–°é¢–æ€§**: â˜…â˜…â˜…â˜…â˜… (å†…å®¹æ˜¯å¦ç‹¬ç‰¹æ–°é¢–)
- **å®ç”¨æ€§**: â˜…â˜…â˜…â˜…â˜… (æ˜¯å¦å¯è½åœ°åº”ç”¨)
- **æ·±åº¦**: â˜…â˜…â˜…â˜…â˜… (æ€è€ƒæ·±åº¦å¦‚ä½•)
- **ç³»ç»Ÿæ€§**: â˜…â˜…â˜…â˜…â˜… (çŸ¥è¯†ä½“ç³»æ˜¯å¦å®Œæ•´)
- **æ¨èæ”¶è—**: [æ˜¯/å¦]

## ğŸ‘¥ é€‚åˆäººç¾¤
[åˆ—å‡ºæœ€é€‚åˆè§‚çœ‹/å­¦ä¹ è¿™ä¸ªUPä¸»å†…å®¹çš„äººç¾¤ç±»å‹]

## ğŸ“š å»¶ä¼¸å­¦ä¹ å»ºè®®
åŸºäºä½œè€…çš„å†…å®¹ï¼Œæ¨èï¼š
- ç›¸å…³ä¸»é¢˜çš„æ·±å…¥å­¦ä¹ æ–¹å‘
- å¯ä»¥äº’è¡¥çš„å…¶ä»–ä½œè€…/èµ„æº
- å®è·µå»ºè®®

---
è¯·ç¡®ä¿æŠ¥å‘Šå†…å®¹è¯¦å®ã€ç»“æ„æ¸…æ™°ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰å®è´¨å†…å®¹ã€‚å°½é‡å¼•ç”¨å…·ä½“è§†é¢‘ä¸­çš„ä¾‹å­æ¥æ”¯æ’‘åˆ†æã€‚"""

        prompt = custom_prompt or default_prompt
        result = self.client.generate_content(prompt)

        if result['success']:
            return {
                'report': result['text'],
                'tokens': result['tokens'],
                'success': True
            }
        else:
            return {
                'report': f"ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                'tokens': 0,
                'success': False,
                'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
            }


# ==================== ä¸»å¤„ç†é€»è¾‘ ====================

def process_subtitles(subtitle_dir: str, model: str = 'flash-lite',
                      custom_prompt: str = None) -> tuple:
    """
    å¤„ç†å­—å¹•æ–‡ä»¶å¤¹ï¼Œç”Ÿæˆæ‘˜è¦å’Œæ±‡æ€»æŠ¥å‘Š

    Args:
        subtitle_dir: å­—å¹•æ–‡ä»¶å¤¹è·¯å¾„
        model: Gemini æ¨¡å‹
        custom_prompt: è‡ªå®šä¹‰æ±‡æ€»æç¤ºè¯

    Returns:
        (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, æ±‡æ€»æŠ¥å‘Šè·¯å¾„)
    """
    subtitle_path = Path(subtitle_dir)

    if not subtitle_path.is_dir():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {subtitle_path}")
        return 0, 0, None

    # è·å–ä½œè€…å
    author_name = subtitle_path.name
    print(f"ğŸ“‚ ä½œè€…: {author_name}")
    print(f"ğŸ“ ç›®å½•: {subtitle_path}")

    # æŸ¥æ‰¾æ‰€æœ‰ SRT æ–‡ä»¶
    srt_files = list(subtitle_path.glob("*.srt"))
    if not srt_files:
        print(f"âŒ æœªæ‰¾åˆ° SRT æ–‡ä»¶")
        return 0, 0, None

    print(f"ğŸ“„ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
    print("=" * 60)

    # åˆå§‹åŒ– Gemini
    try:
        summarizer = GeminiSummarizer(model=model)
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {summarizer.model_name}")
        print(f"ğŸ“¦ SDK ç‰ˆæœ¬: {'æ–°ç‰ˆ google.genai' if USE_NEW_SDK else 'æ—§ç‰ˆ google.generativeai'}")
    except ValueError as e:
        print(f"âŒ {e}")
        return 0, 0, None

    # å¤„ç†æ¯ä¸ª SRT æ–‡ä»¶
    summaries = []
    success_count = 0
    fail_count = 0
    total_tokens = 0
    total_input_tokens = 0
    total_output_tokens = 0
    start_time = time.time()

    # æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆæå‰å®šä¹‰ï¼Œç”¨äºä¸­é—´ä¿å­˜ï¼‰
    output_dir = subtitle_path.parent
    report_path = output_dir / f"{author_name}_AIæ€»ç»“.md"

    def save_progress(summaries_list: list, current_success: int, current_fail: int,
                     current_tokens: int, current_input: int, current_output: int):
        """ä¿å­˜å½“å‰è¿›åº¦åˆ°æ–‡ä»¶"""
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# {author_name} è§†é¢‘å†…å®¹åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**è§†é¢‘æ•°é‡**: {len(srt_files)}\n\n")
            f.write(f"**å·²å¤„ç†**: {current_success + current_fail} / {len(srt_files)}\n\n")
            f.write(f"**æˆåŠŸ**: {current_success} | **å¤±è´¥**: {current_fail}\n\n")
            f.write(f"**ä½¿ç”¨æ¨¡å‹**: {summarizer.model_name}\n\n")
            f.write(f"**Token**: è¾“å…¥ {current_input:,} | è¾“å‡º {current_output:,} | æ€»è®¡ {current_tokens:,}\n\n")
            f.write("---\n\n")
            f.write("## å„è§†é¢‘æ‘˜è¦ï¼ˆæŒ‰å¤„ç†é¡ºåºï¼‰\n\n")

            for item in summaries_list:
                f.write(f"### {item['title']}\n\n")
                f.write(f"{item['summary']}\n\n")
                f.write(f"*æ¥æºæ–‡ä»¶: {item['file']}*\n\n")

            if current_fail > 0:
                f.write("---\n\n")
                f.write("## å¤±è´¥åˆ—è¡¨\n\n")
                for item in summaries_list:
                    if item.get('failed'):
                        f.write(f"- **{item['title']}**: {item.get('error', 'æœªçŸ¥é”™è¯¯')}\n")

    for i, srt_file in enumerate(srt_files, 1):
        # å•ä¸ªè§†é¢‘è®¡æ—¶
        video_start_time = time.time()

        # ä»æ–‡ä»¶åæå–æ ‡é¢˜
        title = srt_file.stem  # å»æ‰ .srt åç¼€

        print(f"\n{'='*60}")
        print(f"[{i}/{len(srt_files)}] å¤„ç†: {title}")
        print(f"{'='*60}")

        # è½¬æ¢ SRT ä¸ºæ–‡æœ¬
        srt_text = srt_to_text(srt_file)
        print(f"ğŸ“„ æ–‡æœ¬é•¿åº¦: {len(srt_text):,} å­—ç¬¦")

        # ç”Ÿæˆæ‘˜è¦
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ Gemini API ç”ŸæˆçŸ¥è¯†åº“ç¬”è®°...")
        result = summarizer.generate_summary(srt_text, title)

        # å•ä¸ªè§†é¢‘è€—æ—¶
        video_elapsed = time.time() - video_start_time

        if result['success']:
            input_tokens = result.get('input_tokens', 0)
            output_tokens = result.get('output_tokens', 0)
            total_tokens_used = result['tokens']

            print(f"  âœ… æˆåŠŸ!")
            print(f"  ğŸ“Š Tokens: è¾“å…¥ {input_tokens:,} | è¾“å‡º {output_tokens:,} | æ€»è®¡ {total_tokens_used:,}")
            print(f"  ğŸ“ æ‘˜è¦é•¿åº¦: {len(result['summary']):,} å­—ç¬¦")
            print(f"  â±ï¸  æœ¬è§†é¢‘è€—æ—¶: {video_elapsed:.2f}ç§’")

            summaries.append({
                'title': title,
                'summary': result['summary'],
                'file': srt_file.name
            })
            success_count += 1
            total_tokens += total_tokens_used
            total_input_tokens += input_tokens
            total_output_tokens += output_tokens
        else:
            print(f"  âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print(f"  â±ï¸  æœ¬è§†é¢‘è€—æ—¶: {video_elapsed:.2f}ç§’")
            summaries.append({
                'title': title,
                'summary': f"**å¤„ç†å¤±è´¥**: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                'file': srt_file.name,
                'failed': True,
                'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
            })
            fail_count += 1

        # æ€»è¿›åº¦
        total_elapsed = time.time() - start_time
        avg_time = total_elapsed / i
        remaining = avg_time * (len(srt_files) - i)
        print(f"  ğŸ“ˆ æ€»è¿›åº¦: {total_elapsed:.2f}ç§’ | é¢„è®¡å‰©ä½™: {remaining:.2f}ç§’")

        # æ¯ 5 ä¸ªè§†é¢‘ä¿å­˜ä¸€æ¬¡è¿›åº¦
        if i % 5 == 0:
            save_progress(summaries, success_count, fail_count, total_tokens,
                        total_input_tokens, total_output_tokens)
            print(f"  ğŸ’¾ è¿›åº¦å·²ä¿å­˜ ({i}/{len(srt_files)})")

    # ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š
    print("\n" + "=" * 60)
    print(f"ğŸ“ ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š...")

    # è¿‡æ»¤å‡ºæˆåŠŸçš„æ‘˜è¦ç”¨äºç”Ÿæˆæ€»æŠ¥å‘Š
    successful_summaries = [s for s in summaries if not s.get('failed')]
    final_result = summarizer.generate_final_summary(successful_summaries, author_name, custom_prompt)

    # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"# {author_name} è§†é¢‘å†…å®¹åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**è§†é¢‘æ•°é‡**: {len(srt_files)}\n\n")
        f.write(f"**æˆåŠŸå¤„ç†**: {success_count}\n\n")
        f.write(f"**ä½¿ç”¨æ¨¡å‹**: {summarizer.model_name}\n\n")
        f.write(f"**SDK ç‰ˆæœ¬**: {'æ–°ç‰ˆ google.genai' if USE_NEW_SDK else 'æ—§ç‰ˆ google.generativeai'}\n\n")
        f.write(f"**Token ç»Ÿè®¡**: è¾“å…¥ {total_input_tokens:,} | è¾“å‡º {total_output_tokens:,} | æ€»è®¡ {total_tokens:,}\n\n")
        f.write("---\n\n")

        if final_result['success']:
            f.write(final_result['report'])
        else:
            f.write(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {final_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        f.write("\n\n---\n\n")
        f.write("## é™„å½•: å„è§†é¢‘æ‘˜è¦\n\n")

        for item in summaries:
            f.write(f"### {item['title']}\n\n")
            f.write(f"{item['summary']}\n\n")
            f.write(f"*æ¥æºæ–‡ä»¶: {item['file']}*\n\n")

    print(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # æœ€ç»ˆç»Ÿè®¡
    total_elapsed = time.time() - start_time
    print("\n" + "=" * 60)
    print(f"ğŸ“Š å¤„ç†å®Œæˆ!")
    print(f"  æˆåŠŸ: {success_count} | å¤±è´¥: {fail_count} | æ€»è®¡: {len(srt_files)}")
    print(f"  æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
    print(f"  å¹³å‡æ¯è§†é¢‘: {total_elapsed/len(srt_files):.2f}ç§’")
    print(f"ğŸ“Š Token ç»Ÿè®¡:")
    print(f"  è¾“å…¥ Tokens: {total_input_tokens:,}")
    print(f"  è¾“å‡º Tokens: {total_output_tokens:,}")
    print(f"  æ€»è®¡ Tokens: {total_tokens:,}")

    return success_count, fail_count, report_path


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Gemini API æ‰¹é‡ç”Ÿæˆå­—å¹•æ‘˜è¦å’Œæ±‡æ€»æŠ¥å‘Š",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
    # å¤„ç†æŒ‡å®šä½œè€…çš„å­—å¹•æ–‡ä»¶å¤¹
    python gemini_subtitle_summary.py "output/subtitles/å°å¤©fotos"

    # æŒ‡å®šæ±‡æ€»ä¸»é¢˜
    python gemini_subtitle_summary.py "output/subtitles/å°å¤©fotos" -p "åˆ†æè¿™ä¸ªUPä¸»çš„å†…å®¹ç‰¹è‰²"

    # æŒ‡å®šGeminiæ¨¡å‹
    python gemini_subtitle_summary.py "output/subtitles/å°å¤©fotos" --model flash-lite
        """
    )

    parser.add_argument('subtitle_dir', help='å­—å¹•æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä½œè€…æ–‡ä»¶å¤¹ï¼‰')
    parser.add_argument('-m', '--model', choices=['flash', 'flash-lite', 'pro'],
                        default='flash-lite', help='Gemini æ¨¡å‹ï¼ˆé»˜è®¤: flash-liteï¼‰')
    parser.add_argument('-p', '--prompt', help='è‡ªå®šä¹‰æ±‡æ€»æç¤ºè¯')
    parser.add_argument('--api-key', help='Gemini API Keyï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')

    args = parser.parse_args()

    # å¤„ç†å­—å¹•
    process_subtitles(args.subtitle_dir, args.model, args.prompt)


if __name__ == "__main__":
    main()
