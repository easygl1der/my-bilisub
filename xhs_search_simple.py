#!/usr/bin/env python3
"""
å°çº¢ä¹¦æœç´¢å·¥å…· - ç®€åŒ–ç¨³å®šç‰ˆ

åŠŸèƒ½ï¼š
1. æœç´¢æŒ‡å®šå…³é”®è¯
2. æ”¯æŒæ’åºæ–¹å¼ï¼ˆæ¨è/æœ€æ–°/æœ€çƒ­ï¼‰
3. æŒ‡å®šè·å–æ•°é‡
4. è¿”å›ç¬”è®°é“¾æ¥åˆ—è¡¨

ä½¿ç”¨ç¤ºä¾‹:
    # é»˜è®¤æœç´¢ï¼ˆæ¨èæ’åºï¼Œ20æ¡ï¼‰
    python xhs_search_simple.py --keyword "ç¾é£Ÿ"

    # æœç´¢æœ€æ–°ç¬”è®°
    python xhs_search_simple.py --keyword "ç¾é£Ÿ" --sort latest

    # æœç´¢æœ€çƒ­ç¬”è®°
    python xhs_search_simple.py --keyword "ç¾é£Ÿ" --sort hot

    # æŒ‡å®šè·å–æ•°é‡
    python xhs_search_simple.py --keyword "ç¾é£Ÿ" --max-notes 50
"""

import asyncio
import sys
import re
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from playwright.async_api import async_playwright

PROJECT_DIR = Path(__file__).parent
OUTPUT_DIR = PROJECT_DIR / "output" / "xhs_search_results"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def read_xhs_cookie_string() -> str:
    """ä» config/cookies.txt è¯»å–å°çº¢ä¹¦Cookieï¼ˆè¿”å›å­—ç¬¦ä¸²æ ¼å¼ï¼‰"""
    cookie_file = PROJECT_DIR / "config" / "cookies.txt"
    if not cookie_file.exists():
        return ""

    with open(cookie_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŸ¥æ‰¾ xiaohongshu_full= æ ¼å¼
    match = re.search(r'xiaohongshu_full=([^\n]+)', content)
    if match:
        return match.group(1)

    # æŸ¥æ‰¾ [xiaohongshu] éƒ¨åˆ†
    xhs_section = re.search(r'\[xiaohongshu\](.*?)\[', content, re.DOTALL)
    if xhs_section:
        section = xhs_section.group(1)
        cookies = []
        for line in section.split('\n'):
            line = line.strip()
            if '=' in line and not line.startswith('#'):
                key, value = line.split('=', 1)
                cookies.append(f"{key.strip()}={value.strip()}")
        return '; '.join(cookies)

    return ""


class XHSSearch:
    """å°çº¢ä¹¦æœç´¢ç±»"""

    def __init__(self):
        self.browser = None
        self.context = None
        self.page = None
        self.playwright = None

    async def start(self, headless: bool = False):
        """å¯åŠ¨æµè§ˆå™¨"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=headless)
        self.context = await self.browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )

        # è®¾ç½®Cookie
        cookie = read_xhs_cookie_string()
        if cookie:
            try:
                cookies = []
                for item in cookie.split(';'):
                    item = item.strip()
                    if '=' in item:
                        key, value = item.split('=', 1)
                        cookies.append({
                            'name': key,
                            'value': value,
                            'domain': '.xiaohongshu.com',
                            'path': '/'
                        })
                await self.context.add_cookies(cookies)
                print(f"âœ… Cookieå·²è®¾ç½® ({len(cookies)} ä¸ª)")
            except Exception as e:
                print(f"âš ï¸  Cookieè®¾ç½®å¤±è´¥: {e}")

        self.page = await self.context.new_page()
        print("âœ… æµè§ˆå™¨å·²å¯åŠ¨")

    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.page:
            await self.page.close()
        if self.context:
            await self.context.close()
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        print("âœ… æµè§ˆå™¨å·²å…³é—­")

    async def search(
        self,
        keyword: str,
        sort_type: str = "default",
        max_notes: int = 20
    ) -> List[Dict]:
        """
        æœç´¢å°çº¢ä¹¦

        Args:
            keyword: æœç´¢å…³é”®è¯
            sort_type: æ’åºç±»å‹
                - default: é»˜è®¤/æ¨è
                - latest: æœ€æ–°
                - hot: æœ€çƒ­/ç‚¹èµæ•°æ’åº
            max_notes: æœ€å¤šè·å–çš„ç¬”è®°æ•°

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        print(f"\nğŸ” æœç´¢å‚æ•°:")
        print(f"   å…³é”®è¯: {keyword}")
        print(f"   æ’åº: {sort_type}")
        print(f"   æ•°é‡: {max_notes}")

        # æ„é€ æœç´¢URL
        # æ³¨æ„ï¼šå°çº¢ä¹¦æœç´¢é¡µé¢æœ¬èº«å¯èƒ½æœ‰æ’åºé€‰é¡¹ï¼Œä½†URLå‚æ•°å¯èƒ½ä¸èµ·ä½œç”¨
        search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}&type=51"
        sort_display = {
            "default": "é»˜è®¤/æ¨è",
            "latest": "æœ€æ–°",
            "hot": "æœ€çƒ­"
        }
        print(f"\nğŸ“„ è®¿é—®: {search_url}")
        print(f"ğŸ“Š æ’åºæ–¹å¼: {sort_display.get(sort_type, 'é»˜è®¤')} (å°çº¢ä¹¦å¯èƒ½é€šè¿‡UIé€‰é¡¹å®ç°)")

        try:
            # ç›´æ¥è®¿é—®æœç´¢é¡µé¢
            await self.page.goto(search_url, wait_until='domcontentloaded', timeout=45000)
            await asyncio.sleep(3)
        except Exception as e:
            print(f"âš ï¸  é¡µé¢åŠ è½½é—®é¢˜: {e}")
            return []

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        try:
            page_content = await self.page.content()
            if 'ç™»å½•' in page_content and 'æ³¨å†Œ' in page_content:
                print("âš ï¸  æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€")
                return []
        except Exception as e:
            print(f"âš ï¸  è·å–é¡µé¢å†…å®¹å¤±è´¥: {e}")
            return []

        # å°è¯•æ»šåŠ¨åŠ è½½ï¼ˆå¢åŠ å»¶è¿Ÿé¿å…å¯¼èˆªå†²çªï¼‰
        print("\nğŸ“œ å°è¯•åŠ è½½æ›´å¤šç¬”è®°...")
        try:
            await asyncio.sleep(2)
            await self.page.evaluate('window.scrollBy(0, window.innerHeight * 0.5)')
            await asyncio.sleep(2)
            print("   ç¬¬ä¸€æ¬¡æ»šåŠ¨å®Œæˆ")
        except Exception as e:
            print(f"   æ»šåŠ¨å¤±è´¥: {e}")

        # æå–ç¬”è®°é“¾æ¥
        print("\nğŸ” æå–ç¬”è®°é“¾æ¥...")
        notes = await self.page.evaluate('''
            () => {
                const result = [];

                // æŸ¥æ‰¾æ‰€æœ‰å¸¦ xsec_token çš„é“¾æ¥
                const allLinks = document.querySelectorAll('a[href*="xsec_token"]');

                allLinks.forEach(a => {
                    const url = a.href;

                    // æ’é™¤ç”¨æˆ·é“¾æ¥
                    if (url.includes('/user/profile/')) {
                        return;
                    }

                    // åªä¿ç•™ç¬”è®°é“¾æ¥
                    if (!url.includes('/search_result/') && !url.includes('/explore/')) {
                        return;
                    }

                    // æå– xsec_token å’Œ xsec_source
                    let xsecToken = '';
                    let xsecSource = '';

                    try {
                        const urlParams = new URLSearchParams(url.split('?')[1]);
                        xsecToken = urlParams.get('xsec_token') || '';
                        xsecSource = urlParams.get('xsec_source') || '';
                    } catch (e) {}

                    // æå–ç¬”è®°ID
                    let noteId = "";
                    if (url.includes('/search_result/')) {
                        const idMatch = url.match(/\\/search_result\\/([a-f0-9]{24})/);
                        if (idMatch) noteId = idMatch[1];
                    } else if (url.includes('/explore/')) {
                        const idMatch = url.match(/\\/explore\\/([a-f0-9]{24})/);
                        if (idMatch) noteId = idMatch[1];
                    }

                    if (!noteId) return;

                    // ä»å¡ç‰‡è·å–ä¿¡æ¯
                    let title = "æ— æ ‡é¢˜";
                    let author = "æœªçŸ¥ä½œè€…";
                    let likes = "0";

                    const card = a.closest('section, article, [class*="note"], [class*="card"], div[class*="item"]');
                    if (card) {
                        // è·å–æ ‡é¢˜
                        const textNodes = card.querySelectorAll('span, div, p, h1, h2, h3');
                        for (const node of textNodes) {
                            const text = node.textContent?.trim();
                            if (text && text.length > 3 && text.length < 100 && !/^\\d+$/.test(text)) {
                                if (!text.includes('èµ') && !text.includes('å…³æ³¨') &&
                                    !text.includes('åˆ†äº«') && !text.includes('æ”¶è—')) {
                                    title = text.substring(0, 100);
                                    break;
                                }
                            }
                        }

                        // è·å–ä½œè€…
                        const authorNodes = card.querySelectorAll('span, a');
                        for (const node of authorNodes) {
                            const text = node.textContent?.trim();
                            if (text && text.length > 1 && text.length < 30) {
                                if (!/\\d/.test(text)) {
                                    author = text;
                                    break;
                                }
                            }
                        }

                        // è·å–ç‚¹èµæ•°
                        const allNodes = card.querySelectorAll('*');
                        for (const node of allNodes) {
                            const text = node.textContent?.trim();
                            if (text && /^\\d+/.test(text)) {
                                const parentClass = node.parentElement?.className || '';
                                if (parentClass.includes('like') || parentClass.includes('count') ||
                                    parentClass.includes('interact')) {
                                    const num = parseInt(text);
                                    if (num < 1000000 && num > 0) {
                                        likes = text;
                                        break;
                                    }
                                }
                            }
                        }
                    }

                    // åˆ¤æ–­ç±»å‹
                    let type = 'image';
                    const hasVideo = card.querySelector('video');
                    if (hasVideo) {
                        type = 'video';
                    } else {
                        const hasPlayIcon = card.querySelector('[class*="play"], [class*="video"], svg[class*="play"]');
                        const hasDuration = card.textContent.includes(':') && card.textContent.match(/\\d+:\\d+/);
                        if (hasPlayIcon || hasDuration) {
                            type = 'video';
                        }
                    }

                    result.push({
                        url: url,
                        noteId: noteId,
                        title: title,
                        author: author,
                        likes: likes,
                        type: type,
                        xsecToken: xsecToken,
                        xsecSource: xsecSource
                    });
                });

                return result;
            }
        ''')

        print(f"   æ‰¾åˆ° {len(notes)} ä¸ªç¬”è®°")
        return notes[:max_notes]

    def save_results(self, notes: List[Dict], keyword: str, sort_type: str):
        """ä¿å­˜æœç´¢ç»“æœåˆ°JSONæ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"xhs_search_{keyword}_{sort_type}_{timestamp}.json"
        output_file = OUTPUT_DIR / filename

        result = {
            'keyword': keyword,
            'sort_type': sort_type,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_count': len(notes),
            'notes': notes
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“ ç»“æœå·²ä¿å­˜: {output_file}")
        return output_file


async def main():
    parser = argparse.ArgumentParser(description='å°çº¢ä¹¦æœç´¢å·¥å…·')

    parser.add_argument('--keyword', type=str, required=True, help='æœç´¢å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰')
    parser.add_argument('--sort', type=str, default='default',
                       choices=['default', 'latest', 'hot'],
                       help='æ’åºç±»å‹: default=æ¨è, latest=æœ€æ–°, hot=æœ€çƒ­ï¼ˆé»˜è®¤: defaultï¼‰')
    parser.add_argument('--max-notes', type=int, default=20,
                       help='æœ€å¤šè·å–çš„ç¬”è®°æ•°ï¼ˆé»˜è®¤: 20ï¼‰')
    parser.add_argument('--headless', action='store_true',
                       help='ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆåå°è¿è¡Œï¼‰')

    args = parser.parse_args()

    print(f"\n{'='*70}")
    print(f"  å°çº¢ä¹¦æœç´¢å·¥å…·")
    print(f"{'='*70}")

    # åˆ›å»ºæœç´¢å®ä¾‹
    searcher = XHSSearch()

    try:
        # å¯åŠ¨æµè§ˆå™¨
        await searcher.start(headless=args.headless)

        # æ‰§è¡Œæœç´¢
        notes = await searcher.search(
            keyword=args.keyword,
            sort_type=args.sort,
            max_notes=args.max_notes
        )

        if not notes:
            print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•ç¬”è®°")
            return

        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“‹ æœç´¢ç»“æœï¼ˆå‰{min(10, len(notes))}æ¡ï¼‰:")
        print("=" * 70)
        for i, note in enumerate(notes[:10], 1):
            type_emoji = 'ğŸ¬' if note['type'] == 'video' else 'ğŸ–¼ï¸'
            print(f"{i}. {type_emoji} {note['title']}")
            print(f"   ä½œè€…: {note['author']}")
            print(f"   ç‚¹èµ: {note['likes']}")
            print(f"   é“¾æ¥: {note['url'][:80]}...")
            print()

        if len(notes) > 10:
            print(f"... è¿˜æœ‰ {len(notes) - 10} æ¡ç¬”è®°")

        # ä¿å­˜ç»“æœ
        output_file = searcher.save_results(notes, args.keyword, args.sort)

        print(f"\n{'='*70}")
        print(f"  âœ… å®Œæˆï¼å…±è·å– {len(notes)} æ¡ç¬”è®°")
        print(f"{'='*70}\n")

    finally:
        # å…³é—­æµè§ˆå™¨
        await searcher.close()


if __name__ == "__main__":
    asyncio.run(main())
